{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#import needed libraries \nfrom urllib.request import urlretrieve\nimport zipfile, os\nimport time, sys, copy\nimport pandas as pd\nimport scipy.sparse as sps\nimport numpy as np\nfrom collections import defaultdict\nimport math","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clone repositeries\n!git clone https://github.com/shalini1194/RKT\n#!git clone https://github.com/lyf-1/PEBG.git\n!git clone https://github.com/jhljx/GKT.git    \n#copy repositories in working directory\n!cp -r ./GKT/* ./\n#!cp -r ./PEBG/assist09/* ./\n!cp -r ./RKT/* ./\n!cp -r ../input/skillbuilder-data-2009-2010/2012-2013-data-with-predictions-4-final.csv ./\n!cp -r ../input/assesments-12-13-precessed-data/* ./","execution_count":3,"outputs":[{"output_type":"stream","text":"Cloning into 'RKT'...\nremote: Enumerating objects: 53, done.\u001b[K\nremote: Counting objects: 100% (53/53), done.\u001b[K\nremote: Compressing objects: 100% (42/42), done.\u001b[K\nremote: Total 53 (delta 9), reused 44 (delta 7), pack-reused 0\u001b[K\nUnpacking objects: 100% (53/53), done.\nCloning into 'GKT'...\nremote: Enumerating objects: 357, done.\u001b[K\nremote: Counting objects: 100% (357/357), done.\u001b[K\nremote: Compressing objects: 100% (247/247), done.\u001b[K\nremote: Total 357 (delta 216), reused 236 (delta 107), pack-reused 0\u001b[K\nReceiving objects: 100% (357/357), 17.02 MiB | 11.31 MiB/s, done.\nResolving deltas: 100% (216/216), done.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import from github cloned repositories\nfrom RKT import utils\n\nimport copy\nimport math\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\ndef future_mask(seq_length):\n    future_mask = np.triu(np.ones((1, seq_length, seq_length)), k=1).astype('bool')\n    return torch.from_numpy(future_mask)\n\n\ndef clone(module, num):\n    return nn.ModuleList([copy.deepcopy(module) for _ in range(num)])\n\n\ndef attention(query, key, value, rel, l1, l2, timestamp, mask=None, dropout=None):\n    \"\"\"Compute scaled dot product attention.\n    \"\"\"\n    rel = rel * mask.to(torch.float) # future masking of correlation matrix.\n    rel_attn = rel.masked_fill(rel == 0, -10000)\n    rel_attn = nn.Softmax(dim=-1)(rel_attn)\n    scores = torch.matmul(query, key.transpose(-2, -1))\n    scores = scores / math.sqrt(query.size(-1))\n    if mask is not None:\n        scores = scores.masked_fill(mask, -1e9)\n\n        time_stamp= torch.exp(-torch.abs(timestamp.float()))\n        #\n        time_stamp=time_stamp.masked_fill(mask,-np.inf)\n\n\n    prob_attn = F.softmax(scores, dim=-1)\n    time_attn = F.softmax(time_stamp,dim=-1)\n    prob_attn = (1-l2)*prob_attn+l2*time_attn\n    # prob_attn = F.softmax(prob_attn + rel_attn, dim=-1)\n\n    prob_attn = (1-l1)*prob_attn + (l1)*rel_attn\n    if dropout is not None:\n        prob_attn = dropout(prob_attn)\n    return torch.matmul(prob_attn, value), prob_attn\n\n\ndef relative_attention(query, key, value, rel, l1, l2, pos_key_embeds, pos_value_embeds, mask=None, dropout=None):\n    \"\"\"Compute scaled dot product attention with relative position embeddings.\n    (https://arxiv.org/pdf/1803.02155.pdf)\n    \"\"\"\n    assert pos_key_embeds.num_embeddings == pos_value_embeds.num_embeddings\n\n    scores = torch.matmul(query, key.transpose(-2, -1))\n\n    idxs = torch.arange(scores.size(-1))\n    if query.is_cuda:\n        idxs = idxs.cuda()\n    idxs = idxs.view(-1, 1) - idxs.view(1, -1)\n    idxs = torch.clamp(idxs, 0, pos_key_embeds.num_embeddings - 1)\n\n    pos_key = pos_key_embeds(idxs).transpose(-2, -1)\n    pos_scores = torch.matmul(query.unsqueeze(-2), pos_key)\n    scores = scores.unsqueeze(-2) + pos_scores\n    scores = scores / math.sqrt(query.size(-1))\n\n    pos_value = pos_value_embeds(idxs)\n    value = value.unsqueeze(-3) + pos_value\n\n    if mask is not None:\n        scores = scores.masked_fill(mask.unsqueeze(-2), -1e9)\n    prob_attn = F.softmax(scores, dim=-1)\n    if dropout is not None:\n        prob_attn = dropout(prob_attn)\n\n    output = torch.matmul(prob_attn, value).unsqueeze(-2)\n    prob_attn = prob_attn.unsqueeze(-2)\n    return output, prob_attn\n\n\nclass MultiHeadedAttention(nn.Module):\n    def __init__(self, total_size, num_heads, drop_prob):\n        super(MultiHeadedAttention, self).__init__()\n        assert total_size % num_heads == 0\n        self.total_size = total_size\n        self.head_size = total_size // num_heads\n        self.num_heads = num_heads\n        self.linear_layers = clone(nn.Linear(total_size, total_size), 3)\n        self.dropout = nn.Dropout(p=drop_prob)\n\n    def forward(self, query, key, value, rel, l1, l2, timestamp, encode_pos, pos_key_embeds, pos_value_embeds, mask=None):\n        batch_size, seq_length = query.shape[:2]\n\n        # Apply mask to all heads\n        if mask is not None:\n            mask = mask.unsqueeze(1)\n\n        # Project inputs\n        rel = rel.unsqueeze(1).repeat(1,self.num_heads,1,1)\n        timestamp = timestamp.unsqueeze(1).repeat(1,self.num_heads,1,1)\n        query, key, value = [l(x).view(batch_size, seq_length, self.num_heads, self.head_size).transpose(1, 2)\n                             for l, x in zip(self.linear_layers, (query, key, value))]\n\n        # Apply attention\n        if encode_pos:\n            out, self.prob_attn = relative_attention(\n                query, key, value, rel, l1, l2, timestamp, pos_key_embeds, pos_value_embeds,  mask, self.dropout)\n        else:\n            out, self.prob_attn = attention(query, key, value, rel, l1, l2, timestamp, mask, self.dropout)\n\n        out = out.transpose(1, 2).contiguous().view(batch_size, seq_length, self.total_size)\n        return out, self.prob_attn\n\n\nclass RKT(nn.Module):\n    def __init__(self, num_items,  embed_size, num_attn_layers, num_heads,\n                 encode_pos, max_pos, drop_prob, l1, l2):\n        \"\"\"Self-attentive knowledge tracing.\n        Arguments:\n            num_items (int): number of items\n            num_skills (int): number of skills\n            embed_size (int): input embedding and attention dot-product dimension\n            num_attn_layers (int): number of attention layers\n            num_heads (int): number of parallel attention heads\n            encode_pos (bool): if True, use relative position embeddings\n            max_pos (int): number of position embeddings to use\n            drop_prob (float): dropout probability\n        \"\"\"\n        super(RKT, self).__init__()\n        self.embed_size = embed_size\n        self.encode_pos = encode_pos\n\n        self.item_embeds = nn.Embedding(num_items + 1, embed_size , padding_idx=0)\n        # self.skill_embeds = nn.Embedding(num_skills + 1, embed_size // 2, padding_idx=0)\n\n        self.pos_key_embeds = nn.Embedding(max_pos, embed_size // num_heads)\n        self.pos_value_embeds = nn.Embedding(max_pos, embed_size // num_heads)\n\n        self.lin_in = nn.Linear(2*embed_size, embed_size)\n        self.attn_layers = clone(MultiHeadedAttention(embed_size, num_heads, drop_prob), num_attn_layers)\n        self.dropout = nn.Dropout(p=drop_prob)\n        self.lin_out = nn.Linear(embed_size, 1)\n        self.l1 = nn.Parameter(torch.tensor(l1))\n        self.l2 = nn.Parameter(torch.tensor(l2))\n\n    def get_inputs(self, item_inputs, label_inputs):\n        item_inputs = self.item_embeds(item_inputs)\n        # skill_inputs = self.skill_embeds(skill_inputs)\n        label_inputs = label_inputs.unsqueeze(-1).float()\n\n        inputs = torch.cat([item_inputs, item_inputs], dim=-1)\n        inputs[..., :self.embed_size] *= label_inputs\n        inputs[..., self.embed_size:] *= 1 - label_inputs\n        return inputs\n\n    def get_query(self, item_ids):\n        item_ids = self.item_embeds(item_ids)\n        # skill_ids = self.skill_embeds(skill_ids)\n        query = torch.cat([item_ids], dim=-1)\n        return query\n\n    def forward(self, item_inputs, label_inputs, item_ids, rel, timestamp):\n        inputs = self.get_inputs(item_inputs, label_inputs)\n\n        inputs = F.relu(self.lin_in(inputs))\n\n        query = self.get_query(item_ids)\n\n        mask = future_mask(inputs.size(-2))\n        if inputs.is_cuda:\n            mask = mask.cuda()\n        outputs, attn  = self.attn_layers[0](query, inputs, inputs, rel, self.l1, self.l2, timestamp, self.encode_pos,\n                                                   self.pos_key_embeds, self.pos_value_embeds, mask)\n        outputs = self.dropout(outputs)\n        for l in self.attn_layers[1:]:\n            residual, attn = l(query, outputs, outputs, rel, self.l1, self.l2, self.encode_pos, timestamp, self.pos_key_embeds,\n                         self.pos_value_embeds, mask)\n            outputs = self.dropout(outputs + F.relu(residual))\n\n        return self.lin_out(outputs), attn\n\n\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\n\nclass Dataset(torch.utils.data.Dataset):\n    'Characterizes a dataset for PyTorch'\n    def __init__(self, data, labels):\n        'Initialization'\n        self.labels = labels\n        self.data = data\n\n\n    def __len__(self):\n        'Denotes the total number of samples'\n        return len(self.data)\n\n    def __getitem__(self, index):\n        'Generates one sample of data'\n        # Select sample\n        X = self.data[index]\n\n        # Load data and get label\n        y = self.labels[index]\n\n        return X, y\n    \n    \n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Passages needed to recompute pro_pro_skills\n#Initially I will use file with the ones already computed by RKT authors\n#In the future I will modify the code and try to compute better ones.\n\nimport os \nimport pandas as pd\nimport numpy as np\nfrom scipy import sparse\n\n\nclass DataProcess():\n    def __init__(self, data_folder='assist09', file_name='skill_builder_data_corrected_collapsed.csv', min_inter_num=3):\n        print(\"Process Dataset %s\" % data_folder)\n        self.min_inter_num = min_inter_num\n        self.data_folder = data_folder\n        self.file_name = file_name\n\n    def process_csv(self):\n        #pre-process original csv file for assist dataset\n\n        # read csv file\n        data_path = os.path.join(self.data_folder, self.file_name)\n        df = pd.read_csv(data_path, low_memory=False, encoding=\"ISO-8859-1\")\n        print('original records number %d' % len(df))\n\n        # delete empty skill_id\n        df = df.dropna(subset=['skill_id'])\n        df = df[~df['skill_id'].isin(['noskill'])]\n        print('After removing empty skill_id, records number %d' % len(df))\n\n        # delete scaffolding problems\n        df = df[df['original'].isin([1])]\n        print('After removing scaffolding problems, records number %d' % len(df))\n\n        #delete the users whose interaction number is less than min_inter_num\n        users = df.groupby(['user_id'], as_index=True)\n        delete_users = []\n        for u in users:\n            if len(u[1]) < self.min_inter_num:\n                delete_users.append(u[0])\n        print('deleted user number based min-inters %d' % len(delete_users))\n        df = df[~df['user_id'].isin(delete_users)]\n        print('After deleting some users, records number %d' % len(df))\n        # print('features: ', df['assistment_id'].unique(), df['answer_type'].unique())\n\n        df.to_csv(os.path.join(self.data_folder, '%s_processed.csv'%self.file_name))\n\n\n    def pro_skill_graph(self):\n        df = pd.read_csv(os.path.join(self.data_folder, '%s_processed.csv'%self.file_name),low_memory=False, encoding=\"ISO-8859-1\")\n        problems = df['problem_id'].unique()\n        pro_id_dict = dict(zip(problems, range(len(problems))))\n        print('problem number %d' % len(problems))\n\n        pro_type = df['problem_type'].unique()\n        pro_type_dict = dict(zip(pro_type, range(len(pro_type))))\n        print('problem type: ', pro_type_dict)\n\n        pro_feat = []\n        pro_skill_adj = []\n        skill_id_dict, skill_cnt = {}, 0\n        for pro_id in range(len(problems)):            \n            tmp_df = df[df['problem_id']==problems[pro_id]]\n            tmp_df_0 = tmp_df.iloc[0]\n\n            # pro_feature: [ms_of_response, answer_type, mean_correct_num]\n            ms = tmp_df['ms_first_response'].abs().mean()\n            p = tmp_df['correct'].mean()\n            pro_type_id = pro_type_dict[tmp_df_0['problem_type']] \n            tmp_pro_feat = [0.] * (len(pro_type_dict)+2)\n            tmp_pro_feat[0] = ms\n            tmp_pro_feat[pro_type_id+1] = 1.\n            tmp_pro_feat[-1] = p\n            pro_feat.append(tmp_pro_feat)\n\n            # build problem-skill bipartite\n            s = tmp_df_0['skill_id']\n            skill_id_dict[s] = skill_cnt\n            skill_cnt += 1\n            pro_skill_adj.append([pro_id, skill_id_dict[s], 1])\n\n        pro_skill_adj = np.array(pro_skill_adj).astype(np.int32)\n        pro_feat = np.array(pro_feat).astype(np.float32)\n        pro_feat[:, 0] = (pro_feat[:, 0] - np.min(pro_feat[:, 0])) / (np.max(pro_feat[:, 0])-np.min(pro_feat[:, 0]))\n        pro_num = np.max(pro_skill_adj[:, 0]) + 1\n        skill_num = np.max(pro_skill_adj[:, 1]) + 1\n        print('problem number %d, skill number %d' % (pro_num, skill_num))\n\n        # save pro-skill-graph in sparse matrix form\n        pro_skill_sparse = sparse.coo_matrix((pro_skill_adj[:, 2].astype(np.float32), (pro_skill_adj[:, 0], pro_skill_adj[:, 1])), shape=(pro_num, skill_num))\n        sparse.save_npz(os.path.join(self.data_folder, 'pro_skill_sparse.npz'), pro_skill_sparse)\n\n        # save pro-id-dict, skill-id-dict\n        self.save_dict(pro_id_dict, os.path.join(self.data_folder, 'pro_id_dict.txt'))\n        self.save_dict(skill_id_dict, os.path.join(self.data_folder, 'skill_id_dict.txt'))\n\n        # save pro_feat_arr\n        np.savez(os.path.join(self.data_folder, 'pro_feat.npz'), pro_feat=pro_feat)\n\n    def generate_user_sequence(self, seq_file):\n        # generate user interaction sequence\n        # and write to data.txt\n\n        df = pd.read_csv(os.path.join(self.data_folder, '%s_processed.csv'%self.file_name), low_memory=False, encoding=\"ISO-8859-1\")\n        ui_df = df.groupby(['user_id'], as_index=True)   \n        print('user number %d' % len(ui_df))\n\n        user_inters = []\n        cnt = 0\n        for ui in ui_df:\n            tmp_user, tmp_inter = ui[0], ui[1]\n            tmp_problems = list(tmp_inter['problem_id'])\n            tmp_skills = list(tmp_inter['skill_id'])\n            tmp_ans = list(tmp_inter['correct'])\n            tmp_end_time = list(tmp_inter['end_time'])\n            user_inters.append([[len(tmp_inter)], tmp_skills, tmp_problems, tmp_ans, tmp_end_time])\n        \n        write_file = os.path.join(self.data_folder, seq_file)\n        self.write_txt(write_file, user_inters)\n\n\n    def save_dict(self, dict_name, file_name):\n        f = open(file_name, 'w')\n        f.write(str(dict_name))\n        f.close\n\n\n    def write_txt(self, file, data):\n        with open(file, 'w') as f:\n            for dd in data:\n                for d in dd:\n                    f.write(str(d)+'\\n')\n\n\n    def read_user_sequence(self, filename, max_len=200, min_len=3, shuffle_flag=True):\n        with open(filename, 'r') as f:\n            lines = f.readlines()\n        with open(os.path.join(self.data_folder, 'skill_id_dict.txt'), 'r') as f:\n            skill_id_dict = eval(f.read()) \n        with open(os.path.join(self.data_folder, 'pro_id_dict.txt'), 'r') as f:\n            pro_id_dict = eval(f.read())\n        \n\n        y, skill, problem, real_len, timestamp = [], [], [], [], []\n        skill_num, pro_num = len(skill_id_dict), len(pro_id_dict)\n        print('skill num, pro num, ', skill_num, pro_num)\n\n        index = 0\n        while index < len(lines):\n            num = eval(lines[index])[0]\n            tmp_skills = eval(lines[index+1])[:max_len]\n            # tmp_skills = [skill_id_dict[ele]+1 for ele in tmp_skills]     # for assist09\n            tmp_skills = [ele+1 for ele in tmp_skills]                      # for assist12 \n            tmp_pro = eval(lines[index+2])[:max_len]\n            tmp_pro = [pro_id_dict[ele]+1 for ele in tmp_pro]\n            tmp_ans = eval(lines[index+3])[:max_len]\n            tmp_time = eval(lines[index+4])[:max_len]\n\n            if num>=min_len:\n                tmp_real_len = len(tmp_skills)\n                # Completion sequence\n                tmp_ans += [-1]*(max_len-tmp_real_len)\n                tmp_skills += [0]*(max_len-tmp_real_len)\n                tmp_pro += [0]*(max_len-tmp_real_len)\n                tmp_time += [-1]*(max_len-tmp_real_len)\n\n                y.append(tmp_ans)\n                skill.append(tmp_skills)\n                problem.append(tmp_pro)\n                real_len.append(tmp_real_len)\n                timestamp.append(tmp_time)\n\n            index += 5\n        \n        y = np.array(y).astype(np.float32)\n        skill = np.array(skill).astype(np.int32)\n        problem = np.array(problem).astype(np.int32)\n        real_len = np.array(real_len).astype(np.int32)\n        timestamp = np.array(timestamp).astype(np.datetime64)\n\n        print(skill.shape, problem.shape, y.shape, real_len.shape)      \n        print(np.max(y), np.min(y))\n        print(np.max(real_len), np.min(real_len))  \n        print(np.max(skill), np.min(skill))\n        print(np.max(problem), np.min(problem))\n\n        np.savez(os.path.join(self.data_folder, \"%s.npz\"%self.file_name), problem=problem, y=y, skill=skill, time = timestamp, real_len=real_len, skill_num=skill_num, problem_num=pro_num)\n\n\n\ndata_folder = './'\nmin_inter_num = 3\nfile_name='2012-2013-data-with-predictions-4-final.csv'\nDP = DataProcess(data_folder, file_name, min_inter_num)\n\nDP.process_csv()\nDP.pro_skill_graph()\nDP.generate_user_sequence('data.txt')\nDP.read_user_sequence(os.path.join(data_folder, 'data.txt')) \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os \nimport pandas as pd\nimport numpy as np\nfrom scipy import sparse\ndata_folder = './'\npro_skill_coo = sparse.load_npz(os.path.join(data_folder, 'pro_skill_sparse.npz'))\n[pro_num, skill_num] = pro_skill_coo.toarray().shape\nprint('problem number %d, skill number %d' % (pro_num, skill_num))\npro_skill_csc = pro_skill_coo.tocsc()\npro_skill_csr = pro_skill_coo.tocsr()\n\n\ndef extract_pro_pro_sim():\n    # extract pro-pro similarity sparse matrix\n    pro_pro_adj = []\n    for p in range(pro_num):\n        tmp_skills = pro_skill_csr.getrow(p).indices\n        similar_pros = pro_skill_csc[:, tmp_skills].indices\n        zipped = zip([p] * similar_pros.shape[0], similar_pros)\n        pro_pro_adj += list(zipped)\n\n    pro_pro_adj = list(set(pro_pro_adj))\n    pro_pro_adj = np.array(pro_pro_adj).astype(np.int32)\n    data = np.ones(pro_pro_adj.shape[0]).astype(np.float32)\n    pro_pro_sparse = sparse.coo_matrix((data, (pro_pro_adj[:, 0], pro_pro_adj[:, 1])), shape=(pro_num, pro_num))\n    sparse.save_npz(os.path.join(data_folder, 'pro_pro_sparse.npz'), pro_pro_sparse)\n\n\ndef extract_skill_skill_sim():\n    # extract skill-skill similarity sparse matrix\n    skill_skill_adj = []\n    for s in range(skill_num):\n        tmp_pros = pro_skill_csc.getcol(s).indices\n        similar_skills = pro_skill_csr[tmp_pros, :].indices\n        zipped = zip([s] * similar_skills.shape[0], similar_skills)\n        skill_skill_adj += list(zipped)\n\n    skill_skill_adj = list(set(skill_skill_adj))\n    skill_skill_adj = np.array(skill_skill_adj).astype(np.int32)\n    data = np.ones(skill_skill_adj.shape[0]).astype(np.float32)\n    skill_skill_sparse = sparse.coo_matrix((data, (skill_skill_adj[:, 0], skill_skill_adj[:, 1])), shape=(skill_num, skill_num))\n    sparse.save_npz(os.path.join(data_folder, 'skill_skill_sparse.npz'), skill_skill_sparse)\n\n\nextract_pro_pro_sim()\nextract_skill_skill_sim()","execution_count":6,"outputs":[{"output_type":"stream","text":"problem number 47104, skill number 47104\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import argparse\nimport psutil\nimport gc\nimport pandas as pd\nfrom random import shuffle\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nfrom scipy import sparse\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.nn.utils import clip_grad_norm_\nfrom torch.nn.utils.rnn import pad_sequence\nfrom collections import  defaultdict\nfrom sys import getsizeof\nimport tensorflow.compat.v2 as tf\nfrom datetime import datetime\n\nfrom RKT.utils import *\n\nstart = torch.cuda.Event(enable_timing=True)\nend = torch.cuda.Event(enable_timing=True)\n\nprint(torch.cuda.is_available())\ndt = datetime.utcnow()\n    \ndef compute_corr(prob_seq, next_seq, corr_dic):\n    corr= np.zeros((prob_seq.shape[0],prob_seq.shape[1], prob_seq.shape[1]))\n    for i in range(0,prob_seq.shape[0]):\n        for  j in range(0,next_seq.shape[1] ):\n            for k in range(j+1):\n                corr[i][j][k]=corr_dic[next_seq[i][j]][prob_seq[i][k]]\n    return corr\n\ndef get_corr_data_assistments(pro_num):\n    pro_pro_sparse = sparse.load_npz('./pro_pro_sparse.npz')\n    pro_pro_coo = pro_pro_sparse.tocoo()\n    # print(pro_skill_csr)\n    pro_pro_dense = pro_pro_coo.toarray()\n    return pro_pro_dense\n\ndef get_corr_data(pro_num):\n    pro_pro_dense = np.zeros((pro_num, pro_num))\n    pro_pro_ = open('../input/ednet-dataset/ednet_corr.csv')\n    for i in pro_pro_:\n        j = i.strip().split(',')\n        pro_pro_dense[int(j[0])][int(j[1])] += int(float(j[2]))\n    return pro_pro_dense\n\ndef get_data_assistments(batch_size=64):\n    \"\"\"Extract sequences from dataframe.\n    Arguments:\n        df (pandas Dataframe): output by prepare_data.py\n        max_length (int): maximum length of a sequence chunk\n        train_split (float): proportion of data to use for training\n    \"\"\"\n    \n    params = {'batch_size': batch_size,\n          'shuffle': True}\n    process = psutil.Process(os.getpid())\n    gc.enable()\n    data = np.load('../input/assesments-12-13-precessed-data/2012-2013-data-with-predictions-4-final.csv.npz')\n    y, skill, problem, timestamps, real_len = data['y'], data['skill'], data['problem'], data['time'] , data['real_len']\n    skill_num, pro_num = data['skill_num'], data['problem_num']\n    print(timestamps)\n    item_ids = [torch.tensor(i).type(torch.cuda.LongTensor) for i in problem]\n    timestamp = [torch.tensor( [(t - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's') for t in timestamp] ).type(torch.cuda.LongTensor) for timestamp in timestamps]  \n    labels = [torch.tensor(i).type(torch.cuda.LongTensor) for i in y]\n    item_inputs = [torch.cat((torch.zeros(1, dtype=torch.long).cuda(), i))[:-1] for i in item_ids]\n    # skill_inputs = [torch.cat((torch.zeros(1, dtype=torch.long), s))[:-1] for s in skill_ids]\n    label_inputs = [torch.cat((torch.zeros(1, dtype=torch.long).cuda(), l))[:-1] for l in labels]\n\n    batches = list(zip(item_inputs, label_inputs, item_ids, timestamp, labels))   \n    seq_lists = list(zip(*batches))\n    inputs_and_ids = [pad_sequence(seqs, batch_first=True, padding_value=0)\n                      for seqs in seq_lists[0:4]]\n    labels = pad_sequence(seq_lists[-1], batch_first=True, padding_value=-1)  # Pad labels with -1\n    train_data, test_data, training_labels, test_labels = train_test_split(data=list(zip(*inputs_and_ids)), labels= labels, split=0.8)\n    print(\"Corr_data computation\")\n    corr_data = get_corr_data_assistments(pro_num) \n    training_set = Dataset(train_data, training_labels)\n    #training_generator = torch.utils.data.DataLoader(training_set, **params)\n    test_set = Dataset(test_data, test_labels)\n    #test_generator = torch.utils.data.DataLoader(test_set, **params)\n    #validation_set = Dataset(val_data, val_labels)\n    #validation_generator = torch.utils.data.DataLoader(validation_set, **params)\n    \n    return (training_set, test_set, corr_data, pro_num, timestamps)\n\n\ndef get_data_Ednet(batch_size=64):\n    \"\"\"Extract sequences from dataframe.\n    Arguments:\n        df (pandas Dataframe): output by prepare_data.py\n        max_length (int): maximum length of a sequence chunk\n        train_split (float): proportion of data to use for training\n    \"\"\"\n    \n    process = psutil.Process(os.getpid())\n    gc.enable()\n    data = np.load('../input/ednet-dataset/ednet.npz')\n\n    y, skill, problem, timestamps, real_len = data['y'], data['skill'], data['problem'], data['time'] , data['real_len']\n    skill_num, pro_num = data['skill_num'], data['problem_num']\n    \n    item_ids = [torch.tensor(i).type(torch.cuda.LongTensor) for i in problem]\n    timestamp = [torch.from_numpy(np.array(timestamp)).cuda() for timestamp in timestamps]  \n    labels = [torch.tensor(i).type(torch.cuda.LongTensor) for i in y]\n    item_inputs = [torch.cat((torch.zeros(1, dtype=torch.long).cuda(), i))[:-1] for i in item_ids]\n    # skill_inputs = [torch.cat((torch.zeros(1, dtype=torch.long), s))[:-1] for s in skill_ids]\n    label_inputs = [torch.cat((torch.zeros(1, dtype=torch.long).cuda(), l))[:-1] for l in labels]\n\n    batches = list(zip(item_inputs, label_inputs, item_ids, timestamp, labels))   \n    seq_lists = list(zip(*batches))\n    inputs_and_ids = [pad_sequence(seqs, batch_first=True, padding_value=0)\n                      for seqs in seq_lists[0:4]]\n    labels = pad_sequence(seq_lists[-1], batch_first=True, padding_value=-1)  # Pad labels with -1\n    train_data, test_data, training_labels, test_labels = train_test_split(data=list(zip(*inputs_and_ids)), labels= labels, split=0.8)\n    train_data, val_data, training_labels, val_labels = train_test_split(data=train_data, labels=training_labels, split=0.8)\n    print(\"Corr_data computation\")\n    corr_data = get_corr_data(pro_num) \n    training_set = Dataset(train_data, training_labels)\n    training_generator = torch.utils.data.DataLoader(training_set, **params)\n    test_set = Dataset(test_data, test_labels)\n    test_generator = torch.utils.data.DataLoader(test_set, **params)\n    validation_set = Dataset(val_data, val_labels)\n    validation_generator = torch.utils.data.DataLoader(validation_set, **params)\n    \n    return (training_generator, validation_generator, test_generator, corr_data, pro_num, timestamps)\n\n#def load_data_and_prepare_batches();\n    \n\n\n\n\ndef train_test_split(data, labels, split=0.8):\n    n_samples = len(data)\n    # x is your dataset\n    training_data, test_data = data[:int(n_samples*split)], data[int(n_samples*split):]\n    training_labels, test_labels = labels[:int(n_samples*split)], labels[int(n_samples*split):]\n    return training_data, test_data, training_labels, test_labels\n\n\ndef compute_auc(preds, labels):\n    preds = preds[labels >= 0].flatten()\n    labels = labels[labels >= 0].float()\n    if len(torch.unique(labels)) == 1:  # Only one class\n        auc = accuracy_score(labels, preds.round())\n        acc = auc\n    else:\n        auc = roc_auc_score(labels, preds)\n        acc = accuracy_score(labels, preds.round())\n    return auc, acc\n\n\ndef compute_loss(preds, labels, criterion):\n    preds = preds[labels >= 0].flatten()\n    labels = labels[labels >= 0].float()\n    return criterion(preds, labels)\ndef computeRePos(time_seq, time_span):\n    batch_size = time_seq.shape[0]\n    size = time_seq.shape[1]\n\n    time_matrix= (torch.abs(torch.unsqueeze(time_seq, axis=1).repeat(1,size,1).reshape((batch_size, size*size,1)) - \\\n                 torch.unsqueeze(time_seq,axis=-1).repeat(1, 1, size,).reshape((batch_size, size*size,1))))\n\n    # time_matrix[time_matrix>time_span] = time_span\n    time_matrix = time_matrix.reshape((batch_size,size,size))\n\n\n    return (time_matrix)\n\n","execution_count":20,"outputs":[{"output_type":"stream","text":"True\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Code from RKT train with few changes for performance\n\n\n\n\ndef train(train_data, val_data, pro_num, corr_data, timestamp, timespan,  model, optimizer, logger, saver, num_epochs, batch_size, grad_clip):\n    \"\"\"Train SAKT model.\n    Arguments:\n        train_data (list of tuples of torch Tensor)\n        val_data (list of tuples of torch Tensor)\n        model (torch Module)\n        optimizer (torch optimizer)\n        logger: wrapper for TensorboardX logger\n        saver: wrapper for torch saving\n        num_epochs (int): number of epochs to train for\n        batch_size (int)\n        grad_clip (float): max norm of the gradients\n    \"\"\"\n    \n    params = {'batch_size': batch_size,\n          'shuffle': True}\n    process = psutil.Process(os.getpid())\n    print('entered train', process.memory_info().rss)\n    criterion = nn.BCEWithLogitsLoss()\n    step = 0\n    metrics = Metrics()\n    test_generator = torch.utils.data.DataLoader(val_data, **params)\n    print('PB memory used: ', process.memory_info().rss)\n    for epoch in range(num_epochs):\n        training_generator = torch.utils.data.DataLoader(train_data, **params)\n        print(\"in epoch\"+str(epoch))\n        print(\"Prepare batches train\")\n        #train_batches = prepare_batches(train_data, batch_size)\n        print(\"Prepare batches val\")\n        #val_batches = prepare_batches(val_data, batch_size)\n        i=0\n        # Training\n        for data, labels in training_generator:\n            item_inputs, label_inputs, item_ids, timestamp = data\n            \n            # rel = compute_corr(item_inputs, item_ids, corr_data)\n            rel = torch.Tensor(corr_data[(item_ids-1).cpu().unsqueeze(1).repeat(1,item_ids.shape[-1],1),(item_inputs-1).cpu().unsqueeze(-1).repeat(1,1,item_inputs.shape[-1])]).cuda()\n            time = computeRePos(timestamp, timespan)\n            # skill_inputs = skill_inputs.cuda()\n            # skill_ids = skill_ids.cuda()\n            #item_ids = item_ids.cuda()\n            preds, weights = model(item_inputs, label_inputs, item_ids, rel, time)\n            loss = compute_loss(preds, labels, criterion)\n            preds = torch.sigmoid(preds).detach().cpu()\n            train_auc, train_acc = compute_auc(preds, labels.cpu())\n            model.zero_grad()\n            loss.backward()\n            clip_grad_norm_(model.parameters(), grad_clip)\n            optimizer.step()\n            step += 1\n            metrics.store({'loss/train': loss.item()})\n            metrics.store({'auc/train': train_auc})\n\n            # print(step)\n            if step % 1000 == 0:\n                print(metrics.average())\n                print(step)\n\n                # weights = {\"weight/\" + name: param for name, param in model.named_parameters()}\n                # grads = {\"grad/\" + name: param.grad\n                #         for name, param in model.named_parameters() if param.grad is not None}\n                # logger.log_histograms(weights, step)\n                # logger.log_histograms(grads, step)            \n        # Logging\n        torch.save(weights, 'weight_tensor_rel')\n        # Validation\n\n        model.eval()\n        for data, labels in test_generator:\n            item_inputs, label_inputs, item_ids, timestamp = data\n            # rel = compute_corr(item_inputs, item_ids, corr_data)\n            rel = torch.Tensor(corr_data[(item_ids-1).cpu().unsqueeze(1).repeat(1,item_ids.shape[-1],1),(item_inputs-1).cpu().unsqueeze(-1).repeat(1,1,item_inputs.shape[-1])]).cuda()\n            time = computeRePos(timestamp, timespan)\n            with torch.no_grad():\n                preds,weights = model(item_inputs, label_inputs, item_ids, rel, time)\n                preds = torch.sigmoid(preds).cpu()\n            val_auc, val_acc = compute_auc(preds, labels.cpu())\n            metrics.store({'auc/val': val_auc, 'acc/val': val_acc})\n            gc.collect()\n        model.train()\n\n        # Save model\n\n        average_metrics = metrics.average()\n        logger.log_scalars(average_metrics, step)\n        print(average_metrics)\n        \n        stop = saver.save(average_metrics['auc/val'], model)\n        if stop:\n            break\n\nparser = argparse.ArgumentParser(description='Train RKT.')\nparser.add_argument('--dataset', type=str)\nparser.add_argument('--logdir', type=str, default='runs/rkt')\nparser.add_argument('--savedir', type=str, default='./')\nparser.add_argument('--patience', type=int, default=5)\nparser.add_argument('--max_length', type=int, default=50)\nparser.add_argument('--embed_size', type=int, default=64)\nparser.add_argument('--num_attn_layers', type=int, default=1)\nparser.add_argument('--num_heads', type=int, default=4)\nparser.add_argument('--encode_pos', action='store_true')\nparser.add_argument('--max_pos', type=int, default=10)\nparser.add_argument('--drop_prob', type=float, default=0.1)\nparser.add_argument('--batch_size', type=int, default=128)\nparser.add_argument('--l1', type=float, default=0.5)\nparser.add_argument('--l2', type=float, default=0.5)\nparser.add_argument('--lr', type=float, default=1e-3)\nparser.add_argument('--grad_clip', type=float, default=10)\nparser.add_argument('--num_epochs', type=int, default=300)\nparser.add_argument('--timespan', default=100000, type=int)\n\nargs = parser.parse_args(args=[])\n\n# full_df = pd.read_csv('./', sep=\",\")\n# train_df = pd.read_csv('../../KT-GAT/data/ed_net2_train.csv', sep=\",\")\n# test_df = pd.read_csv('../../KT-GAT/data/ed_net2_test.csv', sep=\",\")\n# # train_data_file = '../KT-GAT/data/ed_net.csv'\n# print(len(train_data))\n\ntrain_data, test_data, corr_data, pro_num, timestamp = get_data_assistments(batch_size=args.batch_size)\n\nprocess = psutil.Process(os.getpid())\ngc.enable()\nmemory_0= process.memory_info().rss\nprint('Memory for leading train_data and corr_data: ', memory_0)\n# num_items = int(full_df[\"item_id\"].max() + 1)\n# num_skills = int(full_df[\"skill_id\"].max() + 1)\nnum_items = pro_num\nmodel = RKT(num_items, args.embed_size, args.num_attn_layers, args.num_heads,\n              args.encode_pos, args.max_pos, args.drop_prob, args.l1, args.l2).cuda()\noptimizer = Adam(model.parameters(), lr=args.lr)\nmemory_1= process.memory_info().rss\nprint('Memory for model definition: ', memory_1-memory_0)\n\n\n# Reduce batch size until it fits on GPU\nwhile True:\n    #try:\n        # Train\n    param_str = (f'{args.dataset},'\n                 f'batch_size={args.batch_size},'\n                 f'max_length={args.max_length},'\n                 f'encode_pos={args.encode_pos},'\n                 f'max_pos={args.max_pos}')\n    logger = Logger(os.path.join(args.logdir, param_str))\n    saver = Saver(args.savedir, param_str, patience = 20)\n    print('before train', process.memory_info().rss)\n    train(train_data, test_data, pro_num, corr_data, timestamp, args.timespan, model, optimizer, logger, saver, args.num_epochs,\n          args.batch_size, args.grad_clip)\n    break\n    #except RuntimeError:\n     #   args.batch_size = args.batch_size // 2\n      #  print(RuntimeError)\n       # print(f'Batch does not fit on gpu, reducing size to {args.batch_size}')\n\nlogger.close()\n\nparam_str = (f'{args.dataset},'\n              f'batch_size={args.batch_size},'\n              f'max_length={args.max_length},'\n              f'encode_pos={args.encode_pos},'\n              f'max_pos={args.max_pos}')\nsaver = Saver(args.savedir, param_str)\nmodel = saver.load()\n\n# Predict on test set\nprint(\"pre eval\")\nmodel.eval()\nprint(\"post eval\")\ncorrect = np.empty(0)\ni=0\ntest_preds= np.empty(0)\nfor data, labels in test_data:\n    item_inputs, label_inputs, item_ids, timestamp = data\n    rel = torch.Tensor(corr_data[(item_ids-1).cpu().unsqueeze(1).repeat(1,item_ids.shape[-1],1),(item_inputs-1).cpu().unsqueeze(-1).repeat(1,1,item_inputs.shape[-1])]).cuda()\n    # skill_inputs = skill_inputs.cuda()\n    time = computeRePos(timestamp, args.timespan)\n    # skill_ids = skill_ids.cuda()\n    with torch.no_grad():\n        preds,weights = model(item_inputs, label_inputs, item_ids, rel, time)\n        preds = torch.sigmoid(preds[labels >= 0]).flatten().cpu().numpy()\n        test_preds = np.concatenate([test_preds, preds])\n        if(i%100):\n            print(test_preds.shape)\n    labels = labels[labels>=0].float()\n    correct = np.concatenate([correct, labels.cpu()])\n    if(i%100):\n        print(correct.shape)\n    i+=1\n\nprint(correct.shape)\nprint(test_preds.shape)\nprint(\"auc_test = \", roc_auc_score(correct, test_preds))\n#print(\"acc_test = \", accuracy_score(correct, test_preds))","execution_count":null,"outputs":[{"output_type":"stream","text":"[['2013-05-22T14:44:43.483000' '2013-06-05T13:00:49.989000'\n  '2013-06-05T13:00:44.274000' ... '-001-01-01T00:00:00.000000'\n  '-001-01-01T00:00:00.000000' '-001-01-01T00:00:00.000000']\n ['2012-10-29T20:10:34.873000' '2012-10-29T20:11:44.094000'\n  '2012-10-29T20:11:19.607000' ... '-001-01-01T00:00:00.000000'\n  '-001-01-01T00:00:00.000000' '-001-01-01T00:00:00.000000']\n ['2013-05-01T15:27:59.539000' '2013-05-01T15:26:42.812000'\n  '2013-05-01T15:23:37.397000' ... '-001-01-01T00:00:00.000000'\n  '-001-01-01T00:00:00.000000' '-001-01-01T00:00:00.000000']\n ...\n ['2013-08-31T20:48:18.656000' '2013-08-31T21:26:43.716000'\n  '2013-08-31T21:26:51.992000' ... '-001-01-01T00:00:00.000000'\n  '-001-01-01T00:00:00.000000' '-001-01-01T00:00:00.000000']\n ['2013-08-31T20:48:15.280000' '2013-08-31T20:53:57.370000'\n  '2013-08-31T20:50:45.586000' ... '-001-01-01T00:00:00.000000'\n  '-001-01-01T00:00:00.000000' '-001-01-01T00:00:00.000000']\n ['2013-08-31T23:00:25.289000' '2013-08-31T23:02:02.601000'\n  '2013-08-31T23:06:56.326000' ... '-001-01-01T00:00:00.000000'\n  '-001-01-01T00:00:00.000000' '-001-01-01T00:00:00.000000']]\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:65: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n","name":"stderr"},{"output_type":"stream","text":"Corr_data computation\nMemory for leading train_data and corr_data:  3307851776\nMemory for model definition:  0\nbefore train 3307851776\nentered train 3307851776\nPB memory used:  3307851776\nin epoch0\nPrepare batches train\nPrepare batches val\nStep 172, {'loss/train': 0.6037166267633438, 'auc/train': 0.5892482111656282, 'auc/val': 0.6532213510857279, 'acc/val': 0.701852509887192}\n{'loss/train': 0.6037166267633438, 'auc/train': 0.5892482111656282, 'auc/val': 0.6532213510857279, 'acc/val': 0.701852509887192}\nin epoch1\nPrepare batches train\nPrepare batches val\nStep 344, {'loss/train': 0.5769526161426721, 'auc/train': 0.6605854956250131, 'auc/val': 0.6735065843476017, 'acc/val': 0.7050610927701146}\n{'loss/train': 0.5769526161426721, 'auc/train': 0.6605854956250131, 'auc/val': 0.6735065843476017, 'acc/val': 0.7050610927701146}\nin epoch2\nPrepare batches train\nPrepare batches val\nStep 516, {'loss/train': 0.5574156000863674, 'auc/train': 0.69930380240209, 'auc/val': 0.6889951848486534, 'acc/val': 0.7095101780517971}\n{'loss/train': 0.5574156000863674, 'auc/train': 0.69930380240209, 'auc/val': 0.6889951848486534, 'acc/val': 0.7095101780517971}\nin epoch3\nPrepare batches train\nPrepare batches val\nStep 688, {'loss/train': 0.540879006302634, 'auc/train': 0.7272253740269365, 'auc/val': 0.701441425278652, 'acc/val': 0.7119676603502082}\n{'loss/train': 0.540879006302634, 'auc/train': 0.7272253740269365, 'auc/val': 0.701441425278652, 'acc/val': 0.7119676603502082}\nin epoch4\nPrepare batches train\nPrepare batches val\nStep 860, {'loss/train': 0.5292118094688238, 'auc/train': 0.7439705433348294, 'auc/val': 0.7073899387394337, 'acc/val': 0.7138200750574778}\n{'loss/train': 0.5292118094688238, 'auc/train': 0.7439705433348294, 'auc/val': 0.7073899387394337, 'acc/val': 0.7138200750574778}\nin epoch5\nPrepare batches train\nPrepare batches val\n{'loss/train': 0.5218217579381806, 'auc/train': 0.755021311427682}\n1000\nStep 1032, {'loss/train': 0.520802871324122, 'auc/train': 0.7513786115032829, 'auc/val': 0.7121095582918496, 'acc/val': 0.7155525670389765}\n{'loss/train': 0.520802871324122, 'auc/train': 0.7513786115032829, 'auc/val': 0.7121095582918496, 'acc/val': 0.7155525670389765}\nin epoch6\nPrepare batches train\nPrepare batches val\nStep 1204, {'loss/train': 0.5157876510259717, 'auc/train': 0.7613592533840919, 'auc/val': 0.7146249230458899, 'acc/val': 0.7175105733593093}\n{'loss/train': 0.5157876510259717, 'auc/train': 0.7613592533840919, 'auc/val': 0.7146249230458899, 'acc/val': 0.7175105733593093}\nin epoch7\nPrepare batches train\nPrepare batches val\nStep 1376, {'loss/train': 0.5115749113434969, 'auc/train': 0.7666893013396753, 'auc/val': 0.7158758393678258, 'acc/val': 0.7176041751637249}\n{'loss/train': 0.5115749113434969, 'auc/train': 0.7666893013396753, 'auc/val': 0.7158758393678258, 'acc/val': 0.7176041751637249}\nin epoch8\nPrepare batches train\nPrepare batches val\nStep 1548, {'loss/train': 0.508318486428538, 'auc/train': 0.7703112461567034, 'auc/val': 0.7165375515889173, 'acc/val': 0.7187994433194655}\n{'loss/train': 0.508318486428538, 'auc/train': 0.7703112461567034, 'auc/val': 0.7165375515889173, 'acc/val': 0.7187994433194655}\nin epoch9\nPrepare batches train\nPrepare batches val\nStep 1720, {'loss/train': 0.5058005161063616, 'auc/train': 0.7730163995854179, 'auc/val': 0.7175264453794126, 'acc/val': 0.7176010833155732}\n{'loss/train': 0.5058005161063616, 'auc/train': 0.7730163995854179, 'auc/val': 0.7175264453794126, 'acc/val': 0.7176010833155732}\nin epoch10\nPrepare batches train\nPrepare batches val\nStep 1892, {'loss/train': 0.5035812295106954, 'auc/train': 0.7754594389055677, 'auc/val': 0.7177463791222732, 'acc/val': 0.7187163782955908}\n{'loss/train': 0.5035812295106954, 'auc/train': 0.7754594389055677, 'auc/val': 0.7177463791222732, 'acc/val': 0.7187163782955908}\nin epoch11\nPrepare batches train\nPrepare batches val\n{'loss/train': 0.5019098004257238, 'auc/train': 0.7778752040633821}\n2000\nStep 2064, {'loss/train': 0.5012699807994068, 'auc/train': 0.7773190083724515, 'auc/val': 0.7171037787538863, 'acc/val': 0.7178839126703648}\n{'loss/train': 0.5012699807994068, 'auc/train': 0.7773190083724515, 'auc/val': 0.7171037787538863, 'acc/val': 0.7178839126703648}\nin epoch12\nPrepare batches train\nPrepare batches val\nStep 2236, {'loss/train': 0.4997737813134526, 'auc/train': 0.7795101269787257, 'auc/val': 0.7171231234731269, 'acc/val': 0.7178982132925102}\n{'loss/train': 0.4997737813134526, 'auc/train': 0.7795101269787257, 'auc/val': 0.7171231234731269, 'acc/val': 0.7178982132925102}\nin epoch13\nPrepare batches train\nPrepare batches val\nStep 2408, {'loss/train': 0.4981618875334429, 'auc/train': 0.78114333569792, 'auc/val': 0.7155728179904155, 'acc/val': 0.7173812980758001}\n{'loss/train': 0.4981618875334429, 'auc/train': 0.78114333569792, 'auc/val': 0.7155728179904155, 'acc/val': 0.7173812980758001}\nin epoch14\nPrepare batches train\nPrepare batches val\nStep 2580, {'loss/train': 0.49636629743631494, 'auc/train': 0.7830963777465209, 'auc/val': 0.7132008045557562, 'acc/val': 0.7155020485288227}\n{'loss/train': 0.49636629743631494, 'auc/train': 0.7830963777465209, 'auc/val': 0.7132008045557562, 'acc/val': 0.7155020485288227}\nin epoch15\nPrepare batches train\nPrepare batches val\nStep 2752, {'loss/train': 0.49450613177099895, 'auc/train': 0.7850440270618346, 'auc/val': 0.7130049220881902, 'acc/val': 0.7152246400819817}\n{'loss/train': 0.49450613177099895, 'auc/train': 0.7850440270618346, 'auc/val': 0.7130049220881902, 'acc/val': 0.7152246400819817}\nin epoch16\nPrepare batches train\nPrepare batches val\nStep 2924, {'loss/train': 0.49260730157757915, 'auc/train': 0.7868278996147675, 'auc/val': 0.7107441412050933, 'acc/val': 0.712579021053179}\n{'loss/train': 0.49260730157757915, 'auc/train': 0.7868278996147675, 'auc/val': 0.7107441412050933, 'acc/val': 0.712579021053179}\nin epoch17\nPrepare batches train\nPrepare batches val\n{'loss/train': 0.48946437592569153, 'auc/train': 0.7914412296139097}\n3000\nStep 3096, {'loss/train': 0.4912374618773659, 'auc/train': 0.7865621755831974, 'auc/val': 0.7096774633027338, 'acc/val': 0.7140718611034885}\n{'loss/train': 0.4912374618773659, 'auc/train': 0.7865621755831974, 'auc/val': 0.7096774633027338, 'acc/val': 0.7140718611034885}\nin epoch18\nPrepare batches train\nPrepare batches val\nStep 3268, {'loss/train': 0.4886952695804973, 'auc/train': 0.7910211290285811, 'auc/val': 0.7075172000973688, 'acc/val': 0.7122978294979888}\n{'loss/train': 0.4886952695804973, 'auc/train': 0.7910211290285811, 'auc/val': 0.7075172000973688, 'acc/val': 0.7122978294979888}\nin epoch19\nPrepare batches train\nPrepare batches val\nStep 3440, {'loss/train': 0.4860023762597594, 'auc/train': 0.7933722492681535, 'auc/val': 0.7051809466920691, 'acc/val': 0.711719888512302}\n{'loss/train': 0.4860023762597594, 'auc/train': 0.7933722492681535, 'auc/val': 0.7051809466920691, 'acc/val': 0.711719888512302}\nin epoch20\nPrepare batches train\nPrepare batches val\nStep 3612, {'loss/train': 0.4838073475416316, 'auc/train': 0.7959152111763703, 'auc/val': 0.7021068617285493, 'acc/val': 0.7074981950978949}\n{'loss/train': 0.4838073475416316, 'auc/train': 0.7959152111763703, 'auc/val': 0.7021068617285493, 'acc/val': 0.7074981950978949}\nin epoch21\nPrepare batches train\nPrepare batches val\nStep 3784, {'loss/train': 0.48081442436506583, 'auc/train': 0.7987119109236902, 'auc/val': 0.6988200978067709, 'acc/val': 0.7059516204241418}\n{'loss/train': 0.48081442436506583, 'auc/train': 0.7987119109236902, 'auc/val': 0.6988200978067709, 'acc/val': 0.7059516204241418}\nin epoch22\nPrepare batches train\nPrepare batches val\nStep 3956, {'loss/train': 0.4776729019575341, 'auc/train': 0.8017316127116062, 'auc/val': 0.6963711624627118, 'acc/val': 0.7054904162298884}\n{'loss/train': 0.4776729019575341, 'auc/train': 0.8017316127116062, 'auc/val': 0.6963711624627118, 'acc/val': 0.7054904162298884}\nin epoch23\nPrepare batches train\nPrepare batches val\n{'loss/train': 0.46973176300525665, 'auc/train': 0.8091129530488168}\n4000\nStep 4128, {'loss/train': 0.4761189455166459, 'auc/train': 0.8037264421992111, 'auc/val': 0.6936892204832729, 'acc/val': 0.7038691069560439}\n{'loss/train': 0.4761189455166459, 'auc/train': 0.8037264421992111, 'auc/val': 0.6936892204832729, 'acc/val': 0.7038691069560439}\nin epoch24\nPrepare batches train\nPrepare batches val\n","name":"stdout"},{"output_type":"stream","text":"Step 4300, {'loss/train': 0.4704232110187065, 'auc/train': 0.8089085062555554, 'auc/val': 0.690045202861349, 'acc/val': 0.7021676946869964}\n{'loss/train': 0.4704232110187065, 'auc/train': 0.8089085062555554, 'auc/val': 0.690045202861349, 'acc/val': 0.7021676946869964}\nin epoch25\nPrepare batches train\nPrepare batches val\nStep 4472, {'loss/train': 0.4666040730337764, 'auc/train': 0.8127105473886616, 'auc/val': 0.6860974595785896, 'acc/val': 0.6987462955190038}\n{'loss/train': 0.4666040730337764, 'auc/train': 0.8127105473886616, 'auc/val': 0.6860974595785896, 'acc/val': 0.6987462955190038}\nin epoch26\nPrepare batches train\nPrepare batches val\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}