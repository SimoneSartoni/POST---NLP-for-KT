{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#import needed libraries \nfrom urllib.request import urlretrieve\nimport zipfile, os\nimport time, sys, copy\nimport pandas as pd\nimport scipy.sparse as sps\nimport numpy as np\nfrom collections import defaultdict\nimport math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clone repositeries\n!git clone https://github.com/shalini1194/RKT\n#!git clone https://github.com/lyf-1/PEBG.git\n    \n#copy repositories in working directory\n!cp -r ./RKT/* ./\n#!cp -r ./PEBG/assist09/* ./\n#!cp -r ../input/skillbuilder-data-2009-2010/2012-2013-data-with-predictions-4-final.csv ./","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import from github cloned repositories\nfrom RKT import utils\nimport RKT.model_rkt as model_rkt\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\n\nclass Dataset(torch.utils.data.Dataset):\n    'Characterizes a dataset for PyTorch'\n    def __init__(self, data, labels):\n        'Initialization'\n        self.labels = labels\n        self.data = data\n\n\n    def __len__(self):\n        'Denotes the total number of samples'\n        return len(self.data)\n\n    def __getitem__(self, index):\n        'Generates one sample of data'\n        # Select sample\n        X = self.data[index]\n\n        # Load data and get label\n        y = self.labels[index]\n\n        return X, y\n    \n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Passages needed to recompute pro_pro_skills\n#Initially I will use file with the ones already computed by RKT authors\n#In the future I will modify the code and try to compute better ones.\n\"\"\"\nimport os \nimport pandas as pd\nimport numpy as np\nfrom scipy import sparse\n\n\nclass DataProcess():\n    def __init__(self, data_folder='assist09', file_name='skill_builder_data_corrected_collapsed.csv', min_inter_num=3):\n        print(\"Process Dataset %s\" % data_folder)\n        self.min_inter_num = min_inter_num\n        self.data_folder = data_folder\n        self.file_name = file_name\n\n    def process_csv(self):\n        #pre-process original csv file for assist dataset\n\n        # read csv file\n        data_path = os.path.join(self.data_folder, self.file_name)\n        df = pd.read_csv(data_path, low_memory=False, encoding=\"ISO-8859-1\")\n        print('original records number %d' % len(df))\n\n        # delete empty skill_id\n        df = df.dropna(subset=['skill_id'])\n        df = df[~df['skill_id'].isin(['noskill'])]\n        print('After removing empty skill_id, records number %d' % len(df))\n\n        # delete scaffolding problems\n        df = df[df['original'].isin([1])]\n        print('After removing scaffolding problems, records number %d' % len(df))\n\n        #delete the users whose interaction number is less than min_inter_num\n        users = df.groupby(['user_id'], as_index=True)\n        delete_users = []\n        for u in users:\n            if len(u[1]) < self.min_inter_num:\n                delete_users.append(u[0])\n        print('deleted user number based min-inters %d' % len(delete_users))\n        df = df[~df['user_id'].isin(delete_users)]\n        print('After deleting some users, records number %d' % len(df))\n        # print('features: ', df['assistment_id'].unique(), df['answer_type'].unique())\n\n        df.to_csv(os.path.join(self.data_folder, '%s_processed.csv'%self.file_name))\n\n\n    def pro_skill_graph(self):\n        df = pd.read_csv(os.path.join(self.data_folder, '%s_processed.csv'%self.file_name),low_memory=False, encoding=\"ISO-8859-1\")\n        problems = df['problem_id'].unique()\n        pro_id_dict = dict(zip(problems, range(len(problems))))\n        print('problem number %d' % len(problems))\n\n        pro_type = df['problem_type'].unique()\n        pro_type_dict = dict(zip(pro_type, range(len(pro_type))))\n        print('problem type: ', pro_type_dict)\n\n        pro_feat = []\n        pro_skill_adj = []\n        skill_id_dict, skill_cnt = {}, 0\n        for pro_id in range(len(problems)):            \n            tmp_df = df[df['problem_id']==problems[pro_id]]\n            tmp_df_0 = tmp_df.iloc[0]\n\n            # pro_feature: [ms_of_response, answer_type, mean_correct_num]\n            ms = tmp_df['ms_first_response'].abs().mean()\n            p = tmp_df['correct'].mean()\n            pro_type_id = pro_type_dict[tmp_df_0['problem_type']] \n            tmp_pro_feat = [0.] * (len(pro_type_dict)+2)\n            tmp_pro_feat[0] = ms\n            tmp_pro_feat[pro_type_id+1] = 1.\n            tmp_pro_feat[-1] = p\n            pro_feat.append(tmp_pro_feat)\n\n            # build problem-skill bipartite\n            tmp_skills =[]\n            for tmp_df_0 in tmp_df:\n                tmp_skills.append(tmp.tmp_df_0)\n            for s in tmp_skills:\n                if s not in skill_id_dict:\n                    skill_id_dict[s] = skill_cnt\n                    skill_cnt += 1\n                pro_skill_adj.append([pro_id, skill_id_dict[s], 1])\n\n        pro_skill_adj = np.array(pro_skill_adj).astype(np.int32)\n        pro_feat = np.array(pro_feat).astype(np.float32)\n        pro_feat[:, 0] = (pro_feat[:, 0] - np.min(pro_feat[:, 0])) / (np.max(pro_feat[:, 0])-np.min(pro_feat[:, 0]))\n        pro_num = np.max(pro_skill_adj[:, 0]) + 1\n        skill_num = np.max(pro_skill_adj[:, 1]) + 1\n        print('problem number %d, skill number %d' % (pro_num, skill_num))\n\n        # save pro-skill-graph in sparse matrix form\n        pro_skill_sparse = sparse.coo_matrix((pro_skill_adj[:, 2].astype(np.float32), (pro_skill_adj[:, 0], pro_skill_adj[:, 1])), shape=(pro_num, skill_num))\n        sparse.save_npz(os.path.join(self.data_folder, 'pro_skill_sparse.npz'), pro_skill_sparse)\n\n        # take joint skill as a new skill\n        skills = df['skill_id'].unique()\n        for s in skills:\n            if '_' in s:\n                skill_id_dict[s] = skill_cnt\n                skill_cnt += 1 \n\n        # save pro-id-dict, skill-id-dict\n        self.save_dict(pro_id_dict, os.path.join(self.data_folder, 'pro_id_dict.txt'))\n        self.save_dict(skill_id_dict, os.path.join(self.data_folder, 'skill_id_dict.txt'))\n\n        # save pro_feat_arr\n        np.savez(os.path.join(self.data_folder, 'pro_feat.npz'), pro_feat=pro_feat)\n\n    def generate_user_sequence(self, seq_file):\n        # generate user interaction sequence\n        # and write to data.txt\n\n        df = pd.read_csv(os.path.join(self.data_folder, '%s_processed.csv'%self.file_name), low_memory=False, encoding=\"ISO-8859-1\")\n        ui_df = df.groupby(['user_id'], as_index=True)   \n        print('user number %d' % len(ui_df))\n\n        user_inters = []\n        cnt = 0\n        for ui in ui_df:\n            tmp_user, tmp_inter = ui[0], ui[1]\n            tmp_problems = list(tmp_inter['problem_id'])\n            tmp_skills = list(tmp_inter['skill_id'])\n            tmp_ans = list(tmp_inter['correct'])\n            tmp_end_time = list(tmp_inter['end_time'])\n            user_inters.append([[len(tmp_inter)], tmp_skills, tmp_problems, tmp_ans, tmp_end_time])\n        \n        write_file = os.path.join(self.data_folder, seq_file)\n        self.write_txt(write_file, user_inters)\n\n\n    def save_dict(self, dict_name, file_name):\n        f = open(file_name, 'w')\n        f.write(str(dict_name))\n        f.close\n\n\n    def write_txt(self, file, data):\n        with open(file, 'w') as f:\n            for dd in data:\n                for d in dd:\n                    f.write(str(d)+'\\n')\n\n\n    def read_user_sequence(self, filename, max_len=200, min_len=3, shuffle_flag=True):\n        with open(filename, 'r') as f:\n            lines = f.readlines()\n        with open(os.path.join(self.data_folder, 'skill_id_dict.txt'), 'r') as f:\n            skill_id_dict = eval(f.read()) \n        with open(os.path.join(self.data_folder, 'pro_id_dict.txt'), 'r') as f:\n            pro_id_dict = eval(f.read())\n        \n\n        y, skill, problem, real_len, timestamp = [], [], [], [], []\n        skill_num, pro_num = len(skill_id_dict), len(pro_id_dict)\n        print('skill num, pro num, ', skill_num, pro_num)\n\n        index = 0\n        while index < len(lines):\n            num = eval(lines[index])[0]\n            tmp_skills = eval(lines[index+1])[:max_len]\n            # tmp_skills = [skill_id_dict[ele]+1 for ele in tmp_skills]     # for assist09\n            tmp_skills = [ele+1 for ele in tmp_skills]                      # for assist12 \n            tmp_pro = eval(lines[index+2])[:max_len]\n            tmp_pro = [pro_id_dict[ele]+1 for ele in tmp_pro]\n            tmp_ans = eval(lines[index+3])[:max_len]\n            tmp_time = eval(lines[index+4])[:max_len]\n\n            if num>=min_len:\n                tmp_real_len = len(tmp_skills)\n                # Completion sequence\n                tmp_ans += [-1]*(max_len-tmp_real_len)\n                tmp_skills += [0]*(max_len-tmp_real_len)\n                tmp_pro += [0]*(max_len-tmp_real_len)\n                tmp_time += [-1]*(max_len-tmp_real_len)\n\n                y.append(tmp_ans)\n                skill.append(tmp_skills)\n                problem.append(tmp_pro)\n                real_len.append(tmp_real_len)\n                timestamp\n\n            index += 5\n        \n        y = np.array(y).astype(np.float32)\n        skill = np.array(skill).astype(np.int32)\n        problem = np.array(problem).astype(np.int32)\n        real_len = np.array(real_len).astype(np.int32)\n\n        print(skill.shape, problem.shape, y.shape, real_len.shape)      \n        print(np.max(y), np.min(y))\n        print(np.max(real_len), np.min(real_len))  \n        print(np.max(skill), np.min(skill))\n        print(np.max(problem), np.min(problem))\n\n        np.savez(os.path.join(self.data_folder, \"%s.npz\"%self.file_name), problem=problem, y=y, skill=skill, real_len=real_len, skill_num=skill_num, problem_num=pro_num)\n\n\n\ndata_folder = './'\nmin_inter_num = 3\nfile_name='2012-2013-data-with-predictions-4-final.csv'\nDP = DataProcess(data_folder, file_name, min_inter_num)\n\nDP.process_csv()\nDP.pro_skill_graph()\nDP.generate_user_sequence('data.txt')\nDP.read_user_sequence(os.path.join(data_folder, 'data.txt')) \n\"\"\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import argparse\nimport psutil\nimport gc\nimport pandas as pd\nfrom random import shuffle\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nfrom scipy import sparse\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.nn.utils import clip_grad_norm_\nfrom torch.nn.utils.rnn import pad_sequence\nfrom collections import  defaultdict\nfrom sys import getsizeof\n\nfrom RKT.model_rkt import RKT\nfrom RKT.utils import *\n\nstart = torch.cuda.Event(enable_timing=True)\nend = torch.cuda.Event(enable_timing=True)\n\nprint(torch.cuda.is_available())\n\n\ndef compute_corr(prob_seq, next_seq, corr_dic):\n    corr= np.zeros((prob_seq.shape[0],prob_seq.shape[1], prob_seq.shape[1]))\n    for i in range(0,prob_seq.shape[0]):\n        for  j in range(0,next_seq.shape[1] ):\n            for k in range(j+1):\n                corr[i][j][k]=corr_dic[next_seq[i][j]][prob_seq[i][k]]\n    return corr\ndef get_data(batch_size=64):\n    \"\"\"Extract sequences from dataframe.\n    Arguments:\n        df (pandas Dataframe): output by prepare_data.py\n        max_length (int): maximum length of a sequence chunk\n        train_split (float): proportion of data to use for training\n    \"\"\"\n    \n    params = {'batch_size': batch_size,\n          'shuffle': True}\n    process = psutil.Process(os.getpid())\n    gc.enable()\n    data = np.load('../input/ednet-dataset/ednet.npz')\n\n    y, skill, problem, timestamps, real_len = data['y'], data['skill'], data['problem'], data['time'] , data['real_len']\n    skill_num, pro_num = data['skill_num'], data['problem_num']\n    \n    item_ids = [torch.tensor(i).type(torch.cuda.LongTensor) for i in problem]\n    timestamp = [torch.from_numpy(np.array(timestamp)).cuda() for timestamp in timestamps]  \n    labels = [torch.tensor(i).type(torch.cuda.LongTensor) for i in y]\n    item_inputs = [torch.cat((torch.zeros(1, dtype=torch.long).cuda(), i))[:-1] for i in item_ids]\n    # skill_inputs = [torch.cat((torch.zeros(1, dtype=torch.long), s))[:-1] for s in skill_ids]\n    label_inputs = [torch.cat((torch.zeros(1, dtype=torch.long).cuda(), l))[:-1] for l in labels]\n\n    batches = list(zip(item_inputs, label_inputs, item_ids, timestamp, labels))   \n    seq_lists = list(zip(*batches))\n    inputs_and_ids = [pad_sequence(seqs, batch_first=True, padding_value=0)\n                      for seqs in seq_lists[0:4]]\n    labels = pad_sequence(seq_lists[-1], batch_first=True, padding_value=-1)  # Pad labels with -1\n    train_data, test_data, training_labels, test_labels = train_test_split(data=list(zip(*inputs_and_ids)), labels= labels, split=0.8)\n    train_data, val_data, training_labels, val_labels = train_test_split(data=train_data, labels=training_labels, split=0.8)\n    print(\"Corr_data computation\")\n    corr_data = get_corr_data(pro_num) \n    training_set = Dataset(train_data, training_labels)\n    training_generator = torch.utils.data.DataLoader(training_set, **params)\n    test_set = Dataset(test_data, test_labels)\n    test_generator = torch.utils.data.DataLoader(test_set, **params)\n    validation_set = Dataset(val_data, val_labels)\n    validation_generator = torch.utils.data.DataLoader(validation_set, **params)\n    \n    return (training_generator, validation_generator, test_generator, corr_data, pro_num, timestamps)\n\n#def load_data_and_prepare_batches();\n    \n\n\n\n\ndef train_test_split(data, labels, split=0.8):\n    n_samples = len(data)\n    # x is your dataset\n    training_data, test_data = data[:int(n_samples*split)], data[int(n_samples*split):]\n    training_labels, test_labels = labels[:int(n_samples*split)], labels[int(n_samples*split):]\n    return training_data, test_data, training_labels, test_labels\n\n\ndef compute_auc(preds, labels):\n    preds = preds[labels >= 0].flatten()\n    labels = labels[labels >= 0].float()\n    if len(torch.unique(labels)) == 1:  # Only one class\n        auc = accuracy_score(labels, preds.round())\n        acc = auc\n    else:\n        auc = roc_auc_score(labels, preds)\n        acc = accuracy_score(labels, preds.round())\n    return auc, acc\n\n\ndef compute_loss(preds, labels, criterion):\n    preds = preds[labels >= 0].flatten()\n    labels = labels[labels >= 0].float()\n    return criterion(preds, labels)\ndef computeRePos(time_seq, time_span):\n    batch_size = time_seq.shape[0]\n    size = time_seq.shape[1]\n\n    time_matrix= (torch.abs(torch.unsqueeze(time_seq, axis=1).repeat(1,size,1).reshape((batch_size, size*size,1)) - \\\n                 torch.unsqueeze(time_seq,axis=-1).repeat(1, 1, size,).reshape((batch_size, size*size,1))))\n\n    # time_matrix[time_matrix>time_span] = time_span\n    time_matrix = time_matrix.reshape((batch_size,size,size))\n\n\n    return (time_matrix)\ndef get_corr_data(pro_num):\n    pro_pro_dense = np.zeros((pro_num, pro_num))\n    pro_pro_ = open('../input/ednet-dataset/ednet_corr.csv')\n    for i in pro_pro_:\n        j = i.strip().split(',')\n        pro_pro_dense[int(j[0])][int(j[1])] += int(float(j[2]))\n    return pro_pro_dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Code from RKT train with few changes for performance\n\n\n\n\ndef train(train_data, val_data, pro_num, corr_data, timestamp, timespan,  model, optimizer, logger, saver, num_epochs, batch_size, grad_clip):\n    \"\"\"Train SAKT model.\n    Arguments:\n        train_data (list of tuples of torch Tensor)\n        val_data (list of tuples of torch Tensor)\n        model (torch Module)\n        optimizer (torch optimizer)\n        logger: wrapper for TensorboardX logger\n        saver: wrapper for torch saving\n        num_epochs (int): number of epochs to train for\n        batch_size (int)\n        grad_clip (float): max norm of the gradients\n    \"\"\"\n    \n    \n    process = psutil.Process(os.getpid())\n    print('entered train', process.memory_info().rss)\n    criterion = nn.BCEWithLogitsLoss()\n    step = 0\n    metrics = Metrics()\n    print('PB memory used: ', process.memory_info().rss)\n    \n    for epoch in range(num_epochs):\n        print(\"in epoch\"+str(epoch))\n        print(\"Prepare batches train\")\n        #train_batches = prepare_batches(train_data, batch_size)\n        print(\"Prepare batches val\")\n        #val_batches = prepare_batches(val_data, batch_size)\n        i=0\n        # Training\n        for data, labels in train_data:\n            item_inputs, label_inputs, item_ids, timestamp = data\n            \n            # rel = compute_corr(item_inputs, item_ids, corr_data)\n            rel = torch.Tensor(corr_data[(item_ids-1).cpu().unsqueeze(1).repeat(1,item_ids.shape[-1],1),(item_inputs-1).cpu().unsqueeze(-1).repeat(1,1,item_inputs.shape[-1])]).cuda()\n            time = computeRePos(timestamp, timespan)\n            # skill_inputs = skill_inputs.cuda()\n            # skill_ids = skill_ids.cuda()\n            #item_ids = item_ids.cuda()\n            preds, weights = model(item_inputs, label_inputs, item_ids, rel, time)\n            loss = compute_loss(preds, labels, criterion)\n            preds = torch.sigmoid(preds).detach().cpu()\n            train_auc, train_acc = compute_auc(preds, labels.cpu())\n            model.zero_grad()\n            loss.backward()\n            clip_grad_norm_(model.parameters(), grad_clip)\n            optimizer.step()\n            step += 1\n            metrics.store({'loss/train': loss.item()})\n            metrics.store({'auc/train': train_auc})\n\n            # print(step)\n            if step % 1000 == 0:\n                print(metrics.average())\n                print(step)\n\n                # weights = {\"weight/\" + name: param for name, param in model.named_parameters()}\n                # grads = {\"grad/\" + name: param.grad\n                #         for name, param in model.named_parameters() if param.grad is not None}\n                # logger.log_histograms(weights, step)\n                # logger.log_histograms(grads, step)            \n        # Logging\n        torch.save(weights, 'weight_tensor_rel')\n        # Validation\n\n        model.eval()\n        for data, labels in val_data:\n            item_inputs, label_inputs, item_ids, timestamp = data\n            # rel = compute_corr(item_inputs, item_ids, corr_data)\n            rel = torch.Tensor(corr_data[(item_ids-1).cpu().unsqueeze(1).repeat(1,item_ids.shape[-1],1),(item_inputs-1).cpu().unsqueeze(-1).repeat(1,1,item_inputs.shape[-1])]).cuda()\n            time = computeRePos(timestamp, timespan)\n            with torch.no_grad():\n                preds,weights = model(item_inputs, label_inputs, item_ids, rel, time)\n                preds = torch.sigmoid(preds).cpu()\n            val_auc, val_acc = compute_auc(preds, labels.cpu())\n            metrics.store({'auc/val': val_auc, 'acc/val': val_acc})\n            gc.collect()\n        model.train()\n\n        # Save model\n\n        average_metrics = metrics.average()\n        logger.log_scalars(average_metrics, step)\n        print(average_metrics)\n        stop = saver.save(average_metrics['auc/val'], model)\n        if stop:\n            break\n\nparser = argparse.ArgumentParser(description='Train RKT.')\nparser.add_argument('--dataset', type=str)\nparser.add_argument('--logdir', type=str, default='runs/rkt')\nparser.add_argument('--savedir', type=str, default='save/rkt')\nparser.add_argument('--max_length', type=int, default=200)\nparser.add_argument('--embed_size', type=int, default=200)\nparser.add_argument('--num_attn_layers', type=int, default=1)\nparser.add_argument('--num_heads', type=int, default=5)\nparser.add_argument('--encode_pos', action='store_true')\nparser.add_argument('--max_pos', type=int, default=10)\nparser.add_argument('--drop_prob', type=float, default=0.2)\nparser.add_argument('--batch_size', type=int, default=400)\nparser.add_argument('--lr', type=float, default=1e-3)\nparser.add_argument('--grad_clip', type=float, default=10)\nparser.add_argument('--num_epochs', type=int, default=2)\nparser.add_argument('--timespan', default=100000, type=int)\n\nargs = parser.parse_args(args=[])\n\n# full_df = pd.read_csv('./', sep=\",\")\n# train_df = pd.read_csv('../../KT-GAT/data/ed_net2_train.csv', sep=\",\")\n# test_df = pd.read_csv('../../KT-GAT/data/ed_net2_test.csv', sep=\",\")\n# # train_data_file = '../KT-GAT/data/ed_net.csv'\n# print(len(train_data))\n\ntrain_data, val_data, test_data, corr_data, pro_num, timestamp = get_data(batch_size=200)\n\nprocess = psutil.Process(os.getpid())\ngc.enable()\nmemory_0= process.memory_info().rss\nprint('Memory for leading train_data and corr_data: ', memory_0)\n# num_items = int(full_df[\"item_id\"].max() + 1)\n# num_skills = int(full_df[\"skill_id\"].max() + 1)\nnum_items = pro_num\nmodel = RKT(num_items, args.embed_size, args.num_attn_layers, args.num_heads,\n              args.encode_pos, args.max_pos, args.drop_prob).cuda()\noptimizer = Adam(model.parameters(), lr=args.lr)\nmemory_1= process.memory_info().rss\nprint('Memory for model definition: ', memory_1-memory_0)\n\n\n# Reduce batch size until it fits on GPU\nwhile True:\n    #try:\n        # Train\n    param_str = (f'{args.dataset},'\n                 f'batch_size={args.batch_size},'\n                 f'max_length={args.max_length},'\n                 f'encode_pos={args.encode_pos},'\n                 f'max_pos={args.max_pos}')\n    logger = Logger(os.path.join(args.logdir, param_str))\n    saver = Saver(args.savedir, param_str)\n    print('before train', process.memory_info().rss)\n    train(train_data, val_data, pro_num, corr_data, timestamp, args.timespan, model, optimizer, logger, saver, args.num_epochs,\n          args.batch_size, args.grad_clip)\n    break\n    #except RuntimeError:\n     #   args.batch_size = args.batch_size // 2\n      #  print(RuntimeError)\n       # print(f'Batch does not fit on gpu, reducing size to {args.batch_size}')\n\nlogger.close()\n\nparam_str = (f'{args.dataset},'\n              f'batch_size={args.batch_size},'\n              f'max_length={args.max_length},'\n              f'encode_pos={args.encode_pos},'\n              f'max_pos={args.max_pos}')\nsaver = Saver(args.savedir, param_str)\nmodel = saver.load()\n\n# Predict on test set\nprint(\"pre eval\")\nmodel.eval()\nprint(\"post eval\")\ncorrect = np.empty(0)\ni=0\ntest_preds= np.empty(0)\nfor data, labels in test_data:\n    item_inputs, label_inputs, item_ids, timestamp = data\n    rel = torch.Tensor(corr_data[(item_ids-1).cpu().unsqueeze(1).repeat(1,item_ids.shape[-1],1),(item_inputs-1).cpu().unsqueeze(-1).repeat(1,1,item_inputs.shape[-1])]).cuda()\n    # skill_inputs = skill_inputs.cuda()\n    time = computeRePos(timestamp, args.timespan)\n    # skill_ids = skill_ids.cuda()\n    with torch.no_grad():\n        preds,weights = model(item_inputs, label_inputs, item_ids, rel, time)\n        preds = torch.sigmoid(preds[labels >= 0]).flatten().cpu().numpy()\n        test_preds = np.concatenate([test_preds, preds])\n        if(i%100):\n            print(test_preds.shape)\n    labels = labels[labels>=0].float()\n    correct = np.concatenate([correct, labels.cpu()])\n    if(i%100):\n        print(correct.shape)\n    i+=1\n\nprint(correct.shape)\nprint(test_preds.shape)\nprint(\"auc_test = \", roc_auc_score(correct, test_preds))\n#print(\"acc_test = \", accuracy_score(correct, test_preds))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}