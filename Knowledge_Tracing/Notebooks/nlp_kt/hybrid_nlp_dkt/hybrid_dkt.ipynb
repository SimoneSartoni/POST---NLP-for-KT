{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EmpyFMkRReRU",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648307875949,
     "user_tz": -60,
     "elapsed": 70614,
     "user": {
      "displayName": "Simone Sartoni",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01206349563686190394"
     }
    },
    "outputId": "3141a78d-fafa-4721-c38a-016ddba9e47c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
      "\u001B[K     |████████████████████████████████| 3.8 MB 8.1 MB/s \n",
      "\u001B[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001B[K     |████████████████████████████████| 596 kB 77.5 MB/s \n",
      "\u001B[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
      "\u001B[K     |████████████████████████████████| 895 kB 54.7 MB/s \n",
      "\u001B[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n",
      "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
      "\u001B[K     |████████████████████████████████| 6.5 MB 71.4 MB/s \n",
      "\u001B[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "\u001B[K     |████████████████████████████████| 67 kB 5.5 MB/s \n",
      "\u001B[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n",
      "Collecting sentence_transformers\n",
      "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
      "\u001B[K     |████████████████████████████████| 79 kB 5.2 MB/s \n",
      "\u001B[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.17.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.63.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.10.0+cu111)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.11.1+cu111)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.4.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.2.5)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.2 MB 16.2 MB/s \n",
      "\u001B[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence_transformers) (3.10.0.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (4.11.3)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.0.49)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.11.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.23.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.7.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.4)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (7.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=9197340b0e6f1b4079e7d2a6aff1428a04622db9626236603c24657e09de3f84\n",
      "  Stored in directory: /root/.cache/pip/wheels/83/c0/df/b6873ab7aac3f2465aa9144b6b4c41c4391cfecc027c8b07e7\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentencepiece, sentence-transformers\n",
      "Successfully installed sentence-transformers-2.2.0 sentencepiece-0.1.96\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n",
      "\u001B[K     |████████████████████████████████| 325 kB 7.5 MB/s \n",
      "\u001B[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.1 MB 62.0 MB/s \n",
      "\u001B[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
      "Collecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
      "\u001B[K     |████████████████████████████████| 134 kB 72.6 MB/s \n",
      "\u001B[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001B[K     |████████████████████████████████| 212 kB 71.5 MB/s \n",
      "\u001B[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001B[K     |████████████████████████████████| 127 kB 76.9 MB/s \n",
      "\u001B[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001B[K     |████████████████████████████████| 144 kB 73.0 MB/s \n",
      "\u001B[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "\u001B[K     |████████████████████████████████| 94 kB 4.2 MB/s \n",
      "\u001B[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001B[K     |████████████████████████████████| 271 kB 78.3 MB/s \n",
      "\u001B[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, datasets\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001B[0m\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.0.0 frozenlist-1.3.0 fsspec-2022.2.0 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n",
      "Collecting bertopic\n",
      "  Downloading bertopic-0.9.4-py2.py3-none-any.whl (57 kB)\n",
      "\u001B[K     |████████████████████████████████| 57 kB 4.1 MB/s \n",
      "\u001B[?25hCollecting umap-learn>=0.5.0\n",
      "  Downloading umap-learn-0.5.2.tar.gz (86 kB)\n",
      "\u001B[K     |████████████████████████████████| 86 kB 5.4 MB/s \n",
      "\u001B[?25hRequirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.7/dist-packages (from bertopic) (4.63.0)\n",
      "Collecting hdbscan>=0.8.27\n",
      "  Downloading hdbscan-0.8.28.tar.gz (5.2 MB)\n",
      "\u001B[K     |████████████████████████████████| 5.2 MB 80.4 MB/s \n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "    Preparing wheel metadata ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from bertopic) (1.21.5)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from bertopic) (2.2.0)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.7/dist-packages (from bertopic) (5.5.0)\n",
      "Collecting pyyaml<6.0\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001B[K     |████████████████████████████████| 636 kB 66.0 MB/s \n",
      "\u001B[?25hRequirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.7/dist-packages (from bertopic) (1.0.2)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from bertopic) (1.3.5)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->bertopic) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->bertopic) (1.4.1)\n",
      "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->bertopic) (0.29.28)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->bertopic) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.7.0->bertopic) (8.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly>=4.7.0->bertopic) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (3.2.5)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.17.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.1.96)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.4.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.11.1+cu111)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (1.10.0+cu111)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.10.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2019.12.20)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.0.49)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (21.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.6.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (4.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2.23.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.0.7)\n",
      "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.0->bertopic) (0.51.2)\n",
      "Collecting pynndescent>=0.5\n",
      "  Downloading pynndescent-0.5.6.tar.gz (1.1 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.1 MB 82.2 MB/s \n",
      "\u001B[?25hRequirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.34.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (57.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.7.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2021.10.8)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (7.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (7.1.2)\n",
      "Building wheels for collected packages: hdbscan, umap-learn, pynndescent\n",
      "  Building wheel for hdbscan (PEP 517) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for hdbscan: filename=hdbscan-0.8.28-cp37-cp37m-linux_x86_64.whl size=2330763 sha256=81a5e3a88b90411ac0def970c211cd5430ec5ddc13304b27bd37ed70397bdfc6\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/7a/5e/259ccc841c085fc41b99ef4a71e896b62f5161f2bc8a14c97a\n",
      "  Building wheel for umap-learn (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for umap-learn: filename=umap_learn-0.5.2-py3-none-any.whl size=82708 sha256=10c81ebe7c8bf32d988a9f0abfec56cfa0c22e93f5f87a9508c09bd6c5fae42f\n",
      "  Stored in directory: /root/.cache/pip/wheels/84/1b/c6/aaf68a748122632967cef4dffef68224eb16798b6793257d82\n",
      "  Building wheel for pynndescent (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pynndescent: filename=pynndescent-0.5.6-py3-none-any.whl size=53943 sha256=ccfa9f47be740a2269ac443871ca82015564426d0c5a4ec54ebfccbbf9204b0d\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/f1/56/f80d72741e400345b5a5b50ec3d929aca581bf45e0225d5c50\n",
      "Successfully built hdbscan umap-learn pynndescent\n",
      "Installing collected packages: pyyaml, pynndescent, umap-learn, hdbscan, bertopic\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "Successfully installed bertopic-0.9.4 hdbscan-0.8.28 pynndescent-0.5.6 pyyaml-5.4.1 umap-learn-0.5.2\n",
      "ERROR: unknown command \"update\"\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml h5py\n",
    "!pip install transformers\n",
    "\n",
    "!pip install sentence_transformers\n",
    "!pip install datasets\n",
    "!pip install bertopic\n",
    "!pip update umap"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install --upgrade tbb"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8kcN2GxACNx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648307879500,
     "user_tz": -60,
     "elapsed": 3556,
     "user": {
      "displayName": "Simone Sartoni",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01206349563686190394"
     }
    },
    "outputId": "b265d0b4-5d43-4e67-ecf0-4bb5e339aa10"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tbb\n",
      "  Downloading tbb-2021.5.1-py2.py3-none-manylinux1_x86_64.whl (4.0 MB)\n",
      "\u001B[K     |████████████████████████████████| 4.0 MB 7.7 MB/s \n",
      "\u001B[?25hInstalling collected packages: tbb\n",
      "Successfully installed tbb-2021.5.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6353,
     "status": "ok",
     "timestamp": 1648307885850,
     "user": {
      "displayName": "Simone Sartoni",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01206349563686190394"
     },
     "user_tz": -60
    },
    "id": "EG3_4_BK-cXn",
    "outputId": "d95c3a3d-e386-40db-a302-e9537ab041a1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
      "\u001B[K     |████████████████████████████████| 24.1 MB 1.2 MB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
      "Installing collected packages: gensim\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 3.6.0\n",
      "    Uninstalling gensim-3.6.0:\n",
      "      Successfully uninstalled gensim-3.6.0\n",
      "Successfully installed gensim-4.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13371,
     "status": "ok",
     "timestamp": 1648386881793,
     "user": {
      "displayName": "Simone Sartoni",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01206349563686190394"
     },
     "user_tz": -120
    },
    "id": "mdAraGjLUiFX",
    "outputId": "a0c05bad-409b-4dd9-b08b-5c0d92977c9b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TjV0LOmESkmk"
   },
   "outputs": [],
   "source": [
    "# USE THIS TO UPDATE GITHUB DIRECTORY (NEED TO RESTART SESSION TOO)\n",
    "!rm -rf /content/TransformersForKnowledgeTracing\n",
    "!rm -rf /content/Knowledge_Tracing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12749,
     "status": "ok",
     "timestamp": 1648386894539,
     "user": {
      "displayName": "Simone Sartoni",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01206349563686190394"
     },
     "user_tz": -120
    },
    "id": "IoNhQC_cSUvS",
    "outputId": "8af4990e-b65b-4f1d-d6bd-b341ecfa2084"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'TransformersForKnowledgeTracing'...\n",
      "remote: Enumerating objects: 10061, done.\u001B[K\n",
      "remote: Counting objects: 100% (1932/1932), done.\u001B[K\n",
      "remote: Compressing objects: 100% (1280/1280), done.\u001B[K\n",
      "remote: Total 10061 (delta 1512), reused 1049 (delta 644), pack-reused 8129\u001B[K\n",
      "Receiving objects: 100% (10061/10061), 236.78 MiB | 29.52 MiB/s, done.\n",
      "Resolving deltas: 100% (8114/8114), done.\n",
      "Checking out files: 100% (375/375), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone \"https://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@github.com/SimoneSartoni/TransformersForKnowledgeTracing.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1648386894540,
     "user": {
      "displayName": "Simone Sartoni",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01206349563686190394"
     },
     "user_tz": -120
    },
    "id": "FskNj87rReR9",
    "outputId": "94164725-5972-49a7-90fc-98123748ca86"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython', '/Knowledge_Tracing', '/Knowledge_Tracing']\n"
     ]
    }
   ],
   "source": [
    "import os, sys     \n",
    "!cp -r /content/TransformersForKnowledgeTracing/* ./   \n",
    "package_paths = [\n",
    "    '/Knowledge_Tracing',\n",
    "]\n",
    "\n",
    "for pth in package_paths:\n",
    "    sys.path.append(pth)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2143,
     "status": "ok",
     "timestamp": 1648386896679,
     "user": {
      "displayName": "Simone Sartoni",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01206349563686190394"
     },
     "user_tz": -120
    },
    "id": "dBWyVU5vh3Ge"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "interactions_filepath_CA = \"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/datasets/CloudAcademy/preprocessed/interactions_processed.csv\"  # Dataset path\n",
    "texts_filepath_CA = \"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/datasets/CloudAcademy/preprocessed/texts_processed.csv\"\n",
    "config_path_CA = \"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/pretrained_distilbert_base_uncased_24_epochs/config.json\"\n",
    "model_filepath_CA = \"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/pretrained_distilbert_base_uncased_24_epochs/tf_model.h5\"\n",
    "\n",
    "interactions_filepath_2009 = \"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/datasets/assistment/2009/interactions_processed.csv\"\n",
    "texts_filepath_2009 = \"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/datasets/assistment/2009/texts_processed.csv\"\n",
    "model_filepath_2009 = \"distilbert-base-uncased\"\n",
    "config_path_finetuned = \"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/finetuned_distilbert/config.json\"\n",
    "model_filepath_finetuned = \"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/finetuned_distilbert/pytorch_model.bin\"\n",
    "\n",
    "interactions_filepath_poj = \"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/datasets/poj/interactions_processed.csv\"\n",
    "texts_filepath_poj = \"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/datasets/poj/texts_processed.csv\"\n",
    "model_filepath_poj = \"distilbert-base-uncased\"\n",
    "\n",
    "interactions_filepath_2012 = \"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/datasets/assistment/2012/interactions_processed.csv\"\n",
    "texts_filepath_2012 = \"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/datasets/assistment/2012/texts_processed.csv\"\n",
    "model_filepath_2012 = \"distilbert-base-uncased\"\n",
    "\n",
    "verbose = 1  # Verbose = {0,1,2}\n",
    "batch_size = 128  # Batch size\n",
    "    \n",
    "test_fraction = 0.2  # Portion of data to be used for testing\n",
    "validation_fraction = 0.2  # Portion of training data to be used for validation\n",
    "texts_filepath =  \"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/datasets/CloudAcademy/preprocessed/texts_processed_CA.csv\"\n",
    "save_filepath = \"/content/\"\n",
    "seq_len = 500\n",
    "\n",
    "dictionary_CA = {'user_id': 'string', 'problem_id': 'int64',\n",
    "          'correct': 'float64', \n",
    "          'skill': \"int32\",\n",
    "          'timestamp': \"string\", 'question_id': \"int64\"}\n",
    "dictionary_2009 = {'user_id': 'int32', 'problem_id': 'int64',\n",
    "              'correct': 'float64', \n",
    "              'skill': \"int32\",\n",
    "              'timestamp': \"string\", 'question_id': \"int64\"}\n",
    "\n",
    "dictionary_2012 = {'user_id': 'int32', 'problem_id': 'int64',\n",
    "              'correct': 'float64', \n",
    "              'skill': \"int32\",\n",
    "              'timestamp': \"string\", 'question_id': \"int64\"}\n",
    "\n",
    "dictionary_poj = {'user_id': 'string', 'problem_id': 'int64',\n",
    "              'correct': 'float64', \n",
    "              'timestamp': \"string\", 'question_id': \"int64\"}\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1648386896679,
     "user": {
      "displayName": "Simone Sartoni",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01206349563686190394"
     },
     "user_tz": -120
    },
    "id": "ikow8d4OFB8P"
   },
   "outputs": [],
   "source": [
    "interactions_filepath = interactions_filepath_2012\n",
    "texts_filepath = texts_filepath_2012\n",
    "dictionary = dictionary_2012\n",
    "model_filepath = model_filepath_2012\n",
    "config_path = config_path_CA\n",
    "save_filepath = \"/content/\"\n",
    "interaction_sequence_len = 500\n",
    "load_path_embeddings = \"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/datasets/assistment/2012/st_embeddings.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1648386896679,
     "user": {
      "displayName": "Simone Sartoni",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01206349563686190394"
     },
     "user_tz": -120
    },
    "id": "Et2rs0lzxmeW"
   },
   "outputs": [],
   "source": [
    "count_vectorizer_args = {\"min_df\":2, \"max_df\":1.0, \"max_features\":7000}\n",
    "#\"load_path\":load_path_embeddings\n",
    "sentence_transformers_args = {\"model_name\":\"all-mpnet-base-v2\", \"text_column\":\"plain_text\", \"fit\":{}, \"load\":{}, \"save_filepath\":save_filepath}\n",
    "\n",
    "fit_epoch_st = 1\n",
    "fit_args_epoch_1 = {\"batch_size\":8, \"fraction\":1.0, \"epochs\":fit_epoch_st, \"text_column\":\"plain_text\"}\n",
    "sentence_transformers_args_1 = {\"model_name\":\"all-mpnet-base-v2\", \"text_column\":\"plain_text\", \"fit\":fit_args_epoch_1}\n",
    "\n",
    "fit_args_epoch_5 = {\"batch_size\":8, \"fraction\":1.0, \"epochs\":5, \"text_column\":\"plain_text\"}\n",
    "sentence_transformers_args_5 = {\"model_name\":\"all-mpnet-base-v2\", \"text_column\":\"plain_text\", \"fit\":fit_args_epoch_5}\n",
    "\n",
    "load_args = {\"model_filepath\":model_filepath_poj,  \"config_path\": model_filepath_poj}\n",
    "transform_args = {\"text_column\":'sentence', \"batch_size\": 800}\n",
    "\n",
    "fit_on_custom_args = {\"batch_size\":32, \"fraction\":1.0, \"epochs\":1}\n",
    "pretrained_distilbert_args = {\n",
    "    \"model_filepath\":model_filepath_2012, \n",
    "    \"config_path\": config_path,\n",
    "    \"fit_on_custom\":{},\n",
    "    \"text_column\":\"plain_text\",\n",
    "    \"fit_on_nli\":{},\n",
    "    \"batch_size\":32\n",
    "}\n",
    "\n",
    "pretrained_args = {\"model_path_or_name\":\"all-mpnet-base-v2\"}\n",
    "bertopic_args = {\"nr_topics\":500, \n",
    "                 \"calculate_probabilities\":True, \n",
    "                 \"cluster_selection_method\":\"irrilevant\", \n",
    "                 \"output\":\"probability\",\n",
    "                 \"text_column\":\"plain_text\",\n",
    "                 \"pretrained\": pretrained_args,\n",
    "                 \"custom\":{}}\n",
    "word2vec_args = {\"epochs\":200, \"text_column\":\"list_of_words\", \"min_count\":1, \"sg\":1, \"window\":5, \"vector_size\":800, \"save_filepath\":save_filepath, \"save_name\":\"2009_\"}\n",
    "doc2vec_args = {\"epochs\":100, \"text_column\":\"list_of_words\", \"min_count\":1, \"dm\":1, \"window\":10, \"vector_size\":768, \"save_filepath\":save_filepath, \"save_name\":\"2009_\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "57af06d02e9e47d38bb931b80f2af688",
      "c8ed9321bc914937935fc9e723533a72",
      "caba4f4879c244cf83a21df3162442e5",
      "b5d28eb8800b4bb78326f90ac1d4f911",
      "383515af290242eabfe47a074c02d6cf",
      "d8b2be691467439f960cae5320ae6ccb",
      "0ec6a66430f14ab7bc2676d89e4cb81a",
      "236e702a4eb74e9e80ef2cff96a7a61a",
      "becf3d39d9a04cb386244db71d1d27f9",
      "f7013ad734a44e0992ca5f76bf1fe1cd",
      "1f637bf1da3c4d9f8a603a8307fb4a8c",
      "e994759ba959467ab0dfde85aece1c2a",
      "f7816bb7bee345379c15e178db2223f3",
      "59c8fb354be5483cab82262285043e19",
      "404e09294ec3400cac85b418e23c99e8",
      "cddb99d0690c4f46a784f8c296d4c5fc",
      "a741d3f72220439ebbd1d03eaf82283a",
      "3f138edee01e4c688c2858445e9ef8a0",
      "623ff5149aab439a914883f2c83f0a44",
      "d3f359c0318b4ecc9f8a3c1f37248b68",
      "ab173af715104eaf8d8269f25cafa054",
      "5fee3edb11e8411abd8b87e52b43117f"
     ]
    },
    "id": "KAlLPGp8lx5T",
    "outputId": "b845ff5b-9121-4ff7-e202-905b13f93baa",
    "executionInfo": {
     "status": "error",
     "timestamp": 1648378303607,
     "user_tz": -120,
     "elapsed": 5228362,
     "user": {
      "displayName": "Simone Sartoni",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01206349563686190394"
     }
    }
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading csv.....\n",
      "shape of dataframe : (179919, 7)\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing DistilBertModel.\n",
      "\n",
      "All the weights of DistilBertModel were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;30;43mStreaming output truncated to the last 5000 lines.\u001B[0m\n",
      "20064\n",
      "20096\n",
      "20128\n",
      "20160\n",
      "20192\n",
      "20224\n",
      "20256\n",
      "20288\n",
      "20320\n",
      "20352\n",
      "20384\n",
      "20416\n",
      "20448\n",
      "20480\n",
      "20512\n",
      "20544\n",
      "20576\n",
      "20608\n",
      "20640\n",
      "20672\n",
      "20704\n",
      "20736\n",
      "20768\n",
      "20800\n",
      "20832\n",
      "20864\n",
      "20896\n",
      "20928\n",
      "20960\n",
      "20992\n",
      "21024\n",
      "21056\n",
      "21088\n",
      "21120\n",
      "21152\n",
      "21184\n",
      "21216\n",
      "21248\n",
      "21280\n",
      "21312\n",
      "21344\n",
      "21376\n",
      "21408\n",
      "21440\n",
      "21472\n",
      "21504\n",
      "21536\n",
      "21568\n",
      "21600\n",
      "21632\n",
      "21664\n",
      "21696\n",
      "21728\n",
      "21760\n",
      "21792\n",
      "21824\n",
      "21856\n",
      "21888\n",
      "21920\n",
      "21952\n",
      "21984\n",
      "22016\n",
      "22048\n",
      "22080\n",
      "22112\n",
      "22144\n",
      "22176\n",
      "22208\n",
      "22240\n",
      "22272\n",
      "22304\n",
      "22336\n",
      "22368\n",
      "22400\n",
      "22432\n",
      "22464\n",
      "22496\n",
      "22528\n",
      "22560\n",
      "22592\n",
      "22624\n",
      "22656\n",
      "22688\n",
      "22720\n",
      "22752\n",
      "22784\n",
      "22816\n",
      "22848\n",
      "22880\n",
      "22912\n",
      "22944\n",
      "22976\n",
      "23008\n",
      "23040\n",
      "23072\n",
      "23104\n",
      "23136\n",
      "23168\n",
      "23200\n",
      "23232\n",
      "23264\n",
      "23296\n",
      "23328\n",
      "23360\n",
      "23392\n",
      "23424\n",
      "23456\n",
      "23488\n",
      "23520\n",
      "23552\n",
      "23584\n",
      "23616\n",
      "23648\n",
      "23680\n",
      "23712\n",
      "23744\n",
      "23776\n",
      "23808\n",
      "23840\n",
      "23872\n",
      "23904\n",
      "23936\n",
      "23968\n",
      "24000\n",
      "24032\n",
      "24064\n",
      "24096\n",
      "24128\n",
      "24160\n",
      "24192\n",
      "24224\n",
      "24256\n",
      "24288\n",
      "24320\n",
      "24352\n",
      "24384\n",
      "24416\n",
      "24448\n",
      "24480\n",
      "24512\n",
      "24544\n",
      "24576\n",
      "24608\n",
      "24640\n",
      "24672\n",
      "24704\n",
      "24736\n",
      "24768\n",
      "24800\n",
      "24832\n",
      "24864\n",
      "24896\n",
      "24928\n",
      "24960\n",
      "24992\n",
      "25024\n",
      "25056\n",
      "25088\n",
      "25120\n",
      "25152\n",
      "25184\n",
      "25216\n",
      "25248\n",
      "25280\n",
      "25312\n",
      "25344\n",
      "25376\n",
      "25408\n",
      "25440\n",
      "25472\n",
      "25504\n",
      "25536\n",
      "25568\n",
      "25600\n",
      "25632\n",
      "25664\n",
      "25696\n",
      "25728\n",
      "25760\n",
      "25792\n",
      "25824\n",
      "25856\n",
      "25888\n",
      "25920\n",
      "25952\n",
      "25984\n",
      "26016\n",
      "26048\n",
      "26080\n",
      "26112\n",
      "26144\n",
      "26176\n",
      "26208\n",
      "26240\n",
      "26272\n",
      "26304\n",
      "26336\n",
      "26368\n",
      "26400\n",
      "26432\n",
      "26464\n",
      "26496\n",
      "26528\n",
      "26560\n",
      "26592\n",
      "26624\n",
      "26656\n",
      "26688\n",
      "26720\n",
      "26752\n",
      "26784\n",
      "26816\n",
      "26848\n",
      "26880\n",
      "26912\n",
      "26944\n",
      "26976\n",
      "27008\n",
      "27040\n",
      "27072\n",
      "27104\n",
      "27136\n",
      "27168\n",
      "27200\n",
      "27232\n",
      "27264\n",
      "27296\n",
      "27328\n",
      "27360\n",
      "27392\n",
      "27424\n",
      "27456\n",
      "27488\n",
      "27520\n",
      "27552\n",
      "27584\n",
      "27616\n",
      "27648\n",
      "27680\n",
      "27712\n",
      "27744\n",
      "27776\n",
      "27808\n",
      "27840\n",
      "27872\n",
      "27904\n",
      "27936\n",
      "27968\n",
      "28000\n",
      "28032\n",
      "28064\n",
      "28096\n",
      "28128\n",
      "28160\n",
      "28192\n",
      "28224\n",
      "28256\n",
      "28288\n",
      "28320\n",
      "28352\n",
      "28384\n",
      "28416\n",
      "28448\n",
      "28480\n",
      "28512\n",
      "28544\n",
      "28576\n",
      "28608\n",
      "28640\n",
      "28672\n",
      "28704\n",
      "28736\n",
      "28768\n",
      "28800\n",
      "28832\n",
      "28864\n",
      "28896\n",
      "28928\n",
      "28960\n",
      "28992\n",
      "29024\n",
      "29056\n",
      "29088\n",
      "29120\n",
      "29152\n",
      "29184\n",
      "29216\n",
      "29248\n",
      "29280\n",
      "29312\n",
      "29344\n",
      "29376\n",
      "29408\n",
      "29440\n",
      "29472\n",
      "29504\n",
      "29536\n",
      "29568\n",
      "29600\n",
      "29632\n",
      "29664\n",
      "29696\n",
      "29728\n",
      "29760\n",
      "29792\n",
      "29824\n",
      "29856\n",
      "29888\n",
      "29920\n",
      "29952\n",
      "29984\n",
      "30016\n",
      "30048\n",
      "30080\n",
      "30112\n",
      "30144\n",
      "30176\n",
      "30208\n",
      "30240\n",
      "30272\n",
      "30304\n",
      "30336\n",
      "30368\n",
      "30400\n",
      "30432\n",
      "30464\n",
      "30496\n",
      "30528\n",
      "30560\n",
      "30592\n",
      "30624\n",
      "30656\n",
      "30688\n",
      "30720\n",
      "30752\n",
      "30784\n",
      "30816\n",
      "30848\n",
      "30880\n",
      "30912\n",
      "30944\n",
      "30976\n",
      "31008\n",
      "31040\n",
      "31072\n",
      "31104\n",
      "31136\n",
      "31168\n",
      "31200\n",
      "31232\n",
      "31264\n",
      "31296\n",
      "31328\n",
      "31360\n",
      "31392\n",
      "31424\n",
      "31456\n",
      "31488\n",
      "31520\n",
      "31552\n",
      "31584\n",
      "31616\n",
      "31648\n",
      "31680\n",
      "31712\n",
      "31744\n",
      "31776\n",
      "31808\n",
      "31840\n",
      "31872\n",
      "31904\n",
      "31936\n",
      "31968\n",
      "32000\n",
      "32032\n",
      "32064\n",
      "32096\n",
      "32128\n",
      "32160\n",
      "32192\n",
      "32224\n",
      "32256\n",
      "32288\n",
      "32320\n",
      "32352\n",
      "32384\n",
      "32416\n",
      "32448\n",
      "32480\n",
      "32512\n",
      "32544\n",
      "32576\n",
      "32608\n",
      "32640\n",
      "32672\n",
      "32704\n",
      "32736\n",
      "32768\n",
      "32800\n",
      "32832\n",
      "32864\n",
      "32896\n",
      "32928\n",
      "32960\n",
      "32992\n",
      "33024\n",
      "33056\n",
      "33088\n",
      "33120\n",
      "33152\n",
      "33184\n",
      "33216\n",
      "33248\n",
      "33280\n",
      "33312\n",
      "33344\n",
      "33376\n",
      "33408\n",
      "33440\n",
      "33472\n",
      "33504\n",
      "33536\n",
      "33568\n",
      "33600\n",
      "33632\n",
      "33664\n",
      "33696\n",
      "33728\n",
      "33760\n",
      "33792\n",
      "33824\n",
      "33856\n",
      "33888\n",
      "33920\n",
      "33952\n",
      "33984\n",
      "34016\n",
      "34048\n",
      "34080\n",
      "34112\n",
      "34144\n",
      "34176\n",
      "34208\n",
      "34240\n",
      "34272\n",
      "34304\n",
      "34336\n",
      "34368\n",
      "34400\n",
      "34432\n",
      "34464\n",
      "34496\n",
      "34528\n",
      "34560\n",
      "34592\n",
      "34624\n",
      "34656\n",
      "34688\n",
      "34720\n",
      "34752\n",
      "34784\n",
      "34816\n",
      "34848\n",
      "34880\n",
      "34912\n",
      "34944\n",
      "34976\n",
      "35008\n",
      "35040\n",
      "35072\n",
      "35104\n",
      "35136\n",
      "35168\n",
      "35200\n",
      "35232\n",
      "35264\n",
      "35296\n",
      "35328\n",
      "35360\n",
      "35392\n",
      "35424\n",
      "35456\n",
      "35488\n",
      "35520\n",
      "35552\n",
      "35584\n",
      "35616\n",
      "35648\n",
      "35680\n",
      "35712\n",
      "35744\n",
      "35776\n",
      "35808\n",
      "35840\n",
      "35872\n",
      "35904\n",
      "35936\n",
      "35968\n",
      "36000\n",
      "36032\n",
      "36064\n",
      "36096\n",
      "36128\n",
      "36160\n",
      "36192\n",
      "36224\n",
      "36256\n",
      "36288\n",
      "36320\n",
      "36352\n",
      "36384\n",
      "36416\n",
      "36448\n",
      "36480\n",
      "36512\n",
      "36544\n",
      "36576\n",
      "36608\n",
      "36640\n",
      "36672\n",
      "36704\n",
      "36736\n",
      "36768\n",
      "36800\n",
      "36832\n",
      "36864\n",
      "36896\n",
      "36928\n",
      "36960\n",
      "36992\n",
      "37024\n",
      "37056\n",
      "37088\n",
      "37120\n",
      "37152\n",
      "37184\n",
      "37216\n",
      "37248\n",
      "37280\n",
      "37312\n",
      "37344\n",
      "37376\n",
      "37408\n",
      "37440\n",
      "37472\n",
      "37504\n",
      "37536\n",
      "37568\n",
      "37600\n",
      "37632\n",
      "37664\n",
      "37696\n",
      "37728\n",
      "37760\n",
      "37792\n",
      "37824\n",
      "37856\n",
      "37888\n",
      "37920\n",
      "37952\n",
      "37984\n",
      "38016\n",
      "38048\n",
      "38080\n",
      "38112\n",
      "38144\n",
      "38176\n",
      "38208\n",
      "38240\n",
      "38272\n",
      "38304\n",
      "38336\n",
      "38368\n",
      "38400\n",
      "38432\n",
      "38464\n",
      "38496\n",
      "38528\n",
      "38560\n",
      "38592\n",
      "38624\n",
      "38656\n",
      "38688\n",
      "38720\n",
      "38752\n",
      "38784\n",
      "38816\n",
      "38848\n",
      "38880\n",
      "38912\n",
      "38944\n",
      "38976\n",
      "39008\n",
      "39040\n",
      "39072\n",
      "39104\n",
      "39136\n",
      "39168\n",
      "39200\n",
      "39232\n",
      "39264\n",
      "39296\n",
      "39328\n",
      "39360\n",
      "39392\n",
      "39424\n",
      "39456\n",
      "39488\n",
      "39520\n",
      "39552\n",
      "39584\n",
      "39616\n",
      "39648\n",
      "39680\n",
      "39712\n",
      "39744\n",
      "39776\n",
      "39808\n",
      "39840\n",
      "39872\n",
      "39904\n",
      "39936\n",
      "39968\n",
      "40000\n",
      "40032\n",
      "40064\n",
      "40096\n",
      "40128\n",
      "40160\n",
      "40192\n",
      "40224\n",
      "40256\n",
      "40288\n",
      "40320\n",
      "40352\n",
      "40384\n",
      "40416\n",
      "40448\n",
      "40480\n",
      "40512\n",
      "40544\n",
      "40576\n",
      "40608\n",
      "40640\n",
      "40672\n",
      "40704\n",
      "40736\n",
      "40768\n",
      "40800\n",
      "40832\n",
      "40864\n",
      "40896\n",
      "40928\n",
      "40960\n",
      "40992\n",
      "41024\n",
      "41056\n",
      "41088\n",
      "41120\n",
      "41152\n",
      "41184\n",
      "41216\n",
      "41248\n",
      "41280\n",
      "41312\n",
      "41344\n",
      "41376\n",
      "41408\n",
      "41440\n",
      "41472\n",
      "41504\n",
      "41536\n",
      "41568\n",
      "41600\n",
      "41632\n",
      "41664\n",
      "41696\n",
      "41728\n",
      "41760\n",
      "41792\n",
      "41824\n",
      "41856\n",
      "41888\n",
      "41920\n",
      "41952\n",
      "41984\n",
      "42016\n",
      "42048\n",
      "42080\n",
      "42112\n",
      "42144\n",
      "42176\n",
      "42208\n",
      "42240\n",
      "42272\n",
      "42304\n",
      "42336\n",
      "42368\n",
      "42400\n",
      "42432\n",
      "42464\n",
      "42496\n",
      "42528\n",
      "42560\n",
      "42592\n",
      "42624\n",
      "42656\n",
      "42688\n",
      "42720\n",
      "42752\n",
      "42784\n",
      "42816\n",
      "42848\n",
      "42880\n",
      "42912\n",
      "42944\n",
      "42976\n",
      "43008\n",
      "43040\n",
      "43072\n",
      "43104\n",
      "43136\n",
      "43168\n",
      "43200\n",
      "43232\n",
      "43264\n",
      "43296\n",
      "43328\n",
      "43360\n",
      "43392\n",
      "43424\n",
      "43456\n",
      "43488\n",
      "43520\n",
      "43552\n",
      "43584\n",
      "43616\n",
      "43648\n",
      "43680\n",
      "43712\n",
      "43744\n",
      "43776\n",
      "43808\n",
      "43840\n",
      "43872\n",
      "43904\n",
      "43936\n",
      "43968\n",
      "44000\n",
      "44032\n",
      "44064\n",
      "44096\n",
      "44128\n",
      "44160\n",
      "44192\n",
      "44224\n",
      "44256\n",
      "44288\n",
      "44320\n",
      "44352\n",
      "44384\n",
      "44416\n",
      "44448\n",
      "44480\n",
      "44512\n",
      "44544\n",
      "44576\n",
      "44608\n",
      "44640\n",
      "44672\n",
      "44704\n",
      "44736\n",
      "44768\n",
      "44800\n",
      "44832\n",
      "44864\n",
      "44896\n",
      "44928\n",
      "44960\n",
      "44992\n",
      "45024\n",
      "45056\n",
      "45088\n",
      "45120\n",
      "45152\n",
      "45184\n",
      "45216\n",
      "45248\n",
      "45280\n",
      "45312\n",
      "45344\n",
      "45376\n",
      "45408\n",
      "45440\n",
      "45472\n",
      "45504\n",
      "45536\n",
      "45568\n",
      "45600\n",
      "45632\n",
      "45664\n",
      "45696\n",
      "45728\n",
      "45760\n",
      "45792\n",
      "45824\n",
      "45856\n",
      "45888\n",
      "45920\n",
      "45952\n",
      "45984\n",
      "46016\n",
      "46048\n",
      "46080\n",
      "46112\n",
      "46144\n",
      "46176\n",
      "46208\n",
      "46240\n",
      "46272\n",
      "46304\n",
      "46336\n",
      "46368\n",
      "46400\n",
      "46432\n",
      "46464\n",
      "46496\n",
      "46528\n",
      "46560\n",
      "46592\n",
      "46624\n",
      "46656\n",
      "46688\n",
      "46720\n",
      "46752\n",
      "46784\n",
      "46816\n",
      "46848\n",
      "46880\n",
      "46912\n",
      "46944\n",
      "46976\n",
      "47008\n",
      "47040\n",
      "47072\n",
      "47104\n",
      "47136\n",
      "47168\n",
      "47200\n",
      "47232\n",
      "47264\n",
      "47296\n",
      "47328\n",
      "47360\n",
      "47392\n",
      "47424\n",
      "47456\n",
      "47488\n",
      "47520\n",
      "47552\n",
      "47584\n",
      "47616\n",
      "47648\n",
      "47680\n",
      "47712\n",
      "47744\n",
      "47776\n",
      "47808\n",
      "47840\n",
      "47872\n",
      "47904\n",
      "47936\n",
      "47968\n",
      "48000\n",
      "48032\n",
      "48064\n",
      "48096\n",
      "48128\n",
      "48160\n",
      "48192\n",
      "48224\n",
      "48256\n",
      "48288\n",
      "48320\n",
      "48352\n",
      "48384\n",
      "48416\n",
      "48448\n",
      "48480\n",
      "48512\n",
      "48544\n",
      "48576\n",
      "48608\n",
      "48640\n",
      "48672\n",
      "48704\n",
      "48736\n",
      "48768\n",
      "48800\n",
      "48832\n",
      "48864\n",
      "48896\n",
      "48928\n",
      "48960\n",
      "48992\n",
      "49024\n",
      "49056\n",
      "49088\n",
      "49120\n",
      "49152\n",
      "49184\n",
      "49216\n",
      "49248\n",
      "49280\n",
      "49312\n",
      "49344\n",
      "49376\n",
      "49408\n",
      "49440\n",
      "49472\n",
      "49504\n",
      "49536\n",
      "49568\n",
      "49600\n",
      "49632\n",
      "49664\n",
      "49696\n",
      "49728\n",
      "49760\n",
      "49792\n",
      "49824\n",
      "49856\n",
      "49888\n",
      "49920\n",
      "49952\n",
      "49984\n",
      "50016\n",
      "50048\n",
      "50080\n",
      "50112\n",
      "50144\n",
      "50176\n",
      "50208\n",
      "50240\n",
      "50272\n",
      "50304\n",
      "50336\n",
      "50368\n",
      "50400\n",
      "50432\n",
      "50464\n",
      "50496\n",
      "50528\n",
      "50560\n",
      "50592\n",
      "50624\n",
      "50656\n",
      "50688\n",
      "50720\n",
      "50752\n",
      "50784\n",
      "50816\n",
      "50848\n",
      "50880\n",
      "50912\n",
      "50944\n",
      "50976\n",
      "51008\n",
      "51040\n",
      "51072\n",
      "51104\n",
      "51136\n",
      "51168\n",
      "51200\n",
      "51232\n",
      "51264\n",
      "51296\n",
      "51328\n",
      "51360\n",
      "51392\n",
      "51424\n",
      "51456\n",
      "51488\n",
      "51520\n",
      "51552\n",
      "51584\n",
      "51616\n",
      "51648\n",
      "51680\n",
      "51712\n",
      "51744\n",
      "51776\n",
      "51808\n",
      "51840\n",
      "51872\n",
      "51904\n",
      "51936\n",
      "51968\n",
      "52000\n",
      "52032\n",
      "52064\n",
      "52096\n",
      "52128\n",
      "52160\n",
      "52192\n",
      "52224\n",
      "52256\n",
      "52288\n",
      "52320\n",
      "52352\n",
      "52384\n",
      "52416\n",
      "52448\n",
      "52480\n",
      "52512\n",
      "52544\n",
      "52576\n",
      "52608\n",
      "52640\n",
      "52672\n",
      "52704\n",
      "52736\n",
      "52768\n",
      "52800\n",
      "52832\n",
      "52864\n",
      "52896\n",
      "52928\n",
      "52960\n",
      "52992\n",
      "53024\n",
      "53056\n",
      "53088\n",
      "53120\n",
      "53152\n",
      "53184\n",
      "53216\n",
      "53248\n",
      "53280\n",
      "53312\n",
      "53344\n",
      "53376\n",
      "53408\n",
      "53440\n",
      "53472\n",
      "53504\n",
      "53536\n",
      "53568\n",
      "53600\n",
      "53632\n",
      "53664\n",
      "53696\n",
      "53728\n",
      "53760\n",
      "53792\n",
      "53824\n",
      "53856\n",
      "53888\n",
      "53920\n",
      "53952\n",
      "53984\n",
      "54016\n",
      "54048\n",
      "54080\n",
      "54112\n",
      "54144\n",
      "54176\n",
      "54208\n",
      "54240\n",
      "54272\n",
      "54304\n",
      "54336\n",
      "54368\n",
      "54400\n",
      "54432\n",
      "54464\n",
      "54496\n",
      "54528\n",
      "54560\n",
      "54592\n",
      "54624\n",
      "54656\n",
      "54688\n",
      "54720\n",
      "54752\n",
      "54784\n",
      "54816\n",
      "54848\n",
      "54880\n",
      "54912\n",
      "54944\n",
      "54976\n",
      "55008\n",
      "55040\n",
      "55072\n",
      "55104\n",
      "55136\n",
      "55168\n",
      "55200\n",
      "55232\n",
      "55264\n",
      "55296\n",
      "55328\n",
      "55360\n",
      "55392\n",
      "55424\n",
      "55456\n",
      "55488\n",
      "55520\n",
      "55552\n",
      "55584\n",
      "55616\n",
      "55648\n",
      "55680\n",
      "55712\n",
      "55744\n",
      "55776\n",
      "55808\n",
      "55840\n",
      "55872\n",
      "55904\n",
      "55936\n",
      "55968\n",
      "56000\n",
      "56032\n",
      "56064\n",
      "56096\n",
      "56128\n",
      "56160\n",
      "56192\n",
      "56224\n",
      "56256\n",
      "56288\n",
      "56320\n",
      "56352\n",
      "56384\n",
      "56416\n",
      "56448\n",
      "56480\n",
      "56512\n",
      "56544\n",
      "56576\n",
      "56608\n",
      "56640\n",
      "56672\n",
      "56704\n",
      "56736\n",
      "56768\n",
      "56800\n",
      "56832\n",
      "56864\n",
      "56896\n",
      "56928\n",
      "56960\n",
      "56992\n",
      "57024\n",
      "57056\n",
      "57088\n",
      "57120\n",
      "57152\n",
      "57184\n",
      "57216\n",
      "57248\n",
      "57280\n",
      "57312\n",
      "57344\n",
      "57376\n",
      "57408\n",
      "57440\n",
      "57472\n",
      "57504\n",
      "57536\n",
      "57568\n",
      "57600\n",
      "57632\n",
      "57664\n",
      "57696\n",
      "57728\n",
      "57760\n",
      "57792\n",
      "57824\n",
      "57856\n",
      "57888\n",
      "57920\n",
      "57952\n",
      "57984\n",
      "58016\n",
      "58048\n",
      "58080\n",
      "58112\n",
      "58144\n",
      "58176\n",
      "58208\n",
      "58240\n",
      "58272\n",
      "58304\n",
      "58336\n",
      "58368\n",
      "58400\n",
      "58432\n",
      "58464\n",
      "58496\n",
      "58528\n",
      "58560\n",
      "58592\n",
      "58624\n",
      "58656\n",
      "58688\n",
      "58720\n",
      "58752\n",
      "58784\n",
      "58816\n",
      "58848\n",
      "58880\n",
      "58912\n",
      "58944\n",
      "58976\n",
      "59008\n",
      "59040\n",
      "59072\n",
      "59104\n",
      "59136\n",
      "59168\n",
      "59200\n",
      "59232\n",
      "59264\n",
      "59296\n",
      "59328\n",
      "59360\n",
      "59392\n",
      "59424\n",
      "59456\n",
      "59488\n",
      "59520\n",
      "59552\n",
      "59584\n",
      "59616\n",
      "59648\n",
      "59680\n",
      "59712\n",
      "59744\n",
      "59776\n",
      "59808\n",
      "59840\n",
      "59872\n",
      "59904\n",
      "59936\n",
      "59968\n",
      "60000\n",
      "60032\n",
      "60064\n",
      "60096\n",
      "60128\n",
      "60160\n",
      "60192\n",
      "60224\n",
      "60256\n",
      "60288\n",
      "60320\n",
      "60352\n",
      "60384\n",
      "60416\n",
      "60448\n",
      "60480\n",
      "60512\n",
      "60544\n",
      "60576\n",
      "60608\n",
      "60640\n",
      "60672\n",
      "60704\n",
      "60736\n",
      "60768\n",
      "60800\n",
      "60832\n",
      "60864\n",
      "60896\n",
      "60928\n",
      "60960\n",
      "60992\n",
      "61024\n",
      "61056\n",
      "61088\n",
      "61120\n",
      "61152\n",
      "61184\n",
      "61216\n",
      "61248\n",
      "61280\n",
      "61312\n",
      "61344\n",
      "61376\n",
      "61408\n",
      "61440\n",
      "61472\n",
      "61504\n",
      "61536\n",
      "61568\n",
      "61600\n",
      "61632\n",
      "61664\n",
      "61696\n",
      "61728\n",
      "61760\n",
      "61792\n",
      "61824\n",
      "61856\n",
      "61888\n",
      "61920\n",
      "61952\n",
      "61984\n",
      "62016\n",
      "62048\n",
      "62080\n",
      "62112\n",
      "62144\n",
      "62176\n",
      "62208\n",
      "62240\n",
      "62272\n",
      "62304\n",
      "62336\n",
      "62368\n",
      "62400\n",
      "62432\n",
      "62464\n",
      "62496\n",
      "62528\n",
      "62560\n",
      "62592\n",
      "62624\n",
      "62656\n",
      "62688\n",
      "62720\n",
      "62752\n",
      "62784\n",
      "62816\n",
      "62848\n",
      "62880\n",
      "62912\n",
      "62944\n",
      "62976\n",
      "63008\n",
      "63040\n",
      "63072\n",
      "63104\n",
      "63136\n",
      "63168\n",
      "63200\n",
      "63232\n",
      "63264\n",
      "63296\n",
      "63328\n",
      "63360\n",
      "63392\n",
      "63424\n",
      "63456\n",
      "63488\n",
      "63520\n",
      "63552\n",
      "63584\n",
      "63616\n",
      "63648\n",
      "63680\n",
      "63712\n",
      "63744\n",
      "63776\n",
      "63808\n",
      "63840\n",
      "63872\n",
      "63904\n",
      "63936\n",
      "63968\n",
      "64000\n",
      "64032\n",
      "64064\n",
      "64096\n",
      "64128\n",
      "64160\n",
      "64192\n",
      "64224\n",
      "64256\n",
      "64288\n",
      "64320\n",
      "64352\n",
      "64384\n",
      "64416\n",
      "64448\n",
      "64480\n",
      "64512\n",
      "64544\n",
      "64576\n",
      "64608\n",
      "64640\n",
      "64672\n",
      "64704\n",
      "64736\n",
      "64768\n",
      "64800\n",
      "64832\n",
      "64864\n",
      "64896\n",
      "64928\n",
      "64960\n",
      "64992\n",
      "65024\n",
      "65056\n",
      "65088\n",
      "65120\n",
      "65152\n",
      "65184\n",
      "65216\n",
      "65248\n",
      "65280\n",
      "65312\n",
      "65344\n",
      "65376\n",
      "65408\n",
      "65440\n",
      "65472\n",
      "65504\n",
      "65536\n",
      "65568\n",
      "65600\n",
      "65632\n",
      "65664\n",
      "65696\n",
      "65728\n",
      "65760\n",
      "65792\n",
      "65824\n",
      "65856\n",
      "65888\n",
      "65920\n",
      "65952\n",
      "65984\n",
      "66016\n",
      "66048\n",
      "66080\n",
      "66112\n",
      "66144\n",
      "66176\n",
      "66208\n",
      "66240\n",
      "66272\n",
      "66304\n",
      "66336\n",
      "66368\n",
      "66400\n",
      "66432\n",
      "66464\n",
      "66496\n",
      "66528\n",
      "66560\n",
      "66592\n",
      "66624\n",
      "66656\n",
      "66688\n",
      "66720\n",
      "66752\n",
      "66784\n",
      "66816\n",
      "66848\n",
      "66880\n",
      "66912\n",
      "66944\n",
      "66976\n",
      "67008\n",
      "67040\n",
      "67072\n",
      "67104\n",
      "67136\n",
      "67168\n",
      "67200\n",
      "67232\n",
      "67264\n",
      "67296\n",
      "67328\n",
      "67360\n",
      "67392\n",
      "67424\n",
      "67456\n",
      "67488\n",
      "67520\n",
      "67552\n",
      "67584\n",
      "67616\n",
      "67648\n",
      "67680\n",
      "67712\n",
      "67744\n",
      "67776\n",
      "67808\n",
      "67840\n",
      "67872\n",
      "67904\n",
      "67936\n",
      "67968\n",
      "68000\n",
      "68032\n",
      "68064\n",
      "68096\n",
      "68128\n",
      "68160\n",
      "68192\n",
      "68224\n",
      "68256\n",
      "68288\n",
      "68320\n",
      "68352\n",
      "68384\n",
      "68416\n",
      "68448\n",
      "68480\n",
      "68512\n",
      "68544\n",
      "68576\n",
      "68608\n",
      "68640\n",
      "68672\n",
      "68704\n",
      "68736\n",
      "68768\n",
      "68800\n",
      "68832\n",
      "68864\n",
      "68896\n",
      "68928\n",
      "68960\n",
      "68992\n",
      "69024\n",
      "69056\n",
      "69088\n",
      "69120\n",
      "69152\n",
      "69184\n",
      "69216\n",
      "69248\n",
      "69280\n",
      "69312\n",
      "69344\n",
      "69376\n",
      "69408\n",
      "69440\n",
      "69472\n",
      "69504\n",
      "69536\n",
      "69568\n",
      "69600\n",
      "69632\n",
      "69664\n",
      "69696\n",
      "69728\n",
      "69760\n",
      "69792\n",
      "69824\n",
      "69856\n",
      "69888\n",
      "69920\n",
      "69952\n",
      "69984\n",
      "70016\n",
      "70048\n",
      "70080\n",
      "70112\n",
      "70144\n",
      "70176\n",
      "70208\n",
      "70240\n",
      "70272\n",
      "70304\n",
      "70336\n",
      "70368\n",
      "70400\n",
      "70432\n",
      "70464\n",
      "70496\n",
      "70528\n",
      "70560\n",
      "70592\n",
      "70624\n",
      "70656\n",
      "70688\n",
      "70720\n",
      "70752\n",
      "70784\n",
      "70816\n",
      "70848\n",
      "70880\n",
      "70912\n",
      "70944\n",
      "70976\n",
      "71008\n",
      "71040\n",
      "71072\n",
      "71104\n",
      "71136\n",
      "71168\n",
      "71200\n",
      "71232\n",
      "71264\n",
      "71296\n",
      "71328\n",
      "71360\n",
      "71392\n",
      "71424\n",
      "71456\n",
      "71488\n",
      "71520\n",
      "71552\n",
      "71584\n",
      "71616\n",
      "71648\n",
      "71680\n",
      "71712\n",
      "71744\n",
      "71776\n",
      "71808\n",
      "71840\n",
      "71872\n",
      "71904\n",
      "71936\n",
      "71968\n",
      "72000\n",
      "72032\n",
      "72064\n",
      "72096\n",
      "72128\n",
      "72160\n",
      "72192\n",
      "72224\n",
      "72256\n",
      "72288\n",
      "72320\n",
      "72352\n",
      "72384\n",
      "72416\n",
      "72448\n",
      "72480\n",
      "72512\n",
      "72544\n",
      "72576\n",
      "72608\n",
      "72640\n",
      "72672\n",
      "72704\n",
      "72736\n",
      "72768\n",
      "72800\n",
      "72832\n",
      "72864\n",
      "72896\n",
      "72928\n",
      "72960\n",
      "72992\n",
      "73024\n",
      "73056\n",
      "73088\n",
      "73120\n",
      "73152\n",
      "73184\n",
      "73216\n",
      "73248\n",
      "73280\n",
      "73312\n",
      "73344\n",
      "73376\n",
      "73408\n",
      "73440\n",
      "73472\n",
      "73504\n",
      "73536\n",
      "73568\n",
      "73600\n",
      "73632\n",
      "73664\n",
      "73696\n",
      "73728\n",
      "73760\n",
      "73792\n",
      "73824\n",
      "73856\n",
      "73888\n",
      "73920\n",
      "73952\n",
      "73984\n",
      "74016\n",
      "74048\n",
      "74080\n",
      "74112\n",
      "74144\n",
      "74176\n",
      "74208\n",
      "74240\n",
      "74272\n",
      "74304\n",
      "74336\n",
      "74368\n",
      "74400\n",
      "74432\n",
      "74464\n",
      "74496\n",
      "74528\n",
      "74560\n",
      "74592\n",
      "74624\n",
      "74656\n",
      "74688\n",
      "74720\n",
      "74752\n",
      "74784\n",
      "74816\n",
      "74848\n",
      "74880\n",
      "74912\n",
      "74944\n",
      "74976\n",
      "75008\n",
      "75040\n",
      "75072\n",
      "75104\n",
      "75136\n",
      "75168\n",
      "75200\n",
      "75232\n",
      "75264\n",
      "75296\n",
      "75328\n",
      "75360\n",
      "75392\n",
      "75424\n",
      "75456\n",
      "75488\n",
      "75520\n",
      "75552\n",
      "75584\n",
      "75616\n",
      "75648\n",
      "75680\n",
      "75712\n",
      "75744\n",
      "75776\n",
      "75808\n",
      "75840\n",
      "75872\n",
      "75904\n",
      "75936\n",
      "75968\n",
      "76000\n",
      "76032\n",
      "76064\n",
      "76096\n",
      "76128\n",
      "76160\n",
      "76192\n",
      "76224\n",
      "76256\n",
      "76288\n",
      "76320\n",
      "76352\n",
      "76384\n",
      "76416\n",
      "76448\n",
      "76480\n",
      "76512\n",
      "76544\n",
      "76576\n",
      "76608\n",
      "76640\n",
      "76672\n",
      "76704\n",
      "76736\n",
      "76768\n",
      "76800\n",
      "76832\n",
      "76864\n",
      "76896\n",
      "76928\n",
      "76960\n",
      "76992\n",
      "77024\n",
      "77056\n",
      "77088\n",
      "77120\n",
      "77152\n",
      "77184\n",
      "77216\n",
      "77248\n",
      "77280\n",
      "77312\n",
      "77344\n",
      "77376\n",
      "77408\n",
      "77440\n",
      "77472\n",
      "77504\n",
      "77536\n",
      "77568\n",
      "77600\n",
      "77632\n",
      "77664\n",
      "77696\n",
      "77728\n",
      "77760\n",
      "77792\n",
      "77824\n",
      "77856\n",
      "77888\n",
      "77920\n",
      "77952\n",
      "77984\n",
      "78016\n",
      "78048\n",
      "78080\n",
      "78112\n",
      "78144\n",
      "78176\n",
      "78208\n",
      "78240\n",
      "78272\n",
      "78304\n",
      "78336\n",
      "78368\n",
      "78400\n",
      "78432\n",
      "78464\n",
      "78496\n",
      "78528\n",
      "78560\n",
      "78592\n",
      "78624\n",
      "78656\n",
      "78688\n",
      "78720\n",
      "78752\n",
      "78784\n",
      "78816\n",
      "78848\n",
      "78880\n",
      "78912\n",
      "78944\n",
      "78976\n",
      "79008\n",
      "79040\n",
      "79072\n",
      "79104\n",
      "79136\n",
      "79168\n",
      "79200\n",
      "79232\n",
      "79264\n",
      "79296\n",
      "79328\n",
      "79360\n",
      "79392\n",
      "79424\n",
      "79456\n",
      "79488\n",
      "79520\n",
      "79552\n",
      "79584\n",
      "79616\n",
      "79648\n",
      "79680\n",
      "79712\n",
      "79744\n",
      "79776\n",
      "79808\n",
      "79840\n",
      "79872\n",
      "79904\n",
      "79936\n",
      "79968\n",
      "80000\n",
      "80032\n",
      "80064\n",
      "80096\n",
      "80128\n",
      "80160\n",
      "80192\n",
      "80224\n",
      "80256\n",
      "80288\n",
      "80320\n",
      "80352\n",
      "80384\n",
      "80416\n",
      "80448\n",
      "80480\n",
      "80512\n",
      "80544\n",
      "80576\n",
      "80608\n",
      "80640\n",
      "80672\n",
      "80704\n",
      "80736\n",
      "80768\n",
      "80800\n",
      "80832\n",
      "80864\n",
      "80896\n",
      "80928\n",
      "80960\n",
      "80992\n",
      "81024\n",
      "81056\n",
      "81088\n",
      "81120\n",
      "81152\n",
      "81184\n",
      "81216\n",
      "81248\n",
      "81280\n",
      "81312\n",
      "81344\n",
      "81376\n",
      "81408\n",
      "81440\n",
      "81472\n",
      "81504\n",
      "81536\n",
      "81568\n",
      "81600\n",
      "81632\n",
      "81664\n",
      "81696\n",
      "81728\n",
      "81760\n",
      "81792\n",
      "81824\n",
      "81856\n",
      "81888\n",
      "81920\n",
      "81952\n",
      "81984\n",
      "82016\n",
      "82048\n",
      "82080\n",
      "82112\n",
      "82144\n",
      "82176\n",
      "82208\n",
      "82240\n",
      "82272\n",
      "82304\n",
      "82336\n",
      "82368\n",
      "82400\n",
      "82432\n",
      "82464\n",
      "82496\n",
      "82528\n",
      "82560\n",
      "82592\n",
      "82624\n",
      "82656\n",
      "82688\n",
      "82720\n",
      "82752\n",
      "82784\n",
      "82816\n",
      "82848\n",
      "82880\n",
      "82912\n",
      "82944\n",
      "82976\n",
      "83008\n",
      "83040\n",
      "83072\n",
      "83104\n",
      "83136\n",
      "83168\n",
      "83200\n",
      "83232\n",
      "83264\n",
      "83296\n",
      "83328\n",
      "83360\n",
      "83392\n",
      "83424\n",
      "83456\n",
      "83488\n",
      "83520\n",
      "83552\n",
      "83584\n",
      "83616\n",
      "83648\n",
      "83680\n",
      "83712\n",
      "83744\n",
      "83776\n",
      "83808\n",
      "83840\n",
      "83872\n",
      "83904\n",
      "83936\n",
      "83968\n",
      "84000\n",
      "84032\n",
      "84064\n",
      "84096\n",
      "84128\n",
      "84160\n",
      "84192\n",
      "84224\n",
      "84256\n",
      "84288\n",
      "84320\n",
      "84352\n",
      "84384\n",
      "84416\n",
      "84448\n",
      "84480\n",
      "84512\n",
      "84544\n",
      "84576\n",
      "84608\n",
      "84640\n",
      "84672\n",
      "84704\n",
      "84736\n",
      "84768\n",
      "84800\n",
      "84832\n",
      "84864\n",
      "84896\n",
      "84928\n",
      "84960\n",
      "84992\n",
      "85024\n",
      "85056\n",
      "85088\n",
      "85120\n",
      "85152\n",
      "85184\n",
      "85216\n",
      "85248\n",
      "85280\n",
      "85312\n",
      "85344\n",
      "85376\n",
      "85408\n",
      "85440\n",
      "85472\n",
      "85504\n",
      "85536\n",
      "85568\n",
      "85600\n",
      "85632\n",
      "85664\n",
      "85696\n",
      "85728\n",
      "85760\n",
      "85792\n",
      "85824\n",
      "85856\n",
      "85888\n",
      "85920\n",
      "85952\n",
      "85984\n",
      "86016\n",
      "86048\n",
      "86080\n",
      "86112\n",
      "86144\n",
      "86176\n",
      "86208\n",
      "86240\n",
      "86272\n",
      "86304\n",
      "86336\n",
      "86368\n",
      "86400\n",
      "86432\n",
      "86464\n",
      "86496\n",
      "86528\n",
      "86560\n",
      "86592\n",
      "86624\n",
      "86656\n",
      "86688\n",
      "86720\n",
      "86752\n",
      "86784\n",
      "86816\n",
      "86848\n",
      "86880\n",
      "86912\n",
      "86944\n",
      "86976\n",
      "87008\n",
      "87040\n",
      "87072\n",
      "87104\n",
      "87136\n",
      "87168\n",
      "87200\n",
      "87232\n",
      "87264\n",
      "87296\n",
      "87328\n",
      "87360\n",
      "87392\n",
      "87424\n",
      "87456\n",
      "87488\n",
      "87520\n",
      "87552\n",
      "87584\n",
      "87616\n",
      "87648\n",
      "87680\n",
      "87712\n",
      "87744\n",
      "87776\n",
      "87808\n",
      "87840\n",
      "87872\n",
      "87904\n",
      "87936\n",
      "87968\n",
      "88000\n",
      "88032\n",
      "88064\n",
      "88096\n",
      "88128\n",
      "88160\n",
      "88192\n",
      "88224\n",
      "88256\n",
      "88288\n",
      "88320\n",
      "88352\n",
      "88384\n",
      "88416\n",
      "88448\n",
      "88480\n",
      "88512\n",
      "88544\n",
      "88576\n",
      "88608\n",
      "88640\n",
      "88672\n",
      "88704\n",
      "88736\n",
      "88768\n",
      "88800\n",
      "88832\n",
      "88864\n",
      "88896\n",
      "88928\n",
      "88960\n",
      "88992\n",
      "89024\n",
      "89056\n",
      "89088\n",
      "89120\n",
      "89152\n",
      "89184\n",
      "89216\n",
      "89248\n",
      "89280\n",
      "89312\n",
      "89344\n",
      "89376\n",
      "89408\n",
      "89440\n",
      "89472\n",
      "89504\n",
      "89536\n",
      "89568\n",
      "89600\n",
      "89632\n",
      "89664\n",
      "89696\n",
      "89728\n",
      "89760\n",
      "89792\n",
      "89824\n",
      "89856\n",
      "89888\n",
      "89920\n",
      "89952\n",
      "89984\n",
      "90016\n",
      "90048\n",
      "90080\n",
      "90112\n",
      "90144\n",
      "90176\n",
      "90208\n",
      "90240\n",
      "90272\n",
      "90304\n",
      "90336\n",
      "90368\n",
      "90400\n",
      "90432\n",
      "90464\n",
      "90496\n",
      "90528\n",
      "90560\n",
      "90592\n",
      "90624\n",
      "90656\n",
      "90688\n",
      "90720\n",
      "90752\n",
      "90784\n",
      "90816\n",
      "90848\n",
      "90880\n",
      "90912\n",
      "90944\n",
      "90976\n",
      "91008\n",
      "91040\n",
      "91072\n",
      "91104\n",
      "91136\n",
      "91168\n",
      "91200\n",
      "91232\n",
      "91264\n",
      "91296\n",
      "91328\n",
      "91360\n",
      "91392\n",
      "91424\n",
      "91456\n",
      "91488\n",
      "91520\n",
      "91552\n",
      "91584\n",
      "91616\n",
      "91648\n",
      "91680\n",
      "91712\n",
      "91744\n",
      "91776\n",
      "91808\n",
      "91840\n",
      "91872\n",
      "91904\n",
      "91936\n",
      "91968\n",
      "92000\n",
      "92032\n",
      "92064\n",
      "92096\n",
      "92128\n",
      "92160\n",
      "92192\n",
      "92224\n",
      "92256\n",
      "92288\n",
      "92320\n",
      "92352\n",
      "92384\n",
      "92416\n",
      "92448\n",
      "92480\n",
      "92512\n",
      "92544\n",
      "92576\n",
      "92608\n",
      "92640\n",
      "92672\n",
      "92704\n",
      "92736\n",
      "92768\n",
      "92800\n",
      "92832\n",
      "92864\n",
      "92896\n",
      "92928\n",
      "92960\n",
      "92992\n",
      "93024\n",
      "93056\n",
      "93088\n",
      "93120\n",
      "93152\n",
      "93184\n",
      "93216\n",
      "93248\n",
      "93280\n",
      "93312\n",
      "93344\n",
      "93376\n",
      "93408\n",
      "93440\n",
      "93472\n",
      "93504\n",
      "93536\n",
      "93568\n",
      "93600\n",
      "93632\n",
      "93664\n",
      "93696\n",
      "93728\n",
      "93760\n",
      "93792\n",
      "93824\n",
      "93856\n",
      "93888\n",
      "93920\n",
      "93952\n",
      "93984\n",
      "94016\n",
      "94048\n",
      "94080\n",
      "94112\n",
      "94144\n",
      "94176\n",
      "94208\n",
      "94240\n",
      "94272\n",
      "94304\n",
      "94336\n",
      "94368\n",
      "94400\n",
      "94432\n",
      "94464\n",
      "94496\n",
      "94528\n",
      "94560\n",
      "94592\n",
      "94624\n",
      "94656\n",
      "94688\n",
      "94720\n",
      "94752\n",
      "94784\n",
      "94816\n",
      "94848\n",
      "94880\n",
      "94912\n",
      "94944\n",
      "94976\n",
      "95008\n",
      "95040\n",
      "95072\n",
      "95104\n",
      "95136\n",
      "95168\n",
      "95200\n",
      "95232\n",
      "95264\n",
      "95296\n",
      "95328\n",
      "95360\n",
      "95392\n",
      "95424\n",
      "95456\n",
      "95488\n",
      "95520\n",
      "95552\n",
      "95584\n",
      "95616\n",
      "95648\n",
      "95680\n",
      "95712\n",
      "95744\n",
      "95776\n",
      "95808\n",
      "95840\n",
      "95872\n",
      "95904\n",
      "95936\n",
      "95968\n",
      "96000\n",
      "96032\n",
      "96064\n",
      "96096\n",
      "96128\n",
      "96160\n",
      "96192\n",
      "96224\n",
      "96256\n",
      "96288\n",
      "96320\n",
      "96352\n",
      "96384\n",
      "96416\n",
      "96448\n",
      "96480\n",
      "96512\n",
      "96544\n",
      "96576\n",
      "96608\n",
      "96640\n",
      "96672\n",
      "96704\n",
      "96736\n",
      "96768\n",
      "96800\n",
      "96832\n",
      "96864\n",
      "96896\n",
      "96928\n",
      "96960\n",
      "96992\n",
      "97024\n",
      "97056\n",
      "97088\n",
      "97120\n",
      "97152\n",
      "97184\n",
      "97216\n",
      "97248\n",
      "97280\n",
      "97312\n",
      "97344\n",
      "97376\n",
      "97408\n",
      "97440\n",
      "97472\n",
      "97504\n",
      "97536\n",
      "97568\n",
      "97600\n",
      "97632\n",
      "97664\n",
      "97696\n",
      "97728\n",
      "97760\n",
      "97792\n",
      "97824\n",
      "97856\n",
      "97888\n",
      "97920\n",
      "97952\n",
      "97984\n",
      "98016\n",
      "98048\n",
      "98080\n",
      "98112\n",
      "98144\n",
      "98176\n",
      "98208\n",
      "98240\n",
      "98272\n",
      "98304\n",
      "98336\n",
      "98368\n",
      "98400\n",
      "98432\n",
      "98464\n",
      "98496\n",
      "98528\n",
      "98560\n",
      "98592\n",
      "98624\n",
      "98656\n",
      "98688\n",
      "98720\n",
      "98752\n",
      "98784\n",
      "98816\n",
      "98848\n",
      "98880\n",
      "98912\n",
      "98944\n",
      "98976\n",
      "99008\n",
      "99040\n",
      "99072\n",
      "99104\n",
      "99136\n",
      "99168\n",
      "99200\n",
      "99232\n",
      "99264\n",
      "99296\n",
      "99328\n",
      "99360\n",
      "99392\n",
      "99424\n",
      "99456\n",
      "99488\n",
      "99520\n",
      "99552\n",
      "99584\n",
      "99616\n",
      "99648\n",
      "99680\n",
      "99712\n",
      "99744\n",
      "99776\n",
      "99808\n",
      "99840\n",
      "99872\n",
      "99904\n",
      "99936\n",
      "99968\n",
      "100000\n",
      "100032\n",
      "100064\n",
      "100096\n",
      "100128\n",
      "100160\n",
      "100192\n",
      "100224\n",
      "100256\n",
      "100288\n",
      "100320\n",
      "100352\n",
      "100384\n",
      "100416\n",
      "100448\n",
      "100480\n",
      "100512\n",
      "100544\n",
      "100576\n",
      "100608\n",
      "100640\n",
      "100672\n",
      "100704\n",
      "100736\n",
      "100768\n",
      "100800\n",
      "100832\n",
      "100864\n",
      "100896\n",
      "100928\n",
      "100960\n",
      "100992\n",
      "101024\n",
      "101056\n",
      "101088\n",
      "101120\n",
      "101152\n",
      "101184\n",
      "101216\n",
      "101248\n",
      "101280\n",
      "101312\n",
      "101344\n",
      "101376\n",
      "101408\n",
      "101440\n",
      "101472\n",
      "101504\n",
      "101536\n",
      "101568\n",
      "101600\n",
      "101632\n",
      "101664\n",
      "101696\n",
      "101728\n",
      "101760\n",
      "101792\n",
      "101824\n",
      "101856\n",
      "101888\n",
      "101920\n",
      "101952\n",
      "101984\n",
      "102016\n",
      "102048\n",
      "102080\n",
      "102112\n",
      "102144\n",
      "102176\n",
      "102208\n",
      "102240\n",
      "102272\n",
      "102304\n",
      "102336\n",
      "102368\n",
      "102400\n",
      "102432\n",
      "102464\n",
      "102496\n",
      "102528\n",
      "102560\n",
      "102592\n",
      "102624\n",
      "102656\n",
      "102688\n",
      "102720\n",
      "102752\n",
      "102784\n",
      "102816\n",
      "102848\n",
      "102880\n",
      "102912\n",
      "102944\n",
      "102976\n",
      "103008\n",
      "103040\n",
      "103072\n",
      "103104\n",
      "103136\n",
      "103168\n",
      "103200\n",
      "103232\n",
      "103264\n",
      "103296\n",
      "103328\n",
      "103360\n",
      "103392\n",
      "103424\n",
      "103456\n",
      "103488\n",
      "103520\n",
      "103552\n",
      "103584\n",
      "103616\n",
      "103648\n",
      "103680\n",
      "103712\n",
      "103744\n",
      "103776\n",
      "103808\n",
      "103840\n",
      "103872\n",
      "103904\n",
      "103936\n",
      "103968\n",
      "104000\n",
      "104032\n",
      "104064\n",
      "104096\n",
      "104128\n",
      "104160\n",
      "104192\n",
      "104224\n",
      "104256\n",
      "104288\n",
      "104320\n",
      "104352\n",
      "104384\n",
      "104416\n",
      "104448\n",
      "104480\n",
      "104512\n",
      "104544\n",
      "104576\n",
      "104608\n",
      "104640\n",
      "104672\n",
      "104704\n",
      "104736\n",
      "104768\n",
      "104800\n",
      "104832\n",
      "104864\n",
      "104896\n",
      "104928\n",
      "104960\n",
      "104992\n",
      "105024\n",
      "105056\n",
      "105088\n",
      "105120\n",
      "105152\n",
      "105184\n",
      "105216\n",
      "105248\n",
      "105280\n",
      "105312\n",
      "105344\n",
      "105376\n",
      "105408\n",
      "105440\n",
      "105472\n",
      "105504\n",
      "105536\n",
      "105568\n",
      "105600\n",
      "105632\n",
      "105664\n",
      "105696\n",
      "105728\n",
      "105760\n",
      "105792\n",
      "105824\n",
      "105856\n",
      "105888\n",
      "105920\n",
      "105952\n",
      "105984\n",
      "106016\n",
      "106048\n",
      "106080\n",
      "106112\n",
      "106144\n",
      "106176\n",
      "106208\n",
      "106240\n",
      "106272\n",
      "106304\n",
      "106336\n",
      "106368\n",
      "106400\n",
      "106432\n",
      "106464\n",
      "106496\n",
      "106528\n",
      "106560\n",
      "106592\n",
      "106624\n",
      "106656\n",
      "106688\n",
      "106720\n",
      "106752\n",
      "106784\n",
      "106816\n",
      "106848\n",
      "106880\n",
      "106912\n",
      "106944\n",
      "106976\n",
      "107008\n",
      "107040\n",
      "107072\n",
      "107104\n",
      "107136\n",
      "107168\n",
      "107200\n",
      "107232\n",
      "107264\n",
      "107296\n",
      "107328\n",
      "107360\n",
      "107392\n",
      "107424\n",
      "107456\n",
      "107488\n",
      "107520\n",
      "107552\n",
      "107584\n",
      "107616\n",
      "107648\n",
      "107680\n",
      "107712\n",
      "107744\n",
      "107776\n",
      "107808\n",
      "107840\n",
      "107872\n",
      "107904\n",
      "107936\n",
      "107968\n",
      "108000\n",
      "108032\n",
      "108064\n",
      "108096\n",
      "108128\n",
      "108160\n",
      "108192\n",
      "108224\n",
      "108256\n",
      "108288\n",
      "108320\n",
      "108352\n",
      "108384\n",
      "108416\n",
      "108448\n",
      "108480\n",
      "108512\n",
      "108544\n",
      "108576\n",
      "108608\n",
      "108640\n",
      "108672\n",
      "108704\n",
      "108736\n",
      "108768\n",
      "108800\n",
      "108832\n",
      "108864\n",
      "108896\n",
      "108928\n",
      "108960\n",
      "108992\n",
      "109024\n",
      "109056\n",
      "109088\n",
      "109120\n",
      "109152\n",
      "109184\n",
      "109216\n",
      "109248\n",
      "109280\n",
      "109312\n",
      "109344\n",
      "109376\n",
      "109408\n",
      "109440\n",
      "109472\n",
      "109504\n",
      "109536\n",
      "109568\n",
      "109600\n",
      "109632\n",
      "109664\n",
      "109696\n",
      "109728\n",
      "109760\n",
      "109792\n",
      "109824\n",
      "109856\n",
      "109888\n",
      "109920\n",
      "109952\n",
      "109984\n",
      "110016\n",
      "110048\n",
      "110080\n",
      "110112\n",
      "110144\n",
      "110176\n",
      "110208\n",
      "110240\n",
      "110272\n",
      "110304\n",
      "110336\n",
      "110368\n",
      "110400\n",
      "110432\n",
      "110464\n",
      "110496\n",
      "110528\n",
      "110560\n",
      "110592\n",
      "110624\n",
      "110656\n",
      "110688\n",
      "110720\n",
      "110752\n",
      "110784\n",
      "110816\n",
      "110848\n",
      "110880\n",
      "110912\n",
      "110944\n",
      "110976\n",
      "111008\n",
      "111040\n",
      "111072\n",
      "111104\n",
      "111136\n",
      "111168\n",
      "111200\n",
      "111232\n",
      "111264\n",
      "111296\n",
      "111328\n",
      "111360\n",
      "111392\n",
      "111424\n",
      "111456\n",
      "111488\n",
      "111520\n",
      "111552\n",
      "111584\n",
      "111616\n",
      "111648\n",
      "111680\n",
      "111712\n",
      "111744\n",
      "111776\n",
      "111808\n",
      "111840\n",
      "111872\n",
      "111904\n",
      "111936\n",
      "111968\n",
      "112000\n",
      "112032\n",
      "112064\n",
      "112096\n",
      "112128\n",
      "112160\n",
      "112192\n",
      "112224\n",
      "112256\n",
      "112288\n",
      "112320\n",
      "112352\n",
      "112384\n",
      "112416\n",
      "112448\n",
      "112480\n",
      "112512\n",
      "112544\n",
      "112576\n",
      "112608\n",
      "112640\n",
      "112672\n",
      "112704\n",
      "112736\n",
      "112768\n",
      "112800\n",
      "112832\n",
      "112864\n",
      "112896\n",
      "112928\n",
      "112960\n",
      "112992\n",
      "113024\n",
      "113056\n",
      "113088\n",
      "113120\n",
      "113152\n",
      "113184\n",
      "113216\n",
      "113248\n",
      "113280\n",
      "113312\n",
      "113344\n",
      "113376\n",
      "113408\n",
      "113440\n",
      "113472\n",
      "113504\n",
      "113536\n",
      "113568\n",
      "113600\n",
      "113632\n",
      "113664\n",
      "113696\n",
      "113728\n",
      "113760\n",
      "113792\n",
      "113824\n",
      "113856\n",
      "113888\n",
      "113920\n",
      "113952\n",
      "113984\n",
      "114016\n",
      "114048\n",
      "114080\n",
      "114112\n",
      "114144\n",
      "114176\n",
      "114208\n",
      "114240\n",
      "114272\n",
      "114304\n",
      "114336\n",
      "114368\n",
      "114400\n",
      "114432\n",
      "114464\n",
      "114496\n",
      "114528\n",
      "114560\n",
      "114592\n",
      "114624\n",
      "114656\n",
      "114688\n",
      "114720\n",
      "114752\n",
      "114784\n",
      "114816\n",
      "114848\n",
      "114880\n",
      "114912\n",
      "114944\n",
      "114976\n",
      "115008\n",
      "115040\n",
      "115072\n",
      "115104\n",
      "115136\n",
      "115168\n",
      "115200\n",
      "115232\n",
      "115264\n",
      "115296\n",
      "115328\n",
      "115360\n",
      "115392\n",
      "115424\n",
      "115456\n",
      "115488\n",
      "115520\n",
      "115552\n",
      "115584\n",
      "115616\n",
      "115648\n",
      "115680\n",
      "115712\n",
      "115744\n",
      "115776\n",
      "115808\n",
      "115840\n",
      "115872\n",
      "115904\n",
      "115936\n",
      "115968\n",
      "116000\n",
      "116032\n",
      "116064\n",
      "116096\n",
      "116128\n",
      "116160\n",
      "116192\n",
      "116224\n",
      "116256\n",
      "116288\n",
      "116320\n",
      "116352\n",
      "116384\n",
      "116416\n",
      "116448\n",
      "116480\n",
      "116512\n",
      "116544\n",
      "116576\n",
      "116608\n",
      "116640\n",
      "116672\n",
      "116704\n",
      "116736\n",
      "116768\n",
      "116800\n",
      "116832\n",
      "116864\n",
      "116896\n",
      "116928\n",
      "116960\n",
      "116992\n",
      "117024\n",
      "117056\n",
      "117088\n",
      "117120\n",
      "117152\n",
      "117184\n",
      "117216\n",
      "117248\n",
      "117280\n",
      "117312\n",
      "117344\n",
      "117376\n",
      "117408\n",
      "117440\n",
      "117472\n",
      "117504\n",
      "117536\n",
      "117568\n",
      "117600\n",
      "117632\n",
      "117664\n",
      "117696\n",
      "117728\n",
      "117760\n",
      "117792\n",
      "117824\n",
      "117856\n",
      "117888\n",
      "117920\n",
      "117952\n",
      "117984\n",
      "118016\n",
      "118048\n",
      "118080\n",
      "118112\n",
      "118144\n",
      "118176\n",
      "118208\n",
      "118240\n",
      "118272\n",
      "118304\n",
      "118336\n",
      "118368\n",
      "118400\n",
      "118432\n",
      "118464\n",
      "118496\n",
      "118528\n",
      "118560\n",
      "118592\n",
      "118624\n",
      "118656\n",
      "118688\n",
      "118720\n",
      "118752\n",
      "118784\n",
      "118816\n",
      "118848\n",
      "118880\n",
      "118912\n",
      "118944\n",
      "118976\n",
      "119008\n",
      "119040\n",
      "119072\n",
      "119104\n",
      "119136\n",
      "119168\n",
      "119200\n",
      "119232\n",
      "119264\n",
      "119296\n",
      "119328\n",
      "119360\n",
      "119392\n",
      "119424\n",
      "119456\n",
      "119488\n",
      "119520\n",
      "119552\n",
      "119584\n",
      "119616\n",
      "119648\n",
      "119680\n",
      "119712\n",
      "119744\n",
      "119776\n",
      "119808\n",
      "119840\n",
      "119872\n",
      "119904\n",
      "119936\n",
      "119968\n",
      "120000\n",
      "120032\n",
      "120064\n",
      "120096\n",
      "120128\n",
      "120160\n",
      "120192\n",
      "120224\n",
      "120256\n",
      "120288\n",
      "120320\n",
      "120352\n",
      "120384\n",
      "120416\n",
      "120448\n",
      "120480\n",
      "120512\n",
      "120544\n",
      "120576\n",
      "120608\n",
      "120640\n",
      "120672\n",
      "120704\n",
      "120736\n",
      "120768\n",
      "120800\n",
      "120832\n",
      "120864\n",
      "120896\n",
      "120928\n",
      "120960\n",
      "120992\n",
      "121024\n",
      "121056\n",
      "121088\n",
      "121120\n",
      "121152\n",
      "121184\n",
      "121216\n",
      "121248\n",
      "121280\n",
      "121312\n",
      "121344\n",
      "121376\n",
      "121408\n",
      "121440\n",
      "121472\n",
      "121504\n",
      "121536\n",
      "121568\n",
      "121600\n",
      "121632\n",
      "121664\n",
      "121696\n",
      "121728\n",
      "121760\n",
      "121792\n",
      "121824\n",
      "121856\n",
      "121888\n",
      "121920\n",
      "121952\n",
      "121984\n",
      "122016\n",
      "122048\n",
      "122080\n",
      "122112\n",
      "122144\n",
      "122176\n",
      "122208\n",
      "122240\n",
      "122272\n",
      "122304\n",
      "122336\n",
      "122368\n",
      "122400\n",
      "122432\n",
      "122464\n",
      "122496\n",
      "122528\n",
      "122560\n",
      "122592\n",
      "122624\n",
      "122656\n",
      "122688\n",
      "122720\n",
      "122752\n",
      "122784\n",
      "122816\n",
      "122848\n",
      "122880\n",
      "122912\n",
      "122944\n",
      "122976\n",
      "123008\n",
      "123040\n",
      "123072\n",
      "123104\n",
      "123136\n",
      "123168\n",
      "123200\n",
      "123232\n",
      "123264\n",
      "123296\n",
      "123328\n",
      "123360\n",
      "123392\n",
      "123424\n",
      "123456\n",
      "123488\n",
      "123520\n",
      "123552\n",
      "123584\n",
      "123616\n",
      "123648\n",
      "123680\n",
      "123712\n",
      "123744\n",
      "123776\n",
      "123808\n",
      "123840\n",
      "123872\n",
      "123904\n",
      "123936\n",
      "123968\n",
      "124000\n",
      "124032\n",
      "124064\n",
      "124096\n",
      "124128\n",
      "124160\n",
      "124192\n",
      "124224\n",
      "124256\n",
      "124288\n",
      "124320\n",
      "124352\n",
      "124384\n",
      "124416\n",
      "124448\n",
      "124480\n",
      "124512\n",
      "124544\n",
      "124576\n",
      "124608\n",
      "124640\n",
      "124672\n",
      "124704\n",
      "124736\n",
      "124768\n",
      "124800\n",
      "124832\n",
      "124864\n",
      "124896\n",
      "124928\n",
      "124960\n",
      "124992\n",
      "125024\n",
      "125056\n",
      "125088\n",
      "125120\n",
      "125152\n",
      "125184\n",
      "125216\n",
      "125248\n",
      "125280\n",
      "125312\n",
      "125344\n",
      "125376\n",
      "125408\n",
      "125440\n",
      "125472\n",
      "125504\n",
      "125536\n",
      "125568\n",
      "125600\n",
      "125632\n",
      "125664\n",
      "125696\n",
      "125728\n",
      "125760\n",
      "125792\n",
      "125824\n",
      "125856\n",
      "125888\n",
      "125920\n",
      "125952\n",
      "125984\n",
      "126016\n",
      "126048\n",
      "126080\n",
      "126112\n",
      "126144\n",
      "126176\n",
      "126208\n",
      "126240\n",
      "126272\n",
      "126304\n",
      "126336\n",
      "126368\n",
      "126400\n",
      "126432\n",
      "126464\n",
      "126496\n",
      "126528\n",
      "126560\n",
      "126592\n",
      "126624\n",
      "126656\n",
      "126688\n",
      "126720\n",
      "126752\n",
      "126784\n",
      "126816\n",
      "126848\n",
      "126880\n",
      "126912\n",
      "126944\n",
      "126976\n",
      "127008\n",
      "127040\n",
      "127072\n",
      "127104\n",
      "127136\n",
      "127168\n",
      "127200\n",
      "127232\n",
      "127264\n",
      "127296\n",
      "127328\n",
      "127360\n",
      "127392\n",
      "127424\n",
      "127456\n",
      "127488\n",
      "127520\n",
      "127552\n",
      "127584\n",
      "127616\n",
      "127648\n",
      "127680\n",
      "127712\n",
      "127744\n",
      "127776\n",
      "127808\n",
      "127840\n",
      "127872\n",
      "127904\n",
      "127936\n",
      "127968\n",
      "128000\n",
      "128032\n",
      "128064\n",
      "128096\n",
      "128128\n",
      "128160\n",
      "128192\n",
      "128224\n",
      "128256\n",
      "128288\n",
      "128320\n",
      "128352\n",
      "128384\n",
      "128416\n",
      "128448\n",
      "128480\n",
      "128512\n",
      "128544\n",
      "128576\n",
      "128608\n",
      "128640\n",
      "128672\n",
      "128704\n",
      "128736\n",
      "128768\n",
      "128800\n",
      "128832\n",
      "128864\n",
      "128896\n",
      "128928\n",
      "128960\n",
      "128992\n",
      "129024\n",
      "129056\n",
      "129088\n",
      "129120\n",
      "129152\n",
      "129184\n",
      "129216\n",
      "129248\n",
      "129280\n",
      "129312\n",
      "129344\n",
      "129376\n",
      "129408\n",
      "129440\n",
      "129472\n",
      "129504\n",
      "129536\n",
      "129568\n",
      "129600\n",
      "129632\n",
      "129664\n",
      "129696\n",
      "129728\n",
      "129760\n",
      "129792\n",
      "129824\n",
      "129856\n",
      "129888\n",
      "129920\n",
      "129952\n",
      "129984\n",
      "130016\n",
      "130048\n",
      "130080\n",
      "130112\n",
      "130144\n",
      "130176\n",
      "130208\n",
      "130240\n",
      "130272\n",
      "130304\n",
      "130336\n",
      "130368\n",
      "130400\n",
      "130432\n",
      "130464\n",
      "130496\n",
      "130528\n",
      "130560\n",
      "130592\n",
      "130624\n",
      "130656\n",
      "130688\n",
      "130720\n",
      "130752\n",
      "130784\n",
      "130816\n",
      "130848\n",
      "130880\n",
      "130912\n",
      "130944\n",
      "130976\n",
      "131008\n",
      "131040\n",
      "131072\n",
      "131104\n",
      "131136\n",
      "131168\n",
      "131200\n",
      "131232\n",
      "131264\n",
      "131296\n",
      "131328\n",
      "131360\n",
      "131392\n",
      "131424\n",
      "131456\n",
      "131488\n",
      "131520\n",
      "131552\n",
      "131584\n",
      "131616\n",
      "131648\n",
      "131680\n",
      "131712\n",
      "131744\n",
      "131776\n",
      "131808\n",
      "131840\n",
      "131872\n",
      "131904\n",
      "131936\n",
      "131968\n",
      "132000\n",
      "132032\n",
      "132064\n",
      "132096\n",
      "132128\n",
      "132160\n",
      "132192\n",
      "132224\n",
      "132256\n",
      "132288\n",
      "132320\n",
      "132352\n",
      "132384\n",
      "132416\n",
      "132448\n",
      "132480\n",
      "132512\n",
      "132544\n",
      "132576\n",
      "132608\n",
      "132640\n",
      "132672\n",
      "132704\n",
      "132736\n",
      "132768\n",
      "132800\n",
      "132832\n",
      "132864\n",
      "132896\n",
      "132928\n",
      "132960\n",
      "132992\n",
      "133024\n",
      "133056\n",
      "133088\n",
      "133120\n",
      "133152\n",
      "133184\n",
      "133216\n",
      "133248\n",
      "133280\n",
      "133312\n",
      "133344\n",
      "133376\n",
      "133408\n",
      "133440\n",
      "133472\n",
      "133504\n",
      "133536\n",
      "133568\n",
      "133600\n",
      "133632\n",
      "133664\n",
      "133696\n",
      "133728\n",
      "133760\n",
      "133792\n",
      "133824\n",
      "133856\n",
      "133888\n",
      "133920\n",
      "133952\n",
      "133984\n",
      "134016\n",
      "134048\n",
      "134080\n",
      "134112\n",
      "134144\n",
      "134176\n",
      "134208\n",
      "134240\n",
      "134272\n",
      "134304\n",
      "134336\n",
      "134368\n",
      "134400\n",
      "134432\n",
      "134464\n",
      "134496\n",
      "134528\n",
      "134560\n",
      "134592\n",
      "134624\n",
      "134656\n",
      "134688\n",
      "134720\n",
      "134752\n",
      "134784\n",
      "134816\n",
      "134848\n",
      "134880\n",
      "134912\n",
      "134944\n",
      "134976\n",
      "135008\n",
      "135040\n",
      "135072\n",
      "135104\n",
      "135136\n",
      "135168\n",
      "135200\n",
      "135232\n",
      "135264\n",
      "135296\n",
      "135328\n",
      "135360\n",
      "135392\n",
      "135424\n",
      "135456\n",
      "135488\n",
      "135520\n",
      "135552\n",
      "135584\n",
      "135616\n",
      "135648\n",
      "135680\n",
      "135712\n",
      "135744\n",
      "135776\n",
      "135808\n",
      "135840\n",
      "135872\n",
      "135904\n",
      "135936\n",
      "135968\n",
      "136000\n",
      "136032\n",
      "136064\n",
      "136096\n",
      "136128\n",
      "136160\n",
      "136192\n",
      "136224\n",
      "136256\n",
      "136288\n",
      "136320\n",
      "136352\n",
      "136384\n",
      "136416\n",
      "136448\n",
      "136480\n",
      "136512\n",
      "136544\n",
      "136576\n",
      "136608\n",
      "136640\n",
      "136672\n",
      "136704\n",
      "136736\n",
      "136768\n",
      "136800\n",
      "136832\n",
      "136864\n",
      "136896\n",
      "136928\n",
      "136960\n",
      "136992\n",
      "137024\n",
      "137056\n",
      "137088\n",
      "137120\n",
      "137152\n",
      "137184\n",
      "137216\n",
      "137248\n",
      "137280\n",
      "137312\n",
      "137344\n",
      "137376\n",
      "137408\n",
      "137440\n",
      "137472\n",
      "137504\n",
      "137536\n",
      "137568\n",
      "137600\n",
      "137632\n",
      "137664\n",
      "137696\n",
      "137728\n",
      "137760\n",
      "137792\n",
      "137824\n",
      "137856\n",
      "137888\n",
      "137920\n",
      "137952\n",
      "137984\n",
      "138016\n",
      "138048\n",
      "138080\n",
      "138112\n",
      "138144\n",
      "138176\n",
      "138208\n",
      "138240\n",
      "138272\n",
      "138304\n",
      "138336\n",
      "138368\n",
      "138400\n",
      "138432\n",
      "138464\n",
      "138496\n",
      "138528\n",
      "138560\n",
      "138592\n",
      "138624\n",
      "138656\n",
      "138688\n",
      "138720\n",
      "138752\n",
      "138784\n",
      "138816\n",
      "138848\n",
      "138880\n",
      "138912\n",
      "138944\n",
      "138976\n",
      "139008\n",
      "139040\n",
      "139072\n",
      "139104\n",
      "139136\n",
      "139168\n",
      "139200\n",
      "139232\n",
      "139264\n",
      "139296\n",
      "139328\n",
      "139360\n",
      "139392\n",
      "139424\n",
      "139456\n",
      "139488\n",
      "139520\n",
      "139552\n",
      "139584\n",
      "139616\n",
      "139648\n",
      "139680\n",
      "139712\n",
      "139744\n",
      "139776\n",
      "139808\n",
      "139840\n",
      "139872\n",
      "139904\n",
      "139936\n",
      "139968\n",
      "140000\n",
      "140032\n",
      "140064\n",
      "140096\n",
      "140128\n",
      "140160\n",
      "140192\n",
      "140224\n",
      "140256\n",
      "140288\n",
      "140320\n",
      "140352\n",
      "140384\n",
      "140416\n",
      "140448\n",
      "140480\n",
      "140512\n",
      "140544\n",
      "140576\n",
      "140608\n",
      "140640\n",
      "140672\n",
      "140704\n",
      "140736\n",
      "140768\n",
      "140800\n",
      "140832\n",
      "140864\n",
      "140896\n",
      "140928\n",
      "140960\n",
      "140992\n",
      "141024\n",
      "141056\n",
      "141088\n",
      "141120\n",
      "141152\n",
      "141184\n",
      "141216\n",
      "141248\n",
      "141280\n",
      "141312\n",
      "141344\n",
      "141376\n",
      "141408\n",
      "141440\n",
      "141472\n",
      "141504\n",
      "141536\n",
      "141568\n",
      "141600\n",
      "141632\n",
      "141664\n",
      "141696\n",
      "141728\n",
      "141760\n",
      "141792\n",
      "141824\n",
      "141856\n",
      "141888\n",
      "141920\n",
      "141952\n",
      "141984\n",
      "142016\n",
      "142048\n",
      "142080\n",
      "142112\n",
      "142144\n",
      "142176\n",
      "142208\n",
      "142240\n",
      "142272\n",
      "142304\n",
      "142336\n",
      "142368\n",
      "142400\n",
      "142432\n",
      "142464\n",
      "142496\n",
      "142528\n",
      "142560\n",
      "142592\n",
      "142624\n",
      "142656\n",
      "142688\n",
      "142720\n",
      "142752\n",
      "142784\n",
      "142816\n",
      "142848\n",
      "142880\n",
      "142912\n",
      "142944\n",
      "142976\n",
      "143008\n",
      "143040\n",
      "143072\n",
      "143104\n",
      "143136\n",
      "143168\n",
      "143200\n",
      "143232\n",
      "143264\n",
      "143296\n",
      "143328\n",
      "143360\n",
      "143392\n",
      "143424\n",
      "143456\n",
      "143488\n",
      "143520\n",
      "143552\n",
      "143584\n",
      "143616\n",
      "143648\n",
      "143680\n",
      "143712\n",
      "143744\n",
      "143776\n",
      "143808\n",
      "143840\n",
      "143872\n",
      "143904\n",
      "143936\n",
      "143968\n",
      "144000\n",
      "144032\n",
      "144064\n",
      "144096\n",
      "144128\n",
      "144160\n",
      "144192\n",
      "144224\n",
      "144256\n",
      "144288\n",
      "144320\n",
      "144352\n",
      "144384\n",
      "144416\n",
      "144448\n",
      "144480\n",
      "144512\n",
      "144544\n",
      "144576\n",
      "144608\n",
      "144640\n",
      "144672\n",
      "144704\n",
      "144736\n",
      "144768\n",
      "144800\n",
      "144832\n",
      "144864\n",
      "144896\n",
      "144928\n",
      "144960\n",
      "144992\n",
      "145024\n",
      "145056\n",
      "145088\n",
      "145120\n",
      "145152\n",
      "145184\n",
      "145216\n",
      "145248\n",
      "145280\n",
      "145312\n",
      "145344\n",
      "145376\n",
      "145408\n",
      "145440\n",
      "145472\n",
      "145504\n",
      "145536\n",
      "145568\n",
      "145600\n",
      "145632\n",
      "145664\n",
      "145696\n",
      "145728\n",
      "145760\n",
      "145792\n",
      "145824\n",
      "145856\n",
      "145888\n",
      "145920\n",
      "145952\n",
      "145984\n",
      "146016\n",
      "146048\n",
      "146080\n",
      "146112\n",
      "146144\n",
      "146176\n",
      "146208\n",
      "146240\n",
      "146272\n",
      "146304\n",
      "146336\n",
      "146368\n",
      "146400\n",
      "146432\n",
      "146464\n",
      "146496\n",
      "146528\n",
      "146560\n",
      "146592\n",
      "146624\n",
      "146656\n",
      "146688\n",
      "146720\n",
      "146752\n",
      "146784\n",
      "146816\n",
      "146848\n",
      "146880\n",
      "146912\n",
      "146944\n",
      "146976\n",
      "147008\n",
      "147040\n",
      "147072\n",
      "147104\n",
      "147136\n",
      "147168\n",
      "147200\n",
      "147232\n",
      "147264\n",
      "147296\n",
      "147328\n",
      "147360\n",
      "147392\n",
      "147424\n",
      "147456\n",
      "147488\n",
      "147520\n",
      "147552\n",
      "147584\n",
      "147616\n",
      "147648\n",
      "147680\n",
      "147712\n",
      "147744\n",
      "147776\n",
      "147808\n",
      "147840\n",
      "147872\n",
      "147904\n",
      "147936\n",
      "147968\n",
      "148000\n",
      "148032\n",
      "148064\n",
      "148096\n",
      "148128\n",
      "148160\n",
      "148192\n",
      "148224\n",
      "148256\n",
      "148288\n",
      "148320\n",
      "148352\n",
      "148384\n",
      "148416\n",
      "148448\n",
      "148480\n",
      "148512\n",
      "148544\n",
      "148576\n",
      "148608\n",
      "148640\n",
      "148672\n",
      "148704\n",
      "148736\n",
      "148768\n",
      "148800\n",
      "148832\n",
      "148864\n",
      "148896\n",
      "148928\n",
      "148960\n",
      "148992\n",
      "149024\n",
      "149056\n",
      "149088\n",
      "149120\n",
      "149152\n",
      "149184\n",
      "149216\n",
      "149248\n",
      "149280\n",
      "149312\n",
      "149344\n",
      "149376\n",
      "149408\n",
      "149440\n",
      "149472\n",
      "149504\n",
      "149536\n",
      "149568\n",
      "149600\n",
      "149632\n",
      "149664\n",
      "149696\n",
      "149728\n",
      "149760\n",
      "149792\n",
      "149824\n",
      "149856\n",
      "149888\n",
      "149920\n",
      "149952\n",
      "149984\n",
      "150016\n",
      "150048\n",
      "150080\n",
      "150112\n",
      "150144\n",
      "150176\n",
      "150208\n",
      "150240\n",
      "150272\n",
      "150304\n",
      "150336\n",
      "150368\n",
      "150400\n",
      "150432\n",
      "150464\n",
      "150496\n",
      "150528\n",
      "150560\n",
      "150592\n",
      "150624\n",
      "150656\n",
      "150688\n",
      "150720\n",
      "150752\n",
      "150784\n",
      "150816\n",
      "150848\n",
      "150880\n",
      "150912\n",
      "150944\n",
      "150976\n",
      "151008\n",
      "151040\n",
      "151072\n",
      "151104\n",
      "151136\n",
      "151168\n",
      "151200\n",
      "151232\n",
      "151264\n",
      "151296\n",
      "151328\n",
      "151360\n",
      "151392\n",
      "151424\n",
      "151456\n",
      "151488\n",
      "151520\n",
      "151552\n",
      "151584\n",
      "151616\n",
      "151648\n",
      "151680\n",
      "151712\n",
      "151744\n",
      "151776\n",
      "151808\n",
      "151840\n",
      "151872\n",
      "151904\n",
      "151936\n",
      "151968\n",
      "152000\n",
      "152032\n",
      "152064\n",
      "152096\n",
      "152128\n",
      "152160\n",
      "152192\n",
      "152224\n",
      "152256\n",
      "152288\n",
      "152320\n",
      "152352\n",
      "152384\n",
      "152416\n",
      "152448\n",
      "152480\n",
      "152512\n",
      "152544\n",
      "152576\n",
      "152608\n",
      "152640\n",
      "152672\n",
      "152704\n",
      "152736\n",
      "152768\n",
      "152800\n",
      "152832\n",
      "152864\n",
      "152896\n",
      "152928\n",
      "152960\n",
      "152992\n",
      "153024\n",
      "153056\n",
      "153088\n",
      "153120\n",
      "153152\n",
      "153184\n",
      "153216\n",
      "153248\n",
      "153280\n",
      "153312\n",
      "153344\n",
      "153376\n",
      "153408\n",
      "153440\n",
      "153472\n",
      "153504\n",
      "153536\n",
      "153568\n",
      "153600\n",
      "153632\n",
      "153664\n",
      "153696\n",
      "153728\n",
      "153760\n",
      "153792\n",
      "153824\n",
      "153856\n",
      "153888\n",
      "153920\n",
      "153952\n",
      "153984\n",
      "154016\n",
      "154048\n",
      "154080\n",
      "154112\n",
      "154144\n",
      "154176\n",
      "154208\n",
      "154240\n",
      "154272\n",
      "154304\n",
      "154336\n",
      "154368\n",
      "154400\n",
      "154432\n",
      "154464\n",
      "154496\n",
      "154528\n",
      "154560\n",
      "154592\n",
      "154624\n",
      "154656\n",
      "154688\n",
      "154720\n",
      "154752\n",
      "154784\n",
      "154816\n",
      "154848\n",
      "154880\n",
      "154912\n",
      "154944\n",
      "154976\n",
      "155008\n",
      "155040\n",
      "155072\n",
      "155104\n",
      "155136\n",
      "155168\n",
      "155200\n",
      "155232\n",
      "155264\n",
      "155296\n",
      "155328\n",
      "155360\n",
      "155392\n",
      "155424\n",
      "155456\n",
      "155488\n",
      "155520\n",
      "155552\n",
      "155584\n",
      "155616\n",
      "155648\n",
      "155680\n",
      "155712\n",
      "155744\n",
      "155776\n",
      "155808\n",
      "155840\n",
      "155872\n",
      "155904\n",
      "155936\n",
      "155968\n",
      "156000\n",
      "156032\n",
      "156064\n",
      "156096\n",
      "156128\n",
      "156160\n",
      "156192\n",
      "156224\n",
      "156256\n",
      "156288\n",
      "156320\n",
      "156352\n",
      "156384\n",
      "156416\n",
      "156448\n",
      "156480\n",
      "156512\n",
      "156544\n",
      "156576\n",
      "156608\n",
      "156640\n",
      "156672\n",
      "156704\n",
      "156736\n",
      "156768\n",
      "156800\n",
      "156832\n",
      "156864\n",
      "156896\n",
      "156928\n",
      "156960\n",
      "156992\n",
      "157024\n",
      "157056\n",
      "157088\n",
      "157120\n",
      "157152\n",
      "157184\n",
      "157216\n",
      "157248\n",
      "157280\n",
      "157312\n",
      "157344\n",
      "157376\n",
      "157408\n",
      "157440\n",
      "157472\n",
      "157504\n",
      "157536\n",
      "157568\n",
      "157600\n",
      "157632\n",
      "157664\n",
      "157696\n",
      "157728\n",
      "157760\n",
      "157792\n",
      "157824\n",
      "157856\n",
      "157888\n",
      "157920\n",
      "157952\n",
      "157984\n",
      "158016\n",
      "158048\n",
      "158080\n",
      "158112\n",
      "158144\n",
      "158176\n",
      "158208\n",
      "158240\n",
      "158272\n",
      "158304\n",
      "158336\n",
      "158368\n",
      "158400\n",
      "158432\n",
      "158464\n",
      "158496\n",
      "158528\n",
      "158560\n",
      "158592\n",
      "158624\n",
      "158656\n",
      "158688\n",
      "158720\n",
      "158752\n",
      "158784\n",
      "158816\n",
      "158848\n",
      "158880\n",
      "158912\n",
      "158944\n",
      "158976\n",
      "159008\n",
      "159040\n",
      "159072\n",
      "159104\n",
      "159136\n",
      "159168\n",
      "159200\n",
      "159232\n",
      "159264\n",
      "159296\n",
      "159328\n",
      "159360\n",
      "159392\n",
      "159424\n",
      "159456\n",
      "159488\n",
      "159520\n",
      "159552\n",
      "159584\n",
      "159616\n",
      "159648\n",
      "159680\n",
      "159712\n",
      "159744\n",
      "159776\n",
      "159808\n",
      "159840\n",
      "159872\n",
      "159904\n",
      "159936\n",
      "159968\n",
      "160000\n",
      "160032\n",
      "160064\n",
      "160096\n",
      "160128\n",
      "160160\n",
      "160192\n",
      "160224\n",
      "160256\n",
      "160288\n",
      "160320\n",
      "160352\n",
      "160384\n",
      "160416\n",
      "160448\n",
      "160480\n",
      "160512\n",
      "160544\n",
      "160576\n",
      "160608\n",
      "160640\n",
      "160672\n",
      "160704\n",
      "160736\n",
      "160768\n",
      "160800\n",
      "160832\n",
      "160864\n",
      "160896\n",
      "160928\n",
      "160960\n",
      "160992\n",
      "161024\n",
      "161056\n",
      "161088\n",
      "161120\n",
      "161152\n",
      "161184\n",
      "161216\n",
      "161248\n",
      "161280\n",
      "161312\n",
      "161344\n",
      "161376\n",
      "161408\n",
      "161440\n",
      "161472\n",
      "161504\n",
      "161536\n",
      "161568\n",
      "161600\n",
      "161632\n",
      "161664\n",
      "161696\n",
      "161728\n",
      "161760\n",
      "161792\n",
      "161824\n",
      "161856\n",
      "161888\n",
      "161920\n",
      "161952\n",
      "161984\n",
      "162016\n",
      "162048\n",
      "162080\n",
      "162112\n",
      "162144\n",
      "162176\n",
      "162208\n",
      "162240\n",
      "162272\n",
      "162304\n",
      "162336\n",
      "162368\n",
      "162400\n",
      "162432\n",
      "162464\n",
      "162496\n",
      "162528\n",
      "162560\n",
      "162592\n",
      "162624\n",
      "162656\n",
      "162688\n",
      "162720\n",
      "162752\n",
      "162784\n",
      "162816\n",
      "162848\n",
      "162880\n",
      "162912\n",
      "162944\n",
      "162976\n",
      "163008\n",
      "163040\n",
      "163072\n",
      "163104\n",
      "163136\n",
      "163168\n",
      "163200\n",
      "163232\n",
      "163264\n",
      "163296\n",
      "163328\n",
      "163360\n",
      "163392\n",
      "163424\n",
      "163456\n",
      "163488\n",
      "163520\n",
      "163552\n",
      "163584\n",
      "163616\n",
      "163648\n",
      "163680\n",
      "163712\n",
      "163744\n",
      "163776\n",
      "163808\n",
      "163840\n",
      "163872\n",
      "163904\n",
      "163936\n",
      "163968\n",
      "164000\n",
      "164032\n",
      "164064\n",
      "164096\n",
      "164128\n",
      "164160\n",
      "164192\n",
      "164224\n",
      "164256\n",
      "164288\n",
      "164320\n",
      "164352\n",
      "164384\n",
      "164416\n",
      "164448\n",
      "164480\n",
      "164512\n",
      "164544\n",
      "164576\n",
      "164608\n",
      "164640\n",
      "164672\n",
      "164704\n",
      "164736\n",
      "164768\n",
      "164800\n",
      "164832\n",
      "164864\n",
      "164896\n",
      "164928\n",
      "164960\n",
      "164992\n",
      "165024\n",
      "165056\n",
      "165088\n",
      "165120\n",
      "165152\n",
      "165184\n",
      "165216\n",
      "165248\n",
      "165280\n",
      "165312\n",
      "165344\n",
      "165376\n",
      "165408\n",
      "165440\n",
      "165472\n",
      "165504\n",
      "165536\n",
      "165568\n",
      "165600\n",
      "165632\n",
      "165664\n",
      "165696\n",
      "165728\n",
      "165760\n",
      "165792\n",
      "165824\n",
      "165856\n",
      "165888\n",
      "165920\n",
      "165952\n",
      "165984\n",
      "166016\n",
      "166048\n",
      "166080\n",
      "166112\n",
      "166144\n",
      "166176\n",
      "166208\n",
      "166240\n",
      "166272\n",
      "166304\n",
      "166336\n",
      "166368\n",
      "166400\n",
      "166432\n",
      "166464\n",
      "166496\n",
      "166528\n",
      "166560\n",
      "166592\n",
      "166624\n",
      "166656\n",
      "166688\n",
      "166720\n",
      "166752\n",
      "166784\n",
      "166816\n",
      "166848\n",
      "166880\n",
      "166912\n",
      "166944\n",
      "166976\n",
      "167008\n",
      "167040\n",
      "167072\n",
      "167104\n",
      "167136\n",
      "167168\n",
      "167200\n",
      "167232\n",
      "167264\n",
      "167296\n",
      "167328\n",
      "167360\n",
      "167392\n",
      "167424\n",
      "167456\n",
      "167488\n",
      "167520\n",
      "167552\n",
      "167584\n",
      "167616\n",
      "167648\n",
      "167680\n",
      "167712\n",
      "167744\n",
      "167776\n",
      "167808\n",
      "167840\n",
      "167872\n",
      "167904\n",
      "167936\n",
      "167968\n",
      "168000\n",
      "168032\n",
      "168064\n",
      "168096\n",
      "168128\n",
      "168160\n",
      "168192\n",
      "168224\n",
      "168256\n",
      "168288\n",
      "168320\n",
      "168352\n",
      "168384\n",
      "168416\n",
      "168448\n",
      "168480\n",
      "168512\n",
      "168544\n",
      "168576\n",
      "168608\n",
      "168640\n",
      "168672\n",
      "168704\n",
      "168736\n",
      "168768\n",
      "168800\n",
      "168832\n",
      "168864\n",
      "168896\n",
      "168928\n",
      "168960\n",
      "168992\n",
      "169024\n",
      "169056\n",
      "169088\n",
      "169120\n",
      "169152\n",
      "169184\n",
      "169216\n",
      "169248\n",
      "169280\n",
      "169312\n",
      "169344\n",
      "169376\n",
      "169408\n",
      "169440\n",
      "169472\n",
      "169504\n",
      "169536\n",
      "169568\n",
      "169600\n",
      "169632\n",
      "169664\n",
      "169696\n",
      "169728\n",
      "169760\n",
      "169792\n",
      "169824\n",
      "169856\n",
      "169888\n",
      "169920\n",
      "169952\n",
      "169984\n",
      "170016\n",
      "170048\n",
      "170080\n",
      "170112\n",
      "170144\n",
      "170176\n",
      "170208\n",
      "170240\n",
      "170272\n",
      "170304\n",
      "170336\n",
      "170368\n",
      "170400\n",
      "170432\n",
      "170464\n",
      "170496\n",
      "170528\n",
      "170560\n",
      "170592\n",
      "170624\n",
      "170656\n",
      "170688\n",
      "170720\n",
      "170752\n",
      "170784\n",
      "170816\n",
      "170848\n",
      "170880\n",
      "170912\n",
      "170944\n",
      "170976\n",
      "171008\n",
      "171040\n",
      "171072\n",
      "171104\n",
      "171136\n",
      "171168\n",
      "171200\n",
      "171232\n",
      "171264\n",
      "171296\n",
      "171328\n",
      "171360\n",
      "171392\n",
      "171424\n",
      "171456\n",
      "171488\n",
      "171520\n",
      "171552\n",
      "171584\n",
      "171616\n",
      "171648\n",
      "171680\n",
      "171712\n",
      "171744\n",
      "171776\n",
      "171808\n",
      "171840\n",
      "171872\n",
      "171904\n",
      "171936\n",
      "171968\n",
      "172000\n",
      "172032\n",
      "172064\n",
      "172096\n",
      "172128\n",
      "172160\n",
      "172192\n",
      "172224\n",
      "172256\n",
      "172288\n",
      "172320\n",
      "172352\n",
      "172384\n",
      "172416\n",
      "172448\n",
      "172480\n",
      "172512\n",
      "172544\n",
      "172576\n",
      "172608\n",
      "172640\n",
      "172672\n",
      "172704\n",
      "172736\n",
      "172768\n",
      "172800\n",
      "172832\n",
      "172864\n",
      "172896\n",
      "172928\n",
      "172960\n",
      "172992\n",
      "173024\n",
      "173056\n",
      "173088\n",
      "173120\n",
      "173152\n",
      "173184\n",
      "173216\n",
      "173248\n",
      "173280\n",
      "173312\n",
      "173344\n",
      "173376\n",
      "173408\n",
      "173440\n",
      "173472\n",
      "173504\n",
      "173536\n",
      "173568\n",
      "173600\n",
      "173632\n",
      "173664\n",
      "173696\n",
      "173728\n",
      "173760\n",
      "173792\n",
      "173824\n",
      "173856\n",
      "173888\n",
      "173920\n",
      "173952\n",
      "173984\n",
      "174016\n",
      "174048\n",
      "174080\n",
      "174112\n",
      "174144\n",
      "174176\n",
      "174208\n",
      "174240\n",
      "174272\n",
      "174304\n",
      "174336\n",
      "174368\n",
      "174400\n",
      "174432\n",
      "174464\n",
      "174496\n",
      "174528\n",
      "174560\n",
      "174592\n",
      "174624\n",
      "174656\n",
      "174688\n",
      "174720\n",
      "174752\n",
      "174784\n",
      "174816\n",
      "174848\n",
      "174880\n",
      "174912\n",
      "174944\n",
      "174976\n",
      "175008\n",
      "175040\n",
      "175072\n",
      "175104\n",
      "175136\n",
      "175168\n",
      "175200\n",
      "175232\n",
      "175264\n",
      "175296\n",
      "175328\n",
      "175360\n",
      "175392\n",
      "175424\n",
      "175456\n",
      "175488\n",
      "175520\n",
      "175552\n",
      "175584\n",
      "175616\n",
      "175648\n",
      "175680\n",
      "175712\n",
      "175744\n",
      "175776\n",
      "175808\n",
      "175840\n",
      "175872\n",
      "175904\n",
      "175936\n",
      "175968\n",
      "176000\n",
      "176032\n",
      "176064\n",
      "176096\n",
      "176128\n",
      "176160\n",
      "176192\n",
      "176224\n",
      "176256\n",
      "176288\n",
      "176320\n",
      "176352\n",
      "176384\n",
      "176416\n",
      "176448\n",
      "176480\n",
      "176512\n",
      "176544\n",
      "176576\n",
      "176608\n",
      "176640\n",
      "176672\n",
      "176704\n",
      "176736\n",
      "176768\n",
      "176800\n",
      "176832\n",
      "176864\n",
      "176896\n",
      "176928\n",
      "176960\n",
      "176992\n",
      "177024\n",
      "177056\n",
      "177088\n",
      "177120\n",
      "177152\n",
      "177184\n",
      "177216\n",
      "177248\n",
      "177280\n",
      "177312\n",
      "177344\n",
      "177376\n",
      "177408\n",
      "177440\n",
      "177472\n",
      "177504\n",
      "177536\n",
      "177568\n",
      "177600\n",
      "177632\n",
      "177664\n",
      "177696\n",
      "177728\n",
      "177760\n",
      "177792\n",
      "177824\n",
      "177856\n",
      "177888\n",
      "177920\n",
      "177952\n",
      "177984\n",
      "178016\n",
      "178048\n",
      "178080\n",
      "178112\n",
      "178144\n",
      "178176\n",
      "178208\n",
      "178240\n",
      "178272\n",
      "178304\n",
      "178336\n",
      "178368\n",
      "178400\n",
      "178432\n",
      "178464\n",
      "178496\n",
      "178528\n",
      "178560\n",
      "178592\n",
      "178624\n",
      "178656\n",
      "178688\n",
      "178720\n",
      "178752\n",
      "178784\n",
      "178816\n",
      "178848\n",
      "178880\n",
      "178912\n",
      "178944\n",
      "178976\n",
      "179008\n",
      "179040\n",
      "179072\n",
      "179104\n",
      "179136\n",
      "179168\n",
      "179200\n",
      "179232\n",
      "179264\n",
      "179296\n",
      "179328\n",
      "179360\n",
      "179392\n",
      "179424\n",
      "179456\n",
      "179488\n",
      "179520\n",
      "179552\n",
      "179584\n",
      "179616\n",
      "179648\n",
      "179680\n",
      "179712\n",
      "179744\n",
      "179776\n",
      "179808\n",
      "179840\n",
      "179872\n",
      "179904\n",
      "179936\n",
      "179919\n",
      "pretrainedBERT model created\n",
      "vector_size: 768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57af06d02e9e47d38bb931b80f2af688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e994759ba959467ab0dfde85aece1c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time to build vocab: 0.01 mins\n",
      "Time to train the model: 50.71 mins\n",
      "loading csv.....\n",
      "shape of dataframe : (5892571, 39)\n",
      "         Unnamed: 0  problem_log_id  skill  problem_id  user_id  \\\n",
      "0                 0       136843143     84      232301   172027   \n",
      "1                 1       136843144    198      185963   169036   \n",
      "2                 2       136843145    198      185964   169036   \n",
      "3                 3       136843146    183      186129   169036   \n",
      "4                 4       136843147    198      390031   174120   \n",
      "...             ...             ...    ...         ...      ...   \n",
      "5892566     5894897       146139561    181      125157   168815   \n",
      "5892567     5894898       146139562    181      125096   168815   \n",
      "5892568     5894899       146139566    197       37048   122411   \n",
      "5892569     5894900       146139568    181      125097   168815   \n",
      "5892570     5894901       146139570    181      125166   168815   \n",
      "\n",
      "         assignment_id  assistment_id  start_time  end_time problem_type  ...  \\\n",
      "0               486577         121637         0.0       0.0      algebra  ...   \n",
      "1               486567          97308         0.0       0.0    fill_in_1  ...   \n",
      "2               486567          97308         0.0       0.0      algebra  ...   \n",
      "3               486567          97369         0.0       0.0      algebra  ...   \n",
      "4               548857         222517         0.0       0.0     choose_1  ...   \n",
      "...                ...            ...         ...       ...          ...  ...   \n",
      "5892566         522114          66163         0.0       0.0     choose_1  ...   \n",
      "5892567         522114          66133         0.0       0.0      algebra  ...   \n",
      "5892568         368400          27921         0.0       0.0     choose_1  ...   \n",
      "5892569         522114          66133         0.0       0.0     choose_1  ...   \n",
      "5892570         522114          66168         0.0       0.0      algebra  ...   \n",
      "\n",
      "                                               answer_text  first_action  \\\n",
      "0                                                        7             0   \n",
      "1                                                      180             0   \n",
      "2                                                 .6666666             0   \n",
      "3                                                     1.26             0   \n",
      "4                                                   B. 467             0   \n",
      "...                                                    ...           ...   \n",
      "5892566  Ok. I have studied this example and am ready t...             0   \n",
      "5892567                                               7.92             0   \n",
      "5892568                                            Graph B             0   \n",
      "5892569  Ok. I have studied this example and am ready t...             0   \n",
      "5892570                                            41.8429             0   \n",
      "\n",
      "         problemlogid  Average_confidence(FRUSTRATED)  \\\n",
      "0           136843143                        0.361323   \n",
      "1           136843144                        0.361323   \n",
      "2           136843145                        0.361323   \n",
      "3           136843146                        0.361323   \n",
      "4           136843147                        0.361323   \n",
      "...               ...                             ...   \n",
      "5892566     146139561                        0.361323   \n",
      "5892567     146139562                        0.568161   \n",
      "5892568     146139566                        0.361323   \n",
      "5892569     146139568                        0.361323   \n",
      "5892570     146139570                        0.775000   \n",
      "\n",
      "        Average_confidence(CONFUSED)  Average_confidence(CONCENTRATING)  \\\n",
      "0                                0.0                           0.766925   \n",
      "1                                0.0                           0.766925   \n",
      "2                                0.0                           0.766925   \n",
      "3                                0.0                           0.336529   \n",
      "4                                0.0                           0.336529   \n",
      "...                              ...                                ...   \n",
      "5892566                          0.0                           0.766925   \n",
      "5892567                          0.0                           0.766925   \n",
      "5892568                          0.0                           0.766925   \n",
      "5892569                          0.0                           0.766925   \n",
      "5892570                          0.0                           0.766925   \n",
      "\n",
      "         Average_confidence(BORED) elapsed_time     timestamp  question_id  \n",
      "0                         0.442968          0.0  1346457606.0        38866  \n",
      "1                         0.442968          0.0  1346457638.0        33024  \n",
      "2                         0.442968          0.0  1346457646.0        33025  \n",
      "3                         0.762689          0.0  1346457691.0        33190  \n",
      "4                         0.762689          0.0  1346457694.0        50686  \n",
      "...                            ...          ...           ...          ...  \n",
      "5892566                   0.226950          0.0  1377993536.0        23377  \n",
      "5892567                   0.221484          0.0  1377993549.0        23316  \n",
      "5892568                   0.370962          0.0  1377993575.0         2900  \n",
      "5892569                   0.000000          0.0  1377993592.0        23317  \n",
      "5892570                   0.000000          0.0  1377993597.0        23386  \n",
      "\n",
      "[5892571 rows x 39 columns]\n",
      "Grouping users...\n",
      "Average sequence length is: 128.1690266449157\n",
      "Number of users with sequences longer than 500 is: 2383\n",
      "Number of times we chunk sequences with seq_len=500 is: 3239\n",
      "                                             question_id  \\\n",
      "0      [139760, 139775, 139776, 139777, 20949, 20920,...   \n",
      "1      [50318, 1052, 46187, 34505, 34511, 28474, 4995...   \n",
      "2      [12391, 12291, 12239, 12423, 12339, 12340, 123...   \n",
      "3      [76990, 76991, 76992, 76993, 76994, 76985, 769...   \n",
      "4      [42639, 42640, 42641, 42642, 42643, 42644, 426...   \n",
      "...                                                  ...   \n",
      "45371  [4544, 12833, 45840, 14681, 5424, 55655, 5775,...   \n",
      "45372  [53762, 53714, 53702, 54067, 54075, 53666, 144...   \n",
      "45373  [138000, 138001, 138002, 138003, 137999, 14633...   \n",
      "45374  [145327, 145328, 145329, 145330, 145331, 14535...   \n",
      "45375  [9603, 40340, 40539, 40540, 40541, 40482, 4065...   \n",
      "\n",
      "                                              problem_id  user_id  \\\n",
      "0      [694349, 694384, 694385, 694386, 114117, 11408...    21421   \n",
      "1      [382939, 12302, 338791, 189360, 189366, 161707...    24586   \n",
      "2      [80870, 80730, 80678, 80902, 80818, 80819, 808...    26046   \n",
      "3      [545787, 545788, 545789, 545790, 545791, 54577...    52535   \n",
      "4      [279874, 279875, 279876, 279879, 279880, 27988...    61394   \n",
      "...                                                  ...      ...   \n",
      "45371  [50985, 84889, 335404, 87473, 53987, 409181, 5...   228209   \n",
      "45372  [403807, 403759, 403747, 405426, 405434, 40367...   228210   \n",
      "45373  [691176, 691177, 691178, 691179, 691175, 87423...   228211   \n",
      "45374  [704112, 704113, 704114, 704115, 704116, 70416...   228212   \n",
      "45375  [71653, 253880, 254081, 254082, 254083, 254024...   228213   \n",
      "\n",
      "                                                 correct  \\\n",
      "0      [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
      "1      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
      "2      [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, ...   \n",
      "3      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
      "4      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
      "...                                                  ...   \n",
      "45371  [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
      "45372  [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...   \n",
      "45373  [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
      "45374  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
      "45375  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
      "\n",
      "                                                   skill  \\\n",
      "0            [55, 198, 198, 198, 122, 122, 122, 5, 5, 5]   \n",
      "1                 [198, 36, 198, 96, 96, 44, 0, 0, 0, 0]   \n",
      "2      [163, 163, 163, 163, 163, 198, 198, 198, 163, ...   \n",
      "3      [198, 198, 198, 198, 198, 198, 198, 198, 198, ...   \n",
      "4      [198, 198, 198, 198, 198, 198, 198, 198, 198, ...   \n",
      "...                                                  ...   \n",
      "45371  [104, 5, 97, 55, 6, 4, 96, 96, 6, 5, 55, 198, ...   \n",
      "45372  [59, 59, 59, 198, 198, 198, 183, 183, 183, 183...   \n",
      "45373  [198, 198, 198, 198, 127, 45, 103, 113, 6, 6, ...   \n",
      "45374  [198, 198, 198, 198, 198, 198, 198, 198, 198, ...   \n",
      "45375  [34, 77, 77, 77, 77, 77, 77, 77, 34, 34, 34, 3...   \n",
      "\n",
      "                                              start_time  \\\n",
      "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "...                                                  ...   \n",
      "45371  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "45372  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "45373  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "45374  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "45375  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                                end_time  \\\n",
      "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "...                                                  ...   \n",
      "45371  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "45372  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "45373  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "45374  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "45375  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                            elapsed_time  \\\n",
      "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "...                                                  ...   \n",
      "45371  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "45372  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "45373  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "45374  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "45375  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                               timestamp  \n",
      "0      [1369233860.0, 1369234635.0, 1369234686.0, 136...  \n",
      "1      [1351541381.0, 1351541397.0, 1351541407.0, 135...  \n",
      "2      [1367421783.0, 1367421820.0, 1367421842.0, 136...  \n",
      "3      [1346925086.0, 1346925092.0, 1346925097.0, 134...  \n",
      "4      [1347031756.0, 1347032235.0, 1347032246.0, 134...  \n",
      "...                                                  ...  \n",
      "45371  [1377970523.0, 1377970751.0, 1377970787.0, 137...  \n",
      "45372  [1377979289.0, 1377979297.0, 1377979303.0, 137...  \n",
      "45373  [1377980233.0, 1377980241.0, 1377980249.0, 137...  \n",
      "45374  [1377984323.0, 1377984461.0, 1377984546.0, 137...  \n",
      "45375  [1377989740.0, 1377989923.0, 1377989951.0, 137...  \n",
      "\n",
      "[45376 rows x 9 columns]\n",
      "splitting\n",
      "train size:  (29040, 6) validation size:  (7260, 6)\n",
      "<FlatMapDataset element_spec=({'pretrained_distilbert': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'target_pretrained_distilbert': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'sentence_transformer': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'target_sentence_transformer': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'gensim_word2vec': TensorSpec(shape=(None, 1600), dtype=tf.float32, name=None), 'target_gensim_word2vec': TensorSpec(shape=(None, 1600), dtype=tf.float32, name=None)}, {'target_label': TensorSpec(shape=(None,), dtype=tf.float32, name=None)})>\n",
      "<MapDataset element_spec=({'pretrained_distilbert': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'target_pretrained_distilbert': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'sentence_transformer': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'target_sentence_transformer': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'gensim_word2vec': TensorSpec(shape=(None, 1600), dtype=tf.float32, name=None), 'target_gensim_word2vec': TensorSpec(shape=(None, 1600), dtype=tf.float32, name=None)}, TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>\n",
      "<FlatMapDataset element_spec=({'pretrained_distilbert': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'target_pretrained_distilbert': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'sentence_transformer': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'target_sentence_transformer': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'gensim_word2vec': TensorSpec(shape=(None, 1600), dtype=tf.float32, name=None), 'target_gensim_word2vec': TensorSpec(shape=(None, 1600), dtype=tf.float32, name=None)}, {'target_label': TensorSpec(shape=(None,), dtype=tf.float32, name=None)})>\n",
      "<MapDataset element_spec=({'pretrained_distilbert': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'target_pretrained_distilbert': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'sentence_transformer': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'target_sentence_transformer': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'gensim_word2vec': TensorSpec(shape=(None, 1600), dtype=tf.float32, name=None), 'target_gensim_word2vec': TensorSpec(shape=(None, 1600), dtype=tf.float32, name=None)}, TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>\n",
      "<FlatMapDataset element_spec=({'pretrained_distilbert': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'target_pretrained_distilbert': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'sentence_transformer': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'target_sentence_transformer': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'gensim_word2vec': TensorSpec(shape=(None, 1600), dtype=tf.float32, name=None), 'target_gensim_word2vec': TensorSpec(shape=(None, 1600), dtype=tf.float32, name=None)}, {'target_label': TensorSpec(shape=(None,), dtype=tf.float32, name=None)})>\n",
      "<MapDataset element_spec=({'pretrained_distilbert': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'target_pretrained_distilbert': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'sentence_transformer': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'target_sentence_transformer': TensorSpec(shape=(None, 1536), dtype=tf.float32, name=None), 'gensim_word2vec': TensorSpec(shape=(None, 1600), dtype=tf.float32, name=None), 'target_gensim_word2vec': TensorSpec(shape=(None, 1600), dtype=tf.float32, name=None)}, TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>\n",
      "{'pretrained_distilbert': 1536, 'sentence_transformer': 1536, 'gensim_word2vec': 1600}\n",
      "Model: \"pretrained_distilbert_sentence_transformer_gensim_word2vec_hybrid_dkt_on_predictions\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " pretrained_distilbert (InputLa  [(None, None, 1536)  0          []                               \n",
      " yer)                           ]                                                                 \n",
      "                                                                                                  \n",
      " sentence_transformer (InputLay  [(None, None, 1536)  0          []                               \n",
      " er)                            ]                                                                 \n",
      "                                                                                                  \n",
      " gensim_word2vec (InputLayer)   [(None, None, 1600)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " masking (Masking)              (None, None, 1536)   0           ['pretrained_distilbert[0][0]']  \n",
      "                                                                                                  \n",
      " masking_2 (Masking)            (None, None, 1536)   0           ['sentence_transformer[0][0]']   \n",
      "                                                                                                  \n",
      " masking_4 (Masking)            (None, None, 1600)   0           ['gensim_word2vec[0][0]']        \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, None, 256)    1836032     ['masking[0][0]']                \n",
      "                                                                                                  \n",
      " target_pretrained_distilbert (  [(None, None, 1536)  0          []                               \n",
      " InputLayer)                    ]                                                                 \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, None, 256)    1836032     ['masking_2[0][0]']              \n",
      "                                                                                                  \n",
      " target_sentence_transformer (I  [(None, None, 1536)  0          []                               \n",
      " nputLayer)                     ]                                                                 \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, None, 256)    1901568     ['masking_4[0][0]']              \n",
      "                                                                                                  \n",
      " target_gensim_word2vec (InputL  [(None, None, 1600)  0          []                               \n",
      " ayer)                          ]                                                                 \n",
      "                                                                                                  \n",
      " pretrained_distilbert_output_d  (None, None, 1536)  394752      ['lstm[0][0]']                   \n",
      " ense (TimeDistributed)                                                                           \n",
      "                                                                                                  \n",
      " masking_1 (Masking)            (None, None, 1536)   0           ['target_pretrained_distilbert[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " sentence_transformer_output_de  (None, None, 1536)  394752      ['lstm_1[0][0]']                 \n",
      " nse (TimeDistributed)                                                                            \n",
      "                                                                                                  \n",
      " masking_3 (Masking)            (None, None, 1536)   0           ['target_sentence_transformer[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " gensim_word2vec_output_dense (  (None, None, 1600)  411200      ['lstm_2[0][0]']                 \n",
      " TimeDistributed)                                                                                 \n",
      "                                                                                                  \n",
      " masking_5 (Masking)            (None, None, 1600)   0           ['target_gensim_word2vec[0][0]'] \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, None, 1536)   0           ['pretrained_distilbert_output_de\n",
      "                                                                 nse[0][0]',                      \n",
      "                                                                  'masking_1[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, None, 1536)   0           ['sentence_transformer_output_den\n",
      "                                                                 se[0][0]',                       \n",
      "                                                                  'masking_3[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, None, 1600)   0           ['gensim_word2vec_output_dense[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'masking_5[0][0]']              \n",
      "                                                                                                  \n",
      " pretrained_distilbertoutput_cl  (None, None, 1)     1537        ['multiply[0][0]']               \n",
      " ass (TimeDistributed)                                                                            \n",
      "                                                                                                  \n",
      " sentence_transformeroutput_cla  (None, None, 1)     1537        ['multiply_1[0][0]']             \n",
      " ss (TimeDistributed)                                                                             \n",
      "                                                                                                  \n",
      " gensim_word2vecoutput_class (T  (None, None, 1)     1601        ['multiply_2[0][0]']             \n",
      " imeDistributed)                                                                                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, None, 3)      0           ['pretrained_distilbertoutput_cla\n",
      "                                                                 ss[0][0]',                       \n",
      "                                                                  'sentence_transformeroutput_clas\n",
      "                                                                 s[0][0]',                        \n",
      "                                                                  'gensim_word2vecoutput_class[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " hybrid_prediction (TimeDistrib  (None, None, 1)     4           ['concatenate[0][0]']            \n",
      " uted)                                                                                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,779,015\n",
      "Trainable params: 6,779,015\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "907/907 [==============================] - 706s 763ms/step - loss: 0.1560 - ColdStartBinaryAccuracy10: 0.6619 - ColdStartAUC10: 0.6135 - ColdStartBinaryAccuracy30: 0.6590 - ColdStartAUC30: 0.6337 - ColdStartBinaryAccuracy50: 0.6623 - ColdStartAUC50: 0.6416 - binary_crossentropy: 0.5988 - BinaryAccuracy: 0.6781 - AUC: 0.6516 - Precision: 0.6788 - Recall: 0.9970 - TrueNegatives: 17925.0000 - TruePositives: 2501875.0000 - FalseNegatives: 7573.0000 - FalsePositives: 1183678.0000 - val_loss: 0.1522 - val_ColdStartBinaryAccuracy10: 0.6803 - val_ColdStartAUC10: 0.6535 - val_ColdStartBinaryAccuracy30: 0.6908 - val_ColdStartAUC30: 0.6859 - val_ColdStartBinaryAccuracy50: 0.6957 - val_ColdStartAUC50: 0.6952 - val_binary_crossentropy: 0.5722 - val_BinaryAccuracy: 0.7108 - val_AUC: 0.7106 - val_Precision: 0.7120 - val_Recall: 0.9647 - val_TrueNegatives: 54733.0000 - val_TruePositives: 618746.0000 - val_FalseNegatives: 22670.0000 - val_FalsePositives: 250223.0000\n",
      "Epoch 2/200\n",
      "907/907 [==============================] - 687s 757ms/step - loss: 0.1483 - ColdStartBinaryAccuracy10: 0.6860 - ColdStartAUC10: 0.6669 - ColdStartBinaryAccuracy30: 0.6942 - ColdStartAUC30: 0.6970 - ColdStartBinaryAccuracy50: 0.6993 - ColdStartAUC50: 0.7054 - binary_crossentropy: 0.5692 - BinaryAccuracy: 0.7135 - AUC: 0.7176 - Precision: 0.7174 - Recall: 0.9529 - TrueNegatives: 259794.0000 - TruePositives: 2391245.0000 - FalseNegatives: 118203.0000 - FalsePositives: 941809.0000 - val_loss: 0.1502 - val_ColdStartBinaryAccuracy10: 0.6872 - val_ColdStartAUC10: 0.6698 - val_ColdStartBinaryAccuracy30: 0.6968 - val_ColdStartAUC30: 0.6988 - val_ColdStartBinaryAccuracy50: 0.7016 - val_ColdStartAUC50: 0.7070 - val_binary_crossentropy: 0.5648 - val_BinaryAccuracy: 0.7171 - val_AUC: 0.7223 - val_Precision: 0.7230 - val_Recall: 0.9465 - val_TrueNegatives: 72320.0000 - val_TruePositives: 607115.0000 - val_FalseNegatives: 34301.0000 - val_FalsePositives: 232636.0000\n",
      "Epoch 3/200\n",
      "907/907 [==============================] - 686s 757ms/step - loss: 0.1468 - ColdStartBinaryAccuracy10: 0.6897 - ColdStartAUC10: 0.6787 - ColdStartBinaryAccuracy30: 0.6987 - ColdStartAUC30: 0.7061 - ColdStartBinaryAccuracy50: 0.7040 - ColdStartAUC50: 0.7137 - binary_crossentropy: 0.5637 - BinaryAccuracy: 0.7190 - AUC: 0.7253 - Precision: 0.7267 - Recall: 0.9387 - TrueNegatives: 315758.0000 - TruePositives: 2355533.0000 - FalseNegatives: 153915.0000 - FalsePositives: 885845.0000 - val_loss: 0.1492 - val_ColdStartBinaryAccuracy10: 0.6898 - val_ColdStartAUC10: 0.6812 - val_ColdStartBinaryAccuracy30: 0.7017 - val_ColdStartAUC30: 0.7074 - val_ColdStartBinaryAccuracy50: 0.7069 - val_ColdStartAUC50: 0.7148 - val_binary_crossentropy: 0.5609 - val_BinaryAccuracy: 0.7231 - val_AUC: 0.7288 - val_Precision: 0.7366 - val_Recall: 0.9223 - val_TrueNegatives: 93433.0000 - val_TruePositives: 591576.0000 - val_FalseNegatives: 49840.0000 - val_FalsePositives: 211523.0000\n",
      "Epoch 4/200\n",
      "907/907 [==============================] - 687s 757ms/step - loss: 0.1458 - ColdStartBinaryAccuracy10: 0.6921 - ColdStartAUC10: 0.6881 - ColdStartBinaryAccuracy30: 0.7021 - ColdStartAUC30: 0.7132 - ColdStartBinaryAccuracy50: 0.7073 - ColdStartAUC50: 0.7199 - binary_crossentropy: 0.5596 - BinaryAccuracy: 0.7225 - AUC: 0.7306 - Precision: 0.7329 - Recall: 0.9298 - TrueNegatives: 351078.0000 - TruePositives: 2333181.0000 - FalseNegatives: 176267.0000 - FalsePositives: 850525.0000 - val_loss: 0.1482 - val_ColdStartBinaryAccuracy10: 0.6925 - val_ColdStartAUC10: 0.6902 - val_ColdStartBinaryAccuracy30: 0.7041 - val_ColdStartAUC30: 0.7136 - val_ColdStartBinaryAccuracy50: 0.7092 - val_ColdStartAUC50: 0.7203 - val_binary_crossentropy: 0.5572 - val_BinaryAccuracy: 0.7258 - val_AUC: 0.7333 - val_Precision: 0.7431 - val_Recall: 0.9117 - val_TrueNegatives: 102803.0000 - val_TruePositives: 584767.0000 - val_FalseNegatives: 56649.0000 - val_FalsePositives: 202153.0000\n",
      "Epoch 5/200\n",
      "907/907 [==============================] - 685s 756ms/step - loss: 0.1451 - ColdStartBinaryAccuracy10: 0.6947 - ColdStartAUC10: 0.6954 - ColdStartBinaryAccuracy30: 0.7043 - ColdStartAUC30: 0.7175 - ColdStartBinaryAccuracy50: 0.7094 - ColdStartAUC50: 0.7236 - binary_crossentropy: 0.5569 - BinaryAccuracy: 0.7245 - AUC: 0.7335 - Precision: 0.7374 - Recall: 0.9224 - TrueNegatives: 377107.0000 - TruePositives: 2314711.0000 - FalseNegatives: 194737.0000 - FalsePositives: 824496.0000 - val_loss: 0.1473 - val_ColdStartBinaryAccuracy10: 0.6947 - val_ColdStartAUC10: 0.6965 - val_ColdStartBinaryAccuracy30: 0.7058 - val_ColdStartAUC30: 0.7177 - val_ColdStartBinaryAccuracy50: 0.7107 - val_ColdStartAUC50: 0.7241 - val_binary_crossentropy: 0.5539 - val_BinaryAccuracy: 0.7271 - val_AUC: 0.7366 - val_Precision: 0.7443 - val_Recall: 0.9118 - val_TrueNegatives: 104020.0000 - val_TruePositives: 584819.0000 - val_FalseNegatives: 56597.0000 - val_FalsePositives: 200936.0000\n",
      "Epoch 6/200\n",
      "907/907 [==============================] - 683s 753ms/step - loss: 0.1441 - ColdStartBinaryAccuracy10: 0.6967 - ColdStartAUC10: 0.7033 - ColdStartBinaryAccuracy30: 0.7068 - ColdStartAUC30: 0.7235 - ColdStartBinaryAccuracy50: 0.7120 - ColdStartAUC50: 0.7291 - binary_crossentropy: 0.5530 - BinaryAccuracy: 0.7269 - AUC: 0.7383 - Precision: 0.7413 - Recall: 0.9176 - TrueNegatives: 397886.0000 - TruePositives: 2302754.0000 - FalseNegatives: 206694.0000 - FalsePositives: 803717.0000 - val_loss: 0.1465 - val_ColdStartBinaryAccuracy10: 0.6969 - val_ColdStartAUC10: 0.7040 - val_ColdStartBinaryAccuracy30: 0.7081 - val_ColdStartAUC30: 0.7230 - val_ColdStartBinaryAccuracy50: 0.7128 - val_ColdStartAUC50: 0.7288 - val_binary_crossentropy: 0.5507 - val_BinaryAccuracy: 0.7291 - val_AUC: 0.7402 - val_Precision: 0.7487 - val_Recall: 0.9053 - val_TrueNegatives: 110004.0000 - val_TruePositives: 580681.0000 - val_FalseNegatives: 60735.0000 - val_FalsePositives: 194952.0000\n",
      "Epoch 7/200\n",
      "907/907 [==============================] - 683s 753ms/step - loss: 0.1433 - ColdStartBinaryAccuracy10: 0.6985 - ColdStartAUC10: 0.7096 - ColdStartBinaryAccuracy30: 0.7085 - ColdStartAUC30: 0.7280 - ColdStartBinaryAccuracy50: 0.7138 - ColdStartAUC50: 0.7332 - binary_crossentropy: 0.5501 - BinaryAccuracy: 0.7285 - AUC: 0.7416 - Precision: 0.7443 - Recall: 0.9137 - TrueNegatives: 413730.0000 - TruePositives: 2292874.0000 - FalseNegatives: 216574.0000 - FalsePositives: 787873.0000 - val_loss: 0.1458 - val_ColdStartBinaryAccuracy10: 0.6983 - val_ColdStartAUC10: 0.7097 - val_ColdStartBinaryAccuracy30: 0.7096 - val_ColdStartAUC30: 0.7269 - val_ColdStartBinaryAccuracy50: 0.7143 - val_ColdStartAUC50: 0.7324 - val_binary_crossentropy: 0.5482 - val_BinaryAccuracy: 0.7304 - val_AUC: 0.7431 - val_Precision: 0.7509 - val_Recall: 0.9029 - val_TrueNegatives: 112806.0000 - val_TruePositives: 579121.0000 - val_FalseNegatives: 62295.0000 - val_FalsePositives: 192150.0000\n",
      "Epoch 8/200\n",
      "907/907 [==============================] - 684s 754ms/step - loss: 0.1426 - ColdStartBinaryAccuracy10: 0.6999 - ColdStartAUC10: 0.7145 - ColdStartBinaryAccuracy30: 0.7101 - ColdStartAUC30: 0.7317 - ColdStartBinaryAccuracy50: 0.7153 - ColdStartAUC50: 0.7365 - binary_crossentropy: 0.5475 - BinaryAccuracy: 0.7298 - AUC: 0.7444 - Precision: 0.7467 - Recall: 0.9105 - TrueNegatives: 426418.0000 - TruePositives: 2284892.0000 - FalseNegatives: 224556.0000 - FalsePositives: 775185.0000 - val_loss: 0.1453 - val_ColdStartBinaryAccuracy10: 0.7007 - val_ColdStartAUC10: 0.7148 - val_ColdStartBinaryAccuracy30: 0.7111 - val_ColdStartAUC30: 0.7303 - val_ColdStartBinaryAccuracy50: 0.7156 - val_ColdStartAUC50: 0.7353 - val_binary_crossentropy: 0.5462 - val_BinaryAccuracy: 0.7313 - val_AUC: 0.7454 - val_Precision: 0.7545 - val_Recall: 0.8964 - val_TrueNegatives: 117827.0000 - val_TruePositives: 574969.0000 - val_FalseNegatives: 66447.0000 - val_FalsePositives: 187129.0000\n",
      "Epoch 9/200\n",
      "907/907 [==============================] - 686s 756ms/step - loss: 0.1420 - ColdStartBinaryAccuracy10: 0.7017 - ColdStartAUC10: 0.7190 - ColdStartBinaryAccuracy30: 0.7116 - ColdStartAUC30: 0.7351 - ColdStartBinaryAccuracy50: 0.7167 - ColdStartAUC50: 0.7397 - binary_crossentropy: 0.5451 - BinaryAccuracy: 0.7310 - AUC: 0.7470 - Precision: 0.7488 - Recall: 0.9080 - TrueNegatives: 437057.0000 - TruePositives: 2278641.0000 - FalseNegatives: 230807.0000 - FalsePositives: 764546.0000 - val_loss: 0.1447 - val_ColdStartBinaryAccuracy10: 0.7023 - val_ColdStartAUC10: 0.7188 - val_ColdStartBinaryAccuracy30: 0.7128 - val_ColdStartAUC30: 0.7332 - val_ColdStartBinaryAccuracy50: 0.7172 - val_ColdStartAUC50: 0.7381 - val_binary_crossentropy: 0.5439 - val_BinaryAccuracy: 0.7323 - val_AUC: 0.7477 - val_Precision: 0.7553 - val_Recall: 0.8966 - val_TrueNegatives: 118639.0000 - val_TruePositives: 575098.0000 - val_FalseNegatives: 66318.0000 - val_FalsePositives: 186317.0000\n",
      "Epoch 10/200\n",
      "907/907 [==============================] - 686s 756ms/step - loss: 0.1414 - ColdStartBinaryAccuracy10: 0.7041 - ColdStartAUC10: 0.7227 - ColdStartBinaryAccuracy30: 0.7131 - ColdStartAUC30: 0.7380 - ColdStartBinaryAccuracy50: 0.7181 - ColdStartAUC50: 0.7424 - binary_crossentropy: 0.5429 - BinaryAccuracy: 0.7322 - AUC: 0.7493 - Precision: 0.7505 - Recall: 0.9065 - TrueNegatives: 445438.0000 - TruePositives: 2274755.0000 - FalseNegatives: 234693.0000 - FalsePositives: 756165.0000 - val_loss: 0.1441 - val_ColdStartBinaryAccuracy10: 0.7047 - val_ColdStartAUC10: 0.7222 - val_ColdStartBinaryAccuracy30: 0.7143 - val_ColdStartAUC30: 0.7361 - val_ColdStartBinaryAccuracy50: 0.7187 - val_ColdStartAUC50: 0.7408 - val_binary_crossentropy: 0.5418 - val_BinaryAccuracy: 0.7333 - val_AUC: 0.7497 - val_Precision: 0.7563 - val_Recall: 0.8966 - val_TrueNegatives: 119612.0000 - val_TruePositives: 575074.0000 - val_FalseNegatives: 66342.0000 - val_FalsePositives: 185344.0000\n",
      "Epoch 11/200\n",
      "907/907 [==============================] - 686s 756ms/step - loss: 0.1409 - ColdStartBinaryAccuracy10: 0.7057 - ColdStartAUC10: 0.7260 - ColdStartBinaryAccuracy30: 0.7143 - ColdStartAUC30: 0.7405 - ColdStartBinaryAccuracy50: 0.7192 - ColdStartAUC50: 0.7447 - binary_crossentropy: 0.5410 - BinaryAccuracy: 0.7332 - AUC: 0.7512 - Precision: 0.7520 - Recall: 0.9049 - TrueNegatives: 452762.0000 - TruePositives: 2270921.0000 - FalseNegatives: 238527.0000 - FalsePositives: 748841.0000 - val_loss: 0.1437 - val_ColdStartBinaryAccuracy10: 0.7074 - val_ColdStartAUC10: 0.7253 - val_ColdStartBinaryAccuracy30: 0.7157 - val_ColdStartAUC30: 0.7384 - val_ColdStartBinaryAccuracy50: 0.7200 - val_ColdStartAUC50: 0.7429 - val_binary_crossentropy: 0.5401 - val_BinaryAccuracy: 0.7342 - val_AUC: 0.7515 - val_Precision: 0.7578 - val_Recall: 0.8951 - val_TrueNegatives: 121430.0000 - val_TruePositives: 574121.0000 - val_FalseNegatives: 67295.0000 - val_FalsePositives: 183526.0000\n",
      "Epoch 12/200\n",
      "907/907 [==============================] - 684s 754ms/step - loss: 0.1404 - ColdStartBinaryAccuracy10: 0.7070 - ColdStartAUC10: 0.7291 - ColdStartBinaryAccuracy30: 0.7154 - ColdStartAUC30: 0.7429 - ColdStartBinaryAccuracy50: 0.7203 - ColdStartAUC50: 0.7470 - binary_crossentropy: 0.5391 - BinaryAccuracy: 0.7341 - AUC: 0.7532 - Precision: 0.7533 - Recall: 0.9039 - TrueNegatives: 458698.0000 - TruePositives: 2268362.0000 - FalseNegatives: 241086.0000 - FalsePositives: 742905.0000 - val_loss: 0.1432 - val_ColdStartBinaryAccuracy10: 0.7080 - val_ColdStartAUC10: 0.7279 - val_ColdStartBinaryAccuracy30: 0.7167 - val_ColdStartAUC30: 0.7403 - val_ColdStartBinaryAccuracy50: 0.7208 - val_ColdStartAUC50: 0.7447 - val_binary_crossentropy: 0.5383 - val_BinaryAccuracy: 0.7348 - val_AUC: 0.7529 - val_Precision: 0.7577 - val_Recall: 0.8964 - val_TrueNegatives: 121109.0000 - val_TruePositives: 574968.0000 - val_FalseNegatives: 66448.0000 - val_FalsePositives: 183847.0000\n",
      "Epoch 13/200\n",
      "907/907 [==============================] - 685s 755ms/step - loss: 0.1400 - ColdStartBinaryAccuracy10: 0.7094 - ColdStartAUC10: 0.7316 - ColdStartBinaryAccuracy30: 0.7168 - ColdStartAUC30: 0.7450 - ColdStartBinaryAccuracy50: 0.7215 - ColdStartAUC50: 0.7489 - binary_crossentropy: 0.5375 - BinaryAccuracy: 0.7350 - AUC: 0.7548 - Precision: 0.7545 - Recall: 0.9031 - TrueNegatives: 464091.0000 - TruePositives: 2266237.0000 - FalseNegatives: 243211.0000 - FalsePositives: 737512.0000 - val_loss: 0.1429 - val_ColdStartBinaryAccuracy10: 0.7102 - val_ColdStartAUC10: 0.7302 - val_ColdStartBinaryAccuracy30: 0.7178 - val_ColdStartAUC30: 0.7420 - val_ColdStartBinaryAccuracy50: 0.7220 - val_ColdStartAUC50: 0.7464 - val_binary_crossentropy: 0.5371 - val_BinaryAccuracy: 0.7355 - val_AUC: 0.7544 - val_Precision: 0.7592 - val_Recall: 0.8945 - val_TrueNegatives: 122998.0000 - val_TruePositives: 573722.0000 - val_FalseNegatives: 67694.0000 - val_FalsePositives: 181958.0000\n",
      "Epoch 14/200\n",
      "907/907 [==============================] - 684s 755ms/step - loss: 0.1396 - ColdStartBinaryAccuracy10: 0.7107 - ColdStartAUC10: 0.7341 - ColdStartBinaryAccuracy30: 0.7179 - ColdStartAUC30: 0.7470 - ColdStartBinaryAccuracy50: 0.7225 - ColdStartAUC50: 0.7508 - binary_crossentropy: 0.5359 - BinaryAccuracy: 0.7357 - AUC: 0.7564 - Precision: 0.7555 - Recall: 0.9023 - TrueNegatives: 468855.0000 - TruePositives: 2264309.0000 - FalseNegatives: 245139.0000 - FalsePositives: 732748.0000 - val_loss: 0.1425 - val_ColdStartBinaryAccuracy10: 0.7116 - val_ColdStartAUC10: 0.7324 - val_ColdStartBinaryAccuracy30: 0.7190 - val_ColdStartAUC30: 0.7439 - val_ColdStartBinaryAccuracy50: 0.7229 - val_ColdStartAUC50: 0.7480 - val_binary_crossentropy: 0.5356 - val_BinaryAccuracy: 0.7361 - val_AUC: 0.7556 - val_Precision: 0.7586 - val_Recall: 0.8973 - val_TrueNegatives: 121781.0000 - val_TruePositives: 575522.0000 - val_FalseNegatives: 65894.0000 - val_FalsePositives: 183175.0000\n",
      "Epoch 15/200\n",
      "907/907 [==============================] - 685s 755ms/step - loss: 0.1392 - ColdStartBinaryAccuracy10: 0.7121 - ColdStartAUC10: 0.7361 - ColdStartBinaryAccuracy30: 0.7190 - ColdStartAUC30: 0.7487 - ColdStartBinaryAccuracy50: 0.7234 - ColdStartAUC50: 0.7524 - binary_crossentropy: 0.5344 - BinaryAccuracy: 0.7364 - AUC: 0.7579 - Precision: 0.7564 - Recall: 0.9017 - TrueNegatives: 472839.0000 - TruePositives: 2262794.0000 - FalseNegatives: 246654.0000 - FalsePositives: 728764.0000 - val_loss: 0.1422 - val_ColdStartBinaryAccuracy10: 0.7122 - val_ColdStartAUC10: 0.7341 - val_ColdStartBinaryAccuracy30: 0.7192 - val_ColdStartAUC30: 0.7452 - val_ColdStartBinaryAccuracy50: 0.7230 - val_ColdStartAUC50: 0.7492 - val_binary_crossentropy: 0.5346 - val_BinaryAccuracy: 0.7364 - val_AUC: 0.7569 - val_Precision: 0.7618 - val_Recall: 0.8907 - val_TrueNegatives: 126334.0000 - val_TruePositives: 571280.0000 - val_FalseNegatives: 70136.0000 - val_FalsePositives: 178622.0000\n",
      "Epoch 16/200\n",
      "907/907 [==============================] - 686s 756ms/step - loss: 0.1388 - ColdStartBinaryAccuracy10: 0.7132 - ColdStartAUC10: 0.7382 - ColdStartBinaryAccuracy30: 0.7199 - ColdStartAUC30: 0.7505 - ColdStartBinaryAccuracy50: 0.7242 - ColdStartAUC50: 0.7540 - binary_crossentropy: 0.5331 - BinaryAccuracy: 0.7371 - AUC: 0.7593 - Precision: 0.7573 - Recall: 0.9012 - TrueNegatives: 476928.0000 - TruePositives: 2261403.0000 - FalseNegatives: 248045.0000 - FalsePositives: 724675.0000 - val_loss: 0.1419 - val_ColdStartBinaryAccuracy10: 0.7133 - val_ColdStartAUC10: 0.7357 - val_ColdStartBinaryAccuracy30: 0.7200 - val_ColdStartAUC30: 0.7466 - val_ColdStartBinaryAccuracy50: 0.7240 - val_ColdStartAUC50: 0.7506 - val_binary_crossentropy: 0.5336 - val_BinaryAccuracy: 0.7369 - val_AUC: 0.7577 - val_Precision: 0.7603 - val_Recall: 0.8950 - val_TrueNegatives: 124016.0000 - val_TruePositives: 574067.0000 - val_FalseNegatives: 67349.0000 - val_FalsePositives: 180940.0000\n",
      "Epoch 17/200\n",
      "907/907 [==============================] - 682s 752ms/step - loss: 0.1392 - ColdStartBinaryAccuracy10: 0.7140 - ColdStartAUC10: 0.7388 - ColdStartBinaryAccuracy30: 0.7197 - ColdStartAUC30: 0.7491 - ColdStartBinaryAccuracy50: 0.7239 - ColdStartAUC50: 0.7525 - binary_crossentropy: 0.5343 - BinaryAccuracy: 0.7363 - AUC: 0.7571 - Precision: 0.7560 - Recall: 0.9025 - TrueNegatives: 470474.0000 - TruePositives: 2264827.0000 - FalseNegatives: 244621.0000 - FalsePositives: 731129.0000 - val_loss: 0.1419 - val_ColdStartBinaryAccuracy10: 0.7139 - val_ColdStartAUC10: 0.7366 - val_ColdStartBinaryAccuracy30: 0.7202 - val_ColdStartAUC30: 0.7466 - val_ColdStartBinaryAccuracy50: 0.7240 - val_ColdStartAUC50: 0.7505 - val_binary_crossentropy: 0.5335 - val_BinaryAccuracy: 0.7370 - val_AUC: 0.7575 - val_Precision: 0.7610 - val_Recall: 0.8936 - val_TrueNegatives: 124954.0000 - val_TruePositives: 573198.0000 - val_FalseNegatives: 68218.0000 - val_FalsePositives: 180002.0000\n",
      "Epoch 18/200\n",
      "907/907 [==============================] - 678s 747ms/step - loss: 0.1384 - ColdStartBinaryAccuracy10: 0.7156 - ColdStartAUC10: 0.7410 - ColdStartBinaryAccuracy30: 0.7213 - ColdStartAUC30: 0.7524 - ColdStartBinaryAccuracy50: 0.7255 - ColdStartAUC50: 0.7560 - binary_crossentropy: 0.5312 - BinaryAccuracy: 0.7381 - AUC: 0.7609 - Precision: 0.7582 - Recall: 0.9011 - TrueNegatives: 480608.0000 - TruePositives: 2261325.0000 - FalseNegatives: 248123.0000 - FalsePositives: 720995.0000 - val_loss: 0.1416 - val_ColdStartBinaryAccuracy10: 0.7149 - val_ColdStartAUC10: 0.7381 - val_ColdStartBinaryAccuracy30: 0.7213 - val_ColdStartAUC30: 0.7484 - val_ColdStartBinaryAccuracy50: 0.7248 - val_ColdStartAUC50: 0.7522 - val_binary_crossentropy: 0.5322 - val_BinaryAccuracy: 0.7378 - val_AUC: 0.7590 - val_Precision: 0.7616 - val_Recall: 0.8940 - val_TrueNegatives: 125414.0000 - val_TruePositives: 573444.0000 - val_FalseNegatives: 67972.0000 - val_FalsePositives: 179542.0000\n",
      "Epoch 19/200\n",
      "907/907 [==============================] - 678s 748ms/step - loss: 0.1380 - ColdStartBinaryAccuracy10: 0.7163 - ColdStartAUC10: 0.7423 - ColdStartBinaryAccuracy30: 0.7221 - ColdStartAUC30: 0.7540 - ColdStartBinaryAccuracy50: 0.7263 - ColdStartAUC50: 0.7574 - binary_crossentropy: 0.5299 - BinaryAccuracy: 0.7388 - AUC: 0.7623 - Precision: 0.7591 - Recall: 0.9007 - TrueNegatives: 484188.0000 - TruePositives: 2260150.0000 - FalseNegatives: 249298.0000 - FalsePositives: 717415.0000 - val_loss: 0.1415 - val_ColdStartBinaryAccuracy10: 0.7155 - val_ColdStartAUC10: 0.7393 - val_ColdStartBinaryAccuracy30: 0.7217 - val_ColdStartAUC30: 0.7493 - val_ColdStartBinaryAccuracy50: 0.7253 - val_ColdStartAUC50: 0.7529 - val_binary_crossentropy: 0.5319 - val_BinaryAccuracy: 0.7379 - val_AUC: 0.7592 - val_Precision: 0.7622 - val_Recall: 0.8929 - val_TrueNegatives: 126286.0000 - val_TruePositives: 572746.0000 - val_FalseNegatives: 68670.0000 - val_FalsePositives: 178670.0000\n",
      "Epoch 20/200\n",
      "907/907 [==============================] - 678s 748ms/step - loss: 0.1377 - ColdStartBinaryAccuracy10: 0.7174 - ColdStartAUC10: 0.7436 - ColdStartBinaryAccuracy30: 0.7230 - ColdStartAUC30: 0.7553 - ColdStartBinaryAccuracy50: 0.7272 - ColdStartAUC50: 0.7588 - binary_crossentropy: 0.5287 - BinaryAccuracy: 0.7395 - AUC: 0.7636 - Precision: 0.7599 - Recall: 0.9002 - TrueNegatives: 487817.0000 - TruePositives: 2259045.0000 - FalseNegatives: 250403.0000 - FalsePositives: 713786.0000 - val_loss: 0.1410 - val_ColdStartBinaryAccuracy10: 0.7166 - val_ColdStartAUC10: 0.7404 - val_ColdStartBinaryAccuracy30: 0.7228 - val_ColdStartAUC30: 0.7507 - val_ColdStartBinaryAccuracy50: 0.7263 - val_ColdStartAUC50: 0.7544 - val_binary_crossentropy: 0.5301 - val_BinaryAccuracy: 0.7388 - val_AUC: 0.7611 - val_Precision: 0.7637 - val_Recall: 0.8915 - val_TrueNegatives: 128009.0000 - val_TruePositives: 571809.0000 - val_FalseNegatives: 69607.0000 - val_FalsePositives: 176947.0000\n",
      "Epoch 21/200\n",
      "907/907 [==============================] - 678s 748ms/step - loss: 0.1374 - ColdStartBinaryAccuracy10: 0.7190 - ColdStartAUC10: 0.7451 - ColdStartBinaryAccuracy30: 0.7243 - ColdStartAUC30: 0.7568 - ColdStartBinaryAccuracy50: 0.7283 - ColdStartAUC50: 0.7601 - binary_crossentropy: 0.5275 - BinaryAccuracy: 0.7402 - AUC: 0.7648 - Precision: 0.7607 - Recall: 0.9000 - TrueNegatives: 490996.0000 - TruePositives: 2258627.0000 - FalseNegatives: 250821.0000 - FalsePositives: 710607.0000 - val_loss: 0.1408 - val_ColdStartBinaryAccuracy10: 0.7184 - val_ColdStartAUC10: 0.7416 - val_ColdStartBinaryAccuracy30: 0.7236 - val_ColdStartAUC30: 0.7516 - val_ColdStartBinaryAccuracy50: 0.7270 - val_ColdStartAUC50: 0.7553 - val_binary_crossentropy: 0.5292 - val_BinaryAccuracy: 0.7391 - val_AUC: 0.7618 - val_Precision: 0.7628 - val_Recall: 0.8942 - val_TrueNegatives: 126559.0000 - val_TruePositives: 573585.0000 - val_FalseNegatives: 67831.0000 - val_FalsePositives: 178397.0000\n",
      "Epoch 22/200\n",
      "907/907 [==============================] - 679s 748ms/step - loss: 0.1371 - ColdStartBinaryAccuracy10: 0.7202 - ColdStartAUC10: 0.7463 - ColdStartBinaryAccuracy30: 0.7249 - ColdStartAUC30: 0.7579 - ColdStartBinaryAccuracy50: 0.7289 - ColdStartAUC50: 0.7612 - binary_crossentropy: 0.5265 - BinaryAccuracy: 0.7408 - AUC: 0.7659 - Precision: 0.7613 - Recall: 0.8998 - TrueNegatives: 493789.0000 - TruePositives: 2257974.0000 - FalseNegatives: 251474.0000 - FalsePositives: 707814.0000 - val_loss: 0.1405 - val_ColdStartBinaryAccuracy10: 0.7186 - val_ColdStartAUC10: 0.7424 - val_ColdStartBinaryAccuracy30: 0.7242 - val_ColdStartAUC30: 0.7525 - val_ColdStartBinaryAccuracy50: 0.7275 - val_ColdStartAUC50: 0.7561 - val_binary_crossentropy: 0.5283 - val_BinaryAccuracy: 0.7396 - val_AUC: 0.7626 - val_Precision: 0.7627 - val_Recall: 0.8954 - val_TrueNegatives: 126263.0000 - val_TruePositives: 574330.0000 - val_FalseNegatives: 67086.0000 - val_FalsePositives: 178693.0000\n",
      "Epoch 23/200\n",
      "907/907 [==============================] - 678s 748ms/step - loss: 0.1369 - ColdStartBinaryAccuracy10: 0.7210 - ColdStartAUC10: 0.7475 - ColdStartBinaryAccuracy30: 0.7259 - ColdStartAUC30: 0.7591 - ColdStartBinaryAccuracy50: 0.7297 - ColdStartAUC50: 0.7624 - binary_crossentropy: 0.5255 - BinaryAccuracy: 0.7413 - AUC: 0.7669 - Precision: 0.7619 - Recall: 0.8996 - TrueNegatives: 496218.0000 - TruePositives: 2257448.0000 - FalseNegatives: 252000.0000 - FalsePositives: 705385.0000 - val_loss: 0.1403 - val_ColdStartBinaryAccuracy10: 0.7187 - val_ColdStartAUC10: 0.7434 - val_ColdStartBinaryAccuracy30: 0.7240 - val_ColdStartAUC30: 0.7534 - val_ColdStartBinaryAccuracy50: 0.7279 - val_ColdStartAUC50: 0.7571 - val_binary_crossentropy: 0.5275 - val_BinaryAccuracy: 0.7398 - val_AUC: 0.7637 - val_Precision: 0.7653 - val_Recall: 0.8902 - val_TrueNegatives: 129837.0000 - val_TruePositives: 570975.0000 - val_FalseNegatives: 70441.0000 - val_FalsePositives: 175119.0000\n",
      "Epoch 24/200\n",
      "907/907 [==============================] - 676s 746ms/step - loss: 0.1366 - ColdStartBinaryAccuracy10: 0.7216 - ColdStartAUC10: 0.7490 - ColdStartBinaryAccuracy30: 0.7265 - ColdStartAUC30: 0.7603 - ColdStartBinaryAccuracy50: 0.7303 - ColdStartAUC50: 0.7635 - binary_crossentropy: 0.5245 - BinaryAccuracy: 0.7418 - AUC: 0.7679 - Precision: 0.7625 - Recall: 0.8994 - TrueNegatives: 498547.0000 - TruePositives: 2257020.0000 - FalseNegatives: 252428.0000 - FalsePositives: 703056.0000 - val_loss: 0.1401 - val_ColdStartBinaryAccuracy10: 0.7195 - val_ColdStartAUC10: 0.7442 - val_ColdStartBinaryAccuracy30: 0.7248 - val_ColdStartAUC30: 0.7542 - val_ColdStartBinaryAccuracy50: 0.7284 - val_ColdStartAUC50: 0.7578 - val_binary_crossentropy: 0.5266 - val_BinaryAccuracy: 0.7404 - val_AUC: 0.7644 - val_Precision: 0.7638 - val_Recall: 0.8948 - val_TrueNegatives: 127490.0000 - val_TruePositives: 573908.0000 - val_FalseNegatives: 67508.0000 - val_FalsePositives: 177466.0000\n",
      "Epoch 25/200\n",
      "907/907 [==============================] - 675s 745ms/step - loss: 0.1364 - ColdStartBinaryAccuracy10: 0.7221 - ColdStartAUC10: 0.7501 - ColdStartBinaryAccuracy30: 0.7271 - ColdStartAUC30: 0.7614 - ColdStartBinaryAccuracy50: 0.7309 - ColdStartAUC50: 0.7646 - binary_crossentropy: 0.5235 - BinaryAccuracy: 0.7424 - AUC: 0.7690 - Precision: 0.7630 - Recall: 0.8994 - TrueNegatives: 500645.0000 - TruePositives: 2257011.0000 - FalseNegatives: 252437.0000 - FalsePositives: 700958.0000 - val_loss: 0.1399 - val_ColdStartBinaryAccuracy10: 0.7194 - val_ColdStartAUC10: 0.7450 - val_ColdStartBinaryAccuracy30: 0.7247 - val_ColdStartAUC30: 0.7549 - val_ColdStartBinaryAccuracy50: 0.7286 - val_ColdStartAUC50: 0.7585 - val_binary_crossentropy: 0.5259 - val_BinaryAccuracy: 0.7407 - val_AUC: 0.7651 - val_Precision: 0.7645 - val_Recall: 0.8939 - val_TrueNegatives: 128298.0000 - val_TruePositives: 573344.0000 - val_FalseNegatives: 68072.0000 - val_FalsePositives: 176658.0000\n",
      "Epoch 26/200\n",
      "907/907 [==============================] - 676s 745ms/step - loss: 0.1361 - ColdStartBinaryAccuracy10: 0.7222 - ColdStartAUC10: 0.7509 - ColdStartBinaryAccuracy30: 0.7276 - ColdStartAUC30: 0.7624 - ColdStartBinaryAccuracy50: 0.7314 - ColdStartAUC50: 0.7655 - binary_crossentropy: 0.5226 - BinaryAccuracy: 0.7429 - AUC: 0.7699 - Precision: 0.7637 - Recall: 0.8991 - TrueNegatives: 503360.0000 - TruePositives: 2256269.0000 - FalseNegatives: 253179.0000 - FalsePositives: 698243.0000 - val_loss: 0.1399 - val_ColdStartBinaryAccuracy10: 0.7196 - val_ColdStartAUC10: 0.7459 - val_ColdStartBinaryAccuracy30: 0.7250 - val_ColdStartAUC30: 0.7555 - val_ColdStartBinaryAccuracy50: 0.7289 - val_ColdStartAUC50: 0.7589 - val_binary_crossentropy: 0.5258 - val_BinaryAccuracy: 0.7406 - val_AUC: 0.7651 - val_Precision: 0.7649 - val_Recall: 0.8927 - val_TrueNegatives: 128929.0000 - val_TruePositives: 572617.0000 - val_FalseNegatives: 68799.0000 - val_FalsePositives: 176027.0000\n",
      "Epoch 27/200\n",
      "907/907 [==============================] - 677s 746ms/step - loss: 0.1359 - ColdStartBinaryAccuracy10: 0.7231 - ColdStartAUC10: 0.7521 - ColdStartBinaryAccuracy30: 0.7281 - ColdStartAUC30: 0.7634 - ColdStartBinaryAccuracy50: 0.7320 - ColdStartAUC50: 0.7665 - binary_crossentropy: 0.5218 - BinaryAccuracy: 0.7433 - AUC: 0.7708 - Precision: 0.7641 - Recall: 0.8989 - TrueNegatives: 505299.0000 - TruePositives: 2255861.0000 - FalseNegatives: 253587.0000 - FalsePositives: 696304.0000 - val_loss: 0.1396 - val_ColdStartBinaryAccuracy10: 0.7196 - val_ColdStartAUC10: 0.7466 - val_ColdStartBinaryAccuracy30: 0.7253 - val_ColdStartAUC30: 0.7562 - val_ColdStartBinaryAccuracy50: 0.7289 - val_ColdStartAUC50: 0.7596 - val_binary_crossentropy: 0.5248 - val_BinaryAccuracy: 0.7410 - val_AUC: 0.7661 - val_Precision: 0.7652 - val_Recall: 0.8929 - val_TrueNegatives: 129174.0000 - val_TruePositives: 572744.0000 - val_FalseNegatives: 68672.0000 - val_FalsePositives: 175782.0000\n",
      "Epoch 28/200\n",
      "907/907 [==============================] - 677s 747ms/step - loss: 0.1356 - ColdStartBinaryAccuracy10: 0.7236 - ColdStartAUC10: 0.7534 - ColdStartBinaryAccuracy30: 0.7287 - ColdStartAUC30: 0.7647 - ColdStartBinaryAccuracy50: 0.7325 - ColdStartAUC50: 0.7677 - binary_crossentropy: 0.5208 - BinaryAccuracy: 0.7439 - AUC: 0.7718 - Precision: 0.7647 - Recall: 0.8988 - TrueNegatives: 507642.0000 - TruePositives: 2255547.0000 - FalseNegatives: 253901.0000 - FalsePositives: 693961.0000 - val_loss: 0.1394 - val_ColdStartBinaryAccuracy10: 0.7198 - val_ColdStartAUC10: 0.7473 - val_ColdStartBinaryAccuracy30: 0.7255 - val_ColdStartAUC30: 0.7569 - val_ColdStartBinaryAccuracy50: 0.7294 - val_ColdStartAUC50: 0.7602 - val_binary_crossentropy: 0.5242 - val_BinaryAccuracy: 0.7414 - val_AUC: 0.7666 - val_Precision: 0.7661 - val_Recall: 0.8917 - val_TrueNegatives: 130317.0000 - val_TruePositives: 571937.0000 - val_FalseNegatives: 69479.0000 - val_FalsePositives: 174639.0000\n",
      "Epoch 29/200\n",
      "907/907 [==============================] - 677s 746ms/step - loss: 0.1354 - ColdStartBinaryAccuracy10: 0.7238 - ColdStartAUC10: 0.7544 - ColdStartBinaryAccuracy30: 0.7292 - ColdStartAUC30: 0.7656 - ColdStartBinaryAccuracy50: 0.7329 - ColdStartAUC50: 0.7685 - binary_crossentropy: 0.5200 - BinaryAccuracy: 0.7442 - AUC: 0.7726 - Precision: 0.7652 - Recall: 0.8986 - TrueNegatives: 509458.0000 - TruePositives: 2255078.0000 - FalseNegatives: 254370.0000 - FalsePositives: 692145.0000 - val_loss: 0.1393 - val_ColdStartBinaryAccuracy10: 0.7198 - val_ColdStartAUC10: 0.7479 - val_ColdStartBinaryAccuracy30: 0.7252 - val_ColdStartAUC30: 0.7573 - val_ColdStartBinaryAccuracy50: 0.7292 - val_ColdStartAUC50: 0.7607 - val_binary_crossentropy: 0.5237 - val_BinaryAccuracy: 0.7415 - val_AUC: 0.7671 - val_Precision: 0.7658 - val_Recall: 0.8926 - val_TrueNegatives: 129825.0000 - val_TruePositives: 572542.0000 - val_FalseNegatives: 68874.0000 - val_FalsePositives: 175131.0000\n",
      "Epoch 30/200\n",
      "907/907 [==============================] - 673s 742ms/step - loss: 0.1352 - ColdStartBinaryAccuracy10: 0.7245 - ColdStartAUC10: 0.7551 - ColdStartBinaryAccuracy30: 0.7301 - ColdStartAUC30: 0.7666 - ColdStartBinaryAccuracy50: 0.7338 - ColdStartAUC50: 0.7695 - binary_crossentropy: 0.5191 - BinaryAccuracy: 0.7448 - AUC: 0.7735 - Precision: 0.7658 - Recall: 0.8985 - TrueNegatives: 511948.0000 - TruePositives: 2254736.0000 - FalseNegatives: 254712.0000 - FalsePositives: 689655.0000 - val_loss: 0.1392 - val_ColdStartBinaryAccuracy10: 0.7201 - val_ColdStartAUC10: 0.7488 - val_ColdStartBinaryAccuracy30: 0.7258 - val_ColdStartAUC30: 0.7581 - val_ColdStartBinaryAccuracy50: 0.7297 - val_ColdStartAUC50: 0.7613 - val_binary_crossentropy: 0.5231 - val_BinaryAccuracy: 0.7418 - val_AUC: 0.7677 - val_Precision: 0.7666 - val_Recall: 0.8914 - val_TrueNegatives: 130879.0000 - val_TruePositives: 571778.0000 - val_FalseNegatives: 69638.0000 - val_FalsePositives: 174077.0000\n",
      "Epoch 31/200\n",
      "907/907 [==============================] - 675s 744ms/step - loss: 0.1350 - ColdStartBinaryAccuracy10: 0.7255 - ColdStartAUC10: 0.7562 - ColdStartBinaryAccuracy30: 0.7306 - ColdStartAUC30: 0.7676 - ColdStartBinaryAccuracy50: 0.7343 - ColdStartAUC50: 0.7704 - binary_crossentropy: 0.5184 - BinaryAccuracy: 0.7452 - AUC: 0.7743 - Precision: 0.7662 - Recall: 0.8983 - TrueNegatives: 513884.0000 - TruePositives: 2254294.0000 - FalseNegatives: 255154.0000 - FalsePositives: 687719.0000 - val_loss: 0.1391 - val_ColdStartBinaryAccuracy10: 0.7204 - val_ColdStartAUC10: 0.7494 - val_ColdStartBinaryAccuracy30: 0.7259 - val_ColdStartAUC30: 0.7585 - val_ColdStartBinaryAccuracy50: 0.7296 - val_ColdStartAUC50: 0.7616 - val_binary_crossentropy: 0.5228 - val_BinaryAccuracy: 0.7419 - val_AUC: 0.7679 - val_Precision: 0.7658 - val_Recall: 0.8934 - val_TrueNegatives: 129743.0000 - val_TruePositives: 573046.0000 - val_FalseNegatives: 68370.0000 - val_FalsePositives: 175213.0000\n",
      "Epoch 32/200\n",
      "907/907 [==============================] - 673s 742ms/step - loss: 0.1348 - ColdStartBinaryAccuracy10: 0.7255 - ColdStartAUC10: 0.7572 - ColdStartBinaryAccuracy30: 0.7310 - ColdStartAUC30: 0.7684 - ColdStartBinaryAccuracy50: 0.7347 - ColdStartAUC50: 0.7713 - binary_crossentropy: 0.5175 - BinaryAccuracy: 0.7457 - AUC: 0.7752 - Precision: 0.7668 - Recall: 0.8982 - TrueNegatives: 516031.0000 - TruePositives: 2254053.0000 - FalseNegatives: 255395.0000 - FalsePositives: 685572.0000 - val_loss: 0.1390 - val_ColdStartBinaryAccuracy10: 0.7205 - val_ColdStartAUC10: 0.7499 - val_ColdStartBinaryAccuracy30: 0.7259 - val_ColdStartAUC30: 0.7589 - val_ColdStartBinaryAccuracy50: 0.7296 - val_ColdStartAUC50: 0.7619 - val_binary_crossentropy: 0.5225 - val_BinaryAccuracy: 0.7418 - val_AUC: 0.7682 - val_Precision: 0.7665 - val_Recall: 0.8917 - val_TrueNegatives: 130701.0000 - val_TruePositives: 571962.0000 - val_FalseNegatives: 69454.0000 - val_FalsePositives: 174255.0000\n",
      "Epoch 33/200\n",
      "907/907 [==============================] - 672s 741ms/step - loss: 0.1346 - ColdStartBinaryAccuracy10: 0.7262 - ColdStartAUC10: 0.7579 - ColdStartBinaryAccuracy30: 0.7316 - ColdStartAUC30: 0.7693 - ColdStartBinaryAccuracy50: 0.7353 - ColdStartAUC50: 0.7722 - binary_crossentropy: 0.5168 - BinaryAccuracy: 0.7461 - AUC: 0.7760 - Precision: 0.7672 - Recall: 0.8981 - TrueNegatives: 517675.0000 - TruePositives: 2253798.0000 - FalseNegatives: 255650.0000 - FalsePositives: 683928.0000 - val_loss: 0.1389 - val_ColdStartBinaryAccuracy10: 0.7213 - val_ColdStartAUC10: 0.7505 - val_ColdStartBinaryAccuracy30: 0.7265 - val_ColdStartAUC30: 0.7594 - val_ColdStartBinaryAccuracy50: 0.7301 - val_ColdStartAUC50: 0.7624 - val_binary_crossentropy: 0.5220 - val_BinaryAccuracy: 0.7422 - val_AUC: 0.7687 - val_Precision: 0.7674 - val_Recall: 0.8906 - val_TrueNegatives: 131758.0000 - val_TruePositives: 571272.0000 - val_FalseNegatives: 70144.0000 - val_FalsePositives: 173198.0000\n",
      "Epoch 34/200\n",
      "907/907 [==============================] - 673s 742ms/step - loss: 0.1344 - ColdStartBinaryAccuracy10: 0.7269 - ColdStartAUC10: 0.7590 - ColdStartBinaryAccuracy30: 0.7322 - ColdStartAUC30: 0.7703 - ColdStartBinaryAccuracy50: 0.7358 - ColdStartAUC50: 0.7731 - binary_crossentropy: 0.5160 - BinaryAccuracy: 0.7465 - AUC: 0.7769 - Precision: 0.7677 - Recall: 0.8979 - TrueNegatives: 519780.0000 - TruePositives: 2253200.0000 - FalseNegatives: 256248.0000 - FalsePositives: 681823.0000 - val_loss: 0.1387 - val_ColdStartBinaryAccuracy10: 0.7213 - val_ColdStartAUC10: 0.7513 - val_ColdStartBinaryAccuracy30: 0.7263 - val_ColdStartAUC30: 0.7600 - val_ColdStartBinaryAccuracy50: 0.7300 - val_ColdStartAUC50: 0.7630 - val_binary_crossentropy: 0.5216 - val_BinaryAccuracy: 0.7424 - val_AUC: 0.7692 - val_Precision: 0.7685 - val_Recall: 0.8886 - val_TrueNegatives: 133227.0000 - val_TruePositives: 569966.0000 - val_FalseNegatives: 71450.0000 - val_FalsePositives: 171729.0000\n",
      "Epoch 35/200\n",
      "907/907 [==============================] - 675s 744ms/step - loss: 0.1342 - ColdStartBinaryAccuracy10: 0.7277 - ColdStartAUC10: 0.7597 - ColdStartBinaryAccuracy30: 0.7328 - ColdStartAUC30: 0.7711 - ColdStartBinaryAccuracy50: 0.7364 - ColdStartAUC50: 0.7740 - binary_crossentropy: 0.5152 - BinaryAccuracy: 0.7471 - AUC: 0.7777 - Precision: 0.7682 - Recall: 0.8979 - TrueNegatives: 521877.0000 - TruePositives: 2253149.0000 - FalseNegatives: 256299.0000 - FalsePositives: 679726.0000 - val_loss: 0.1387 - val_ColdStartBinaryAccuracy10: 0.7214 - val_ColdStartAUC10: 0.7517 - val_ColdStartBinaryAccuracy30: 0.7265 - val_ColdStartAUC30: 0.7600 - val_ColdStartBinaryAccuracy50: 0.7301 - val_ColdStartAUC50: 0.7628 - val_binary_crossentropy: 0.5216 - val_BinaryAccuracy: 0.7425 - val_AUC: 0.7690 - val_Precision: 0.7675 - val_Recall: 0.8911 - val_TrueNegatives: 131782.0000 - val_TruePositives: 571535.0000 - val_FalseNegatives: 69881.0000 - val_FalsePositives: 173174.0000\n",
      "Epoch 36/200\n",
      "907/907 [==============================] - 674s 743ms/step - loss: 0.1340 - ColdStartBinaryAccuracy10: 0.7278 - ColdStartAUC10: 0.7605 - ColdStartBinaryAccuracy30: 0.7333 - ColdStartAUC30: 0.7719 - ColdStartBinaryAccuracy50: 0.7369 - ColdStartAUC50: 0.7749 - binary_crossentropy: 0.5145 - BinaryAccuracy: 0.7475 - AUC: 0.7784 - Precision: 0.7687 - Recall: 0.8977 - TrueNegatives: 523547.0000 - TruePositives: 2252817.0000 - FalseNegatives: 256631.0000 - FalsePositives: 678056.0000 - val_loss: 0.1386 - val_ColdStartBinaryAccuracy10: 0.7216 - val_ColdStartAUC10: 0.7524 - val_ColdStartBinaryAccuracy30: 0.7268 - val_ColdStartAUC30: 0.7608 - val_ColdStartBinaryAccuracy50: 0.7305 - val_ColdStartAUC50: 0.7636 - val_binary_crossentropy: 0.5210 - val_BinaryAccuracy: 0.7425 - val_AUC: 0.7697 - val_Precision: 0.7685 - val_Recall: 0.8889 - val_TrueNegatives: 133196.0000 - val_TruePositives: 570145.0000 - val_FalseNegatives: 71271.0000 - val_FalsePositives: 171760.0000\n",
      "Epoch 37/200\n",
      "907/907 [==============================] - 676s 746ms/step - loss: 0.1338 - ColdStartBinaryAccuracy10: 0.7283 - ColdStartAUC10: 0.7616 - ColdStartBinaryAccuracy30: 0.7338 - ColdStartAUC30: 0.7729 - ColdStartBinaryAccuracy50: 0.7374 - ColdStartAUC50: 0.7757 - binary_crossentropy: 0.5137 - BinaryAccuracy: 0.7479 - AUC: 0.7792 - Precision: 0.7691 - Recall: 0.8976 - TrueNegatives: 525436.0000 - TruePositives: 2252480.0000 - FalseNegatives: 256968.0000 - FalsePositives: 676167.0000 - val_loss: 0.1385 - val_ColdStartBinaryAccuracy10: 0.7221 - val_ColdStartAUC10: 0.7529 - val_ColdStartBinaryAccuracy30: 0.7273 - val_ColdStartAUC30: 0.7613 - val_ColdStartBinaryAccuracy50: 0.7309 - val_ColdStartAUC50: 0.7641 - val_binary_crossentropy: 0.5205 - val_BinaryAccuracy: 0.7432 - val_AUC: 0.7700 - val_Precision: 0.7668 - val_Recall: 0.8939 - val_TrueNegatives: 130602.0000 - val_TruePositives: 573332.0000 - val_FalseNegatives: 68084.0000 - val_FalsePositives: 174354.0000\n",
      "Epoch 38/200\n",
      "907/907 [==============================] - 675s 744ms/step - loss: 0.1336 - ColdStartBinaryAccuracy10: 0.7287 - ColdStartAUC10: 0.7625 - ColdStartBinaryAccuracy30: 0.7345 - ColdStartAUC30: 0.7737 - ColdStartBinaryAccuracy50: 0.7380 - ColdStartAUC50: 0.7765 - binary_crossentropy: 0.5131 - BinaryAccuracy: 0.7483 - AUC: 0.7798 - Precision: 0.7696 - Recall: 0.8975 - TrueNegatives: 527396.0000 - TruePositives: 2252201.0000 - FalseNegatives: 257247.0000 - FalsePositives: 674207.0000 - val_loss: 0.1384 - val_ColdStartBinaryAccuracy10: 0.7228 - val_ColdStartAUC10: 0.7532 - val_ColdStartBinaryAccuracy30: 0.7275 - val_ColdStartAUC30: 0.7615 - val_ColdStartBinaryAccuracy50: 0.7310 - val_ColdStartAUC50: 0.7644 - val_binary_crossentropy: 0.5202 - val_BinaryAccuracy: 0.7431 - val_AUC: 0.7703 - val_Precision: 0.7665 - val_Recall: 0.8944 - val_TrueNegatives: 130221.0000 - val_TruePositives: 573698.0000 - val_FalseNegatives: 67718.0000 - val_FalsePositives: 174735.0000\n",
      "Epoch 39/200\n",
      "907/907 [==============================] - 675s 744ms/step - loss: 0.1334 - ColdStartBinaryAccuracy10: 0.7292 - ColdStartAUC10: 0.7632 - ColdStartBinaryAccuracy30: 0.7349 - ColdStartAUC30: 0.7745 - ColdStartBinaryAccuracy50: 0.7384 - ColdStartAUC50: 0.7773 - binary_crossentropy: 0.5123 - BinaryAccuracy: 0.7487 - AUC: 0.7807 - Precision: 0.7700 - Recall: 0.8973 - TrueNegatives: 529005.0000 - TruePositives: 2251784.0000 - FalseNegatives: 257664.0000 - FalsePositives: 672598.0000 - val_loss: 0.1383 - val_ColdStartBinaryAccuracy10: 0.7228 - val_ColdStartAUC10: 0.7537 - val_ColdStartBinaryAccuracy30: 0.7279 - val_ColdStartAUC30: 0.7619 - val_ColdStartBinaryAccuracy50: 0.7314 - val_ColdStartAUC50: 0.7647 - val_binary_crossentropy: 0.5199 - val_BinaryAccuracy: 0.7434 - val_AUC: 0.7706 - val_Precision: 0.7667 - val_Recall: 0.8948 - val_TrueNegatives: 130293.0000 - val_TruePositives: 573920.0000 - val_FalseNegatives: 67496.0000 - val_FalsePositives: 174663.0000\n",
      "Epoch 40/200\n",
      "907/907 [==============================] - 673s 742ms/step - loss: 0.1333 - ColdStartBinaryAccuracy10: 0.7301 - ColdStartAUC10: 0.7640 - ColdStartBinaryAccuracy30: 0.7356 - ColdStartAUC30: 0.7754 - ColdStartBinaryAccuracy50: 0.7392 - ColdStartAUC50: 0.7782 - binary_crossentropy: 0.5116 - BinaryAccuracy: 0.7492 - AUC: 0.7814 - Precision: 0.7705 - Recall: 0.8974 - TrueNegatives: 530645.0000 - TruePositives: 2252025.0000 - FalseNegatives: 257423.0000 - FalsePositives: 670958.0000 - val_loss: 0.1382 - val_ColdStartBinaryAccuracy10: 0.7227 - val_ColdStartAUC10: 0.7544 - val_ColdStartBinaryAccuracy30: 0.7276 - val_ColdStartAUC30: 0.7624 - val_ColdStartBinaryAccuracy50: 0.7313 - val_ColdStartAUC50: 0.7651 - val_binary_crossentropy: 0.5194 - val_BinaryAccuracy: 0.7435 - val_AUC: 0.7712 - val_Precision: 0.7668 - val_Recall: 0.8945 - val_TrueNegatives: 130478.0000 - val_TruePositives: 573764.0000 - val_FalseNegatives: 67652.0000 - val_FalsePositives: 174478.0000\n",
      "Epoch 41/200\n",
      "907/907 [==============================] - 673s 742ms/step - loss: 0.1331 - ColdStartBinaryAccuracy10: 0.7298 - ColdStartAUC10: 0.7647 - ColdStartBinaryAccuracy30: 0.7359 - ColdStartAUC30: 0.7762 - ColdStartBinaryAccuracy50: 0.7394 - ColdStartAUC50: 0.7790 - binary_crossentropy: 0.5109 - BinaryAccuracy: 0.7495 - AUC: 0.7822 - Precision: 0.7708 - Recall: 0.8973 - TrueNegatives: 532020.0000 - TruePositives: 2251707.0000 - FalseNegatives: 257741.0000 - FalsePositives: 669583.0000 - val_loss: 0.1381 - val_ColdStartBinaryAccuracy10: 0.7229 - val_ColdStartAUC10: 0.7548 - val_ColdStartBinaryAccuracy30: 0.7280 - val_ColdStartAUC30: 0.7628 - val_ColdStartBinaryAccuracy50: 0.7315 - val_ColdStartAUC50: 0.7654 - val_binary_crossentropy: 0.5193 - val_BinaryAccuracy: 0.7437 - val_AUC: 0.7712 - val_Precision: 0.7662 - val_Recall: 0.8963 - val_TrueNegatives: 129511.0000 - val_TruePositives: 574908.0000 - val_FalseNegatives: 66508.0000 - val_FalsePositives: 175445.0000\n",
      "Epoch 42/200\n",
      "907/907 [==============================] - 673s 742ms/step - loss: 0.1329 - ColdStartBinaryAccuracy10: 0.7307 - ColdStartAUC10: 0.7657 - ColdStartBinaryAccuracy30: 0.7361 - ColdStartAUC30: 0.7769 - ColdStartBinaryAccuracy50: 0.7396 - ColdStartAUC50: 0.7797 - binary_crossentropy: 0.5103 - BinaryAccuracy: 0.7498 - AUC: 0.7829 - Precision: 0.7712 - Recall: 0.8972 - TrueNegatives: 533441.0000 - TruePositives: 2251503.0000 - FalseNegatives: 257945.0000 - FalsePositives: 668162.0000 - val_loss: 0.1381 - val_ColdStartBinaryAccuracy10: 0.7230 - val_ColdStartAUC10: 0.7554 - val_ColdStartBinaryAccuracy30: 0.7279 - val_ColdStartAUC30: 0.7631 - val_ColdStartBinaryAccuracy50: 0.7315 - val_ColdStartAUC50: 0.7658 - val_binary_crossentropy: 0.5190 - val_BinaryAccuracy: 0.7437 - val_AUC: 0.7715 - val_Precision: 0.7668 - val_Recall: 0.8950 - val_TrueNegatives: 130332.0000 - val_TruePositives: 574066.0000 - val_FalseNegatives: 67350.0000 - val_FalsePositives: 174624.0000\n",
      "Epoch 43/200\n",
      "907/907 [==============================] - 672s 741ms/step - loss: 0.1327 - ColdStartBinaryAccuracy10: 0.7311 - ColdStartAUC10: 0.7660 - ColdStartBinaryAccuracy30: 0.7370 - ColdStartAUC30: 0.7777 - ColdStartBinaryAccuracy50: 0.7405 - ColdStartAUC50: 0.7805 - binary_crossentropy: 0.5096 - BinaryAccuracy: 0.7503 - AUC: 0.7836 - Precision: 0.7717 - Recall: 0.8972 - TrueNegatives: 535645.0000 - TruePositives: 2251392.0000 - FalseNegatives: 258056.0000 - FalsePositives: 665958.0000 - val_loss: 0.1379 - val_ColdStartBinaryAccuracy10: 0.7235 - val_ColdStartAUC10: 0.7557 - val_ColdStartBinaryAccuracy30: 0.7285 - val_ColdStartAUC30: 0.7635 - val_ColdStartBinaryAccuracy50: 0.7320 - val_ColdStartAUC50: 0.7662 - val_binary_crossentropy: 0.5186 - val_BinaryAccuracy: 0.7439 - val_AUC: 0.7720 - val_Precision: 0.7660 - val_Recall: 0.8971 - val_TrueNegatives: 129178.0000 - val_TruePositives: 575440.0000 - val_FalseNegatives: 65976.0000 - val_FalsePositives: 175778.0000\n",
      "Epoch 44/200\n",
      "907/907 [==============================] - 671s 740ms/step - loss: 0.1326 - ColdStartBinaryAccuracy10: 0.7316 - ColdStartAUC10: 0.7668 - ColdStartBinaryAccuracy30: 0.7376 - ColdStartAUC30: 0.7784 - ColdStartBinaryAccuracy50: 0.7411 - ColdStartAUC50: 0.7812 - binary_crossentropy: 0.5090 - BinaryAccuracy: 0.7508 - AUC: 0.7842 - Precision: 0.7721 - Recall: 0.8972 - TrueNegatives: 537071.0000 - TruePositives: 2251493.0000 - FalseNegatives: 257955.0000 - FalsePositives: 664532.0000 - val_loss: 0.1379 - val_ColdStartBinaryAccuracy10: 0.7235 - val_ColdStartAUC10: 0.7561 - val_ColdStartBinaryAccuracy30: 0.7290 - val_ColdStartAUC30: 0.7637 - val_ColdStartBinaryAccuracy50: 0.7322 - val_ColdStartAUC50: 0.7664 - val_binary_crossentropy: 0.5184 - val_BinaryAccuracy: 0.7442 - val_AUC: 0.7721 - val_Precision: 0.7658 - val_Recall: 0.8983 - val_TrueNegatives: 128764.0000 - val_TruePositives: 576181.0000 - val_FalseNegatives: 65235.0000 - val_FalsePositives: 176192.0000\n",
      "Epoch 45/200\n",
      "907/907 [==============================] - 671s 740ms/step - loss: 0.1324 - ColdStartBinaryAccuracy10: 0.7320 - ColdStartAUC10: 0.7679 - ColdStartBinaryAccuracy30: 0.7381 - ColdStartAUC30: 0.7794 - ColdStartBinaryAccuracy50: 0.7415 - ColdStartAUC50: 0.7821 - binary_crossentropy: 0.5083 - BinaryAccuracy: 0.7512 - AUC: 0.7849 - Precision: 0.7725 - Recall: 0.8972 - TrueNegatives: 538692.0000 - TruePositives: 2251408.0000 - FalseNegatives: 258040.0000 - FalsePositives: 662911.0000 - val_loss: 0.1379 - val_ColdStartBinaryAccuracy10: 0.7236 - val_ColdStartAUC10: 0.7567 - val_ColdStartBinaryAccuracy30: 0.7289 - val_ColdStartAUC30: 0.7642 - val_ColdStartBinaryAccuracy50: 0.7320 - val_ColdStartAUC50: 0.7667 - val_binary_crossentropy: 0.5183 - val_BinaryAccuracy: 0.7442 - val_AUC: 0.7722 - val_Precision: 0.7677 - val_Recall: 0.8940 - val_TrueNegatives: 131483.0000 - val_TruePositives: 573398.0000 - val_FalseNegatives: 68018.0000 - val_FalsePositives: 173473.0000\n",
      "Epoch 46/200\n",
      "773/907 [========================>.....] - ETA: 1:21 - loss: 0.1320 - ColdStartBinaryAccuracy10: 0.7318 - ColdStartAUC10: 0.7678 - ColdStartBinaryAccuracy30: 0.7381 - ColdStartAUC30: 0.7794 - ColdStartBinaryAccuracy50: 0.7419 - ColdStartAUC50: 0.7824 - binary_crossentropy: 0.5076 - BinaryAccuracy: 0.7516 - AUC: 0.7855 - Precision: 0.7730 - Recall: 0.8974 - TrueNegatives: 458374.0000 - TruePositives: 1917049.0000 - FalseNegatives: 219082.0000 - FalsePositives: 562978.0000"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-2601423bf9a3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     85\u001B[0m                                                                               \u001B[0msave_best_only\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m                                                                               save_weights_only=True),\n\u001B[0;32m---> 87\u001B[0;31m                                             \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensorBoard\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlog_dir\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlog_dir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     88\u001B[0m                                         ])\n\u001B[1;32m     89\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/Knowledge_Tracing/code/models/dkt_models/hybrid_dkt/hybrid_dkt_on_predictions.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, dataset, epochs, verbose, callbacks, validation_data, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001B[0m\n\u001B[1;32m    148\u001B[0m                                                           \u001B[0msteps_per_epoch\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msteps_per_epoch\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m                                                           \u001B[0mvalidation_steps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvalidation_steps\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m                                                           validation_freq=validation_freq)\n\u001B[0m\u001B[1;32m    151\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m     def custom_evaluate(self,\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 64\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1382\u001B[0m                 _r=1):\n\u001B[1;32m   1383\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1384\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1385\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1386\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    913\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    914\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 915\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    916\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    917\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    945\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    946\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 947\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    948\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    949\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2955\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m   2956\u001B[0m     return graph_function._call_flat(\n\u001B[0;32m-> 2957\u001B[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0m\u001B[1;32m   2958\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2959\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1852\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1853\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0;32m-> 1854\u001B[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[1;32m   1855\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[1;32m   1856\u001B[0m         \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    502\u001B[0m               \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    503\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 504\u001B[0;31m               ctx=ctx)\n\u001B[0m\u001B[1;32m    505\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    506\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0;32m---> 55\u001B[0;31m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[1;32m     56\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from Knowledge_Tracing.code.models.dkt_models.hybrid_dkt import data_utils, hybrid_dkt_on_predictions as hybrid_deepkt\n",
    "from Knowledge_Tracing.code.evaluation.tensorflow_evaluation import metrics\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "verbose = 1  # Verbose = {0,1,2}\n",
    "best_model_weights = \"weights/bestmodel\"  # File to save the model.\n",
    "\n",
    "batch_size = 16  # Batch size\n",
    "\n",
    "test_fraction = 0.2  # Portion of data to be used for testing\n",
    "validation_fraction = 0.2  # Portion of training data to be used for validation\n",
    "# \"count_vectorizer\":count_vectorizer_args, \"word2vec\":word2vec_args, \"pretrained_distilbert\":pretrained_distilbert_args, \n",
    "nlp_kwargs_list = [{\"sentence_transformers\":sentence_transformers_args, \"word2vec\":word2vec_args, \"pretrained_distilbert\":pretrained_distilbert_args}]    \n",
    "if __name__ == '__main__':\n",
    "    for nlp_kwargs in nlp_kwargs_list:\n",
    "        train_set, val_set, test_set, encoding_depths, encoding_names, parameters = data_utils.load_dataset(batch_size=batch_size, shuffle=False,\n",
    "                                                                      interactions_filepath=interactions_filepath, \n",
    "                                                                      texts_filepath=texts_filepath,\n",
    "                                                                      save_filepath=save_filepath,\n",
    "                                                                      interaction_sequence_len=interaction_sequence_len, min_seq_len=5, dictionary=dictionary,\n",
    "                                                                      **nlp_kwargs)\n",
    "\n",
    "        print(encoding_depths)\n",
    "        log_dir = \"logs\"  # Path to save the logs.\n",
    "        lstm_units = 256  # Number of LSTM units\n",
    "        epochs = 200  # Number of epochs to train\n",
    "        dropout_rate = 0.3  # Dropout rate\n",
    "\n",
    "\n",
    "        configs = {}\n",
    "        for encoding_depth, encoding_name in list(zip(list(encoding_depths.values()), encoding_names)):\n",
    "            if encoding_name == \"count_vectorizer\" or encoding_name == \"bertopic\":\n",
    "                config = {\"name\":encoding_name, \"embedding_size\":encoding_depth, \n",
    "                      \"hidden_units\":128}    \n",
    "            else:\n",
    "                config = {\"name\":encoding_name, \"embedding_size\":encoding_depth, \n",
    "                      \"hidden_units\":lstm_units}    \n",
    "            configs[encoding_name] = config \n",
    "\n",
    "\n",
    "        for lr in [1e-4]:\n",
    "            # USE THIS TO UPDATE GITHUB DIRECTORY (NEED TO RESTART SESSION TOO)\n",
    "            !rm -rf /content/weights\n",
    "            metrics_list_2=[\n",
    "                metrics.ColdStartBinaryAccuracy(10),\n",
    "                metrics.ColdStartAUC(10),\n",
    "                metrics.ColdStartBinaryAccuracy(30),\n",
    "                metrics.ColdStartAUC(30),\n",
    "                metrics.ColdStartBinaryAccuracy(50),\n",
    "                metrics.ColdStartAUC(50),\n",
    "                tf.keras.losses.binary_crossentropy,\n",
    "                metrics.BinaryAccuracy(),\n",
    "                metrics.AUC(),\n",
    "                metrics.Precision(),\n",
    "                metrics.Recall(),\n",
    "                metrics.TrueNegatives(),\n",
    "                metrics.TruePositives(),\n",
    "                metrics.FalseNegatives(),\n",
    "                metrics.FalsePositives(),\n",
    "            ]\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=lr)  # Optimizer to use\n",
    "            student_model = hybrid_deepkt.hybrid_DKT_on_predictions(\n",
    "                configs=configs,\n",
    "                dropout_rate=dropout_rate)\n",
    "            log_dir = \"logs/\" + student_model.name  # Path to save the logs.\n",
    "            best_model_weights = \"weights/bestmodel/\" + student_model.name  # File to save the model.\n",
    "            student_model.compile(optimizer=optimizer, \n",
    "                                  metrics=metrics_list_2\n",
    "            )\n",
    "\n",
    "            student_model.summary()\n",
    "\n",
    "            history = student_model.fit(dataset=train_set,\n",
    "                                        epochs=epochs,\n",
    "                                        verbose=verbose,\n",
    "                                        validation_data=val_set,\n",
    "                                        callbacks=[\n",
    "                                            tf.keras.callbacks.EarlyStopping(monitor='val_AUC', mode='max',\n",
    "                                                                            patience=10, restore_best_weights=True),\n",
    "                                            tf.keras.callbacks.CSVLogger(f\"{log_dir}/train.log\"),\n",
    "                                            tf.keras.callbacks.ModelCheckpoint(best_model_weights,\n",
    "                                                                              save_best_only=True,\n",
    "                                                                              save_weights_only=True),\n",
    "                                            tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "                                        ])\n",
    "\n",
    "            student_model.load_weights(best_model_weights)\n",
    "\n",
    "            result = [student_model.model_name, student_model.embeddings_names, \" \".join(parameters), interaction_sequence_len, lr, epochs, lstm_units, dropout_rate] + student_model.custom_evaluate(test_set, verbose=verbose)\n",
    "            print(result)\n",
    "            results.append(result)\n",
    "            del [student_model, metrics_list_2]\n",
    "            gc.collect()\n",
    "        del [train_set, val_set, test_set, encoding_depths, encoding_names]\n",
    "        gc.collect()\n",
    "        print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 150318,
     "status": "ok",
     "timestamp": 1648378455819,
     "user": {
      "displayName": "Simone Sartoni",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01206349563686190394"
     },
     "user_tz": -120
    },
    "id": "eJsXZlWMKDCH",
    "outputId": "258ac31a-f565-4e74-e9b9-2d77cbd860d6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "283/283 [==============================] - 150s 530ms/step - loss: 0.1364 - ColdStartBinaryAccuracy10: 0.7232 - ColdStartAUC10: 0.7546 - ColdStartBinaryAccuracy30: 0.7292 - ColdStartAUC30: 0.7648 - ColdStartBinaryAccuracy50: 0.7327 - ColdStartAUC50: 0.7668 - binary_crossentropy: 0.5203 - BinaryAccuracy: 0.7429 - AUC: 0.7715 - Precision: 0.7663 - Recall: 0.8919 - TrueNegatives: 165426.0000 - TruePositives: 703007.0000 - FalseNegatives: 85243.0000 - FalsePositives: 214414.0000\n",
      "['hybrid_dkt_on_predictions', 'pretrained_distilbert_sentence_transformer_gensim_word2vec_', '{}_{}_plain_text_plain_text all-mpnet-base-v2_{}_plain_text list_of_words_200_sg:1_min_count:1_window:5_vector_size:800', 500, 0.0001, 200, 256, 0.3, 0.13637886941432953, 0.7232492566108704, 0.7545697689056396, 0.7292108535766602, 0.7647724151611328, 0.7327430248260498, 0.7668070197105408, 0.5203476548194885, 0.7428537011146545, 0.7715469598770142, 0.7662861347198486, 0.891857922077179, 165426.0, 703007.0, 85243.0, 214414.0]\n"
     ]
    }
   ],
   "source": [
    "student_model.load_weights(best_model_weights)\n",
    "\n",
    "result = [student_model.model_name, student_model.embeddings_names, \" \".join(parameters), interaction_sequence_len, lr, epochs, lstm_units, dropout_rate] + student_model.custom_evaluate(test_set, verbose=verbose)\n",
    "print(result)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FxZaV0FQWQsi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648386899290,
     "user_tz": -120,
     "elapsed": 223,
     "user": {
      "displayName": "Simone Sartoni",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01206349563686190394"
     }
    }
   },
   "outputs": [],
   "source": [
    "from Knowledge_Tracing.code.evaluation.tensorflow_evaluation import metrics"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "results = [['hybrid_dkt_on_predictions', 'pretrained_distilbert_sentence_transformer_gensim_word2vec_', '{}_{}_plain_text_plain_text all-mpnet-base-v2_{}_plain_text list_of_words_200_sg:1_min_count:1_window:5_vector_size:800', 500, 0.0001, 200, 256, 0.3, 0.13637886941432953, 0.7232492566108704, 0.7545697689056396, 0.7292108535766602, 0.7647724151611328, 0.7327430248260498, 0.7668070197105408, 0.5203476548194885, 0.7428537011146545, 0.7715469598770142, 0.7662861347198486, 0.891857922077179, 165426.0, 703007.0, 85243.0, 214414.0]]"
   ],
   "metadata": {
    "id": "ckIxiqzhgvNg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648386899896,
     "user_tz": -120,
     "elapsed": 321,
     "user": {
      "displayName": "Simone Sartoni",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01206349563686190394"
     }
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7t7e7O69iS5a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648386906967,
     "user_tz": -120,
     "elapsed": 4601,
     "user": {
      "displayName": "Simone Sartoni",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01206349563686190394"
     }
    }
   },
   "outputs": [],
   "source": [
    "metrics_list=[\n",
    "        metrics.ColdStartBinaryAccuracy(10),\n",
    "        metrics.ColdStartAUC(10),\n",
    "        metrics.ColdStartBinaryAccuracy(30),\n",
    "        metrics.ColdStartAUC(30),\n",
    "        metrics.ColdStartBinaryAccuracy(50),\n",
    "        metrics.ColdStartAUC(50),\n",
    "        tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics.BinaryAccuracy(),\n",
    "        metrics.AUC(),\n",
    "        metrics.Precision(),\n",
    "        metrics.Recall(),\n",
    "        metrics.TrueNegatives(),\n",
    "        metrics.TruePositives(),\n",
    "        metrics.FalseNegatives(),\n",
    "        metrics.FalsePositives(),\n",
    "    ]\n",
    "import pandas as pd\n",
    "#from Knowledge_Tracing.code.evaluation.tensorflow_utils import metrics, losses as custom_losses\n",
    "metrics_names = [metric.name for metric in metrics_list]\n",
    "column_names =[\"model_name\", \"embeddings_names\", \"parameters\", \"interactions_max_sequence\", \"lr\", \"epochs\", \"lstm_units\", \"dropout_rate\", \"wrong_loss\"] + [metric for metric in metrics_names]\n",
    "result_df_to_add = pd.DataFrame(results, columns=column_names)\n",
    "update = True\n",
    "hybrid_result_filepath_2009=\"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/results/assistment 2009/dkt/hybrid_dkt_results.csv\"\n",
    "hybrid_result_filepath_2012=\"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/results/assistment_2012/dkt/hybrid_dkt_results.csv\"\n",
    "hybrid_result_filepath_CA=\"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/results/CloudAcademy/dkt/hybrid_dkt_results.csv\"\n",
    "hybrid_result_filepath_poj=\"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/results/poj/dkt/hybrid_dkt_results.csv\"\n",
    "\n",
    "result_filepath_2009=\"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/results/assistment 2009/dkt/nlp_dkt_results.csv\"\n",
    "result_filepath_2012=\"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/results/assistment_2012/dkt/nlp_dkt_results.csv\"\n",
    "result_filepath_CA=\"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/results/CloudAcademy/dkt/nlp_dkt_results.csv\"\n",
    "result_filepath_poj=\"/content/drive/MyDrive/simone sartoni - text enhanced deep knowledge tracing/Text-enhanced Knowledge Tracing/results/poj/dkt/nlp_dkt_results.csv\"\n",
    "\n",
    "if update:\n",
    "    result_df = pd.read_csv(hybrid_result_filepath_2012)\n",
    "    result_df = result_df.append(result_df_to_add)\n",
    "else:\n",
    "    result_df = result_df_to_add\n",
    "result_df.to_csv(hybrid_result_filepath_2012, index = False, header=True)  \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hybrid_dkt.ipynb",
   "provenance": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "57af06d02e9e47d38bb931b80f2af688": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c8ed9321bc914937935fc9e723533a72",
       "IPY_MODEL_caba4f4879c244cf83a21df3162442e5",
       "IPY_MODEL_b5d28eb8800b4bb78326f90ac1d4f911"
      ],
      "layout": "IPY_MODEL_383515af290242eabfe47a074c02d6cf"
     }
    },
    "c8ed9321bc914937935fc9e723533a72": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8b2be691467439f960cae5320ae6ccb",
      "placeholder": "​",
      "style": "IPY_MODEL_0ec6a66430f14ab7bc2676d89e4cb81a",
      "value": "Batches: 100%"
     }
    },
    "caba4f4879c244cf83a21df3162442e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_236e702a4eb74e9e80ef2cff96a7a61a",
      "max": 2812,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_becf3d39d9a04cb386244db71d1d27f9",
      "value": 2812
     }
    },
    "b5d28eb8800b4bb78326f90ac1d4f911": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7013ad734a44e0992ca5f76bf1fe1cd",
      "placeholder": "​",
      "style": "IPY_MODEL_1f637bf1da3c4d9f8a603a8307fb4a8c",
      "value": " 2812/2812 [04:22&lt;00:00, 126.86it/s]"
     }
    },
    "383515af290242eabfe47a074c02d6cf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8b2be691467439f960cae5320ae6ccb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ec6a66430f14ab7bc2676d89e4cb81a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "236e702a4eb74e9e80ef2cff96a7a61a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "becf3d39d9a04cb386244db71d1d27f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f7013ad734a44e0992ca5f76bf1fe1cd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f637bf1da3c4d9f8a603a8307fb4a8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e994759ba959467ab0dfde85aece1c2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f7816bb7bee345379c15e178db2223f3",
       "IPY_MODEL_59c8fb354be5483cab82262285043e19",
       "IPY_MODEL_404e09294ec3400cac85b418e23c99e8"
      ],
      "layout": "IPY_MODEL_cddb99d0690c4f46a784f8c296d4c5fc"
     }
    },
    "f7816bb7bee345379c15e178db2223f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a741d3f72220439ebbd1d03eaf82283a",
      "placeholder": "​",
      "style": "IPY_MODEL_3f138edee01e4c688c2858445e9ef8a0",
      "value": "Batches: 100%"
     }
    },
    "59c8fb354be5483cab82262285043e19": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_623ff5149aab439a914883f2c83f0a44",
      "max": 2812,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d3f359c0318b4ecc9f8a3c1f37248b68",
      "value": 2812
     }
    },
    "404e09294ec3400cac85b418e23c99e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab173af715104eaf8d8269f25cafa054",
      "placeholder": "​",
      "style": "IPY_MODEL_5fee3edb11e8411abd8b87e52b43117f",
      "value": " 2812/2812 [01:32&lt;00:00, 124.39it/s]"
     }
    },
    "cddb99d0690c4f46a784f8c296d4c5fc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a741d3f72220439ebbd1d03eaf82283a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f138edee01e4c688c2858445e9ef8a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "623ff5149aab439a914883f2c83f0a44": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3f359c0318b4ecc9f8a3c1f37248b68": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ab173af715104eaf8d8269f25cafa054": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fee3edb11e8411abd8b87e52b43117f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}